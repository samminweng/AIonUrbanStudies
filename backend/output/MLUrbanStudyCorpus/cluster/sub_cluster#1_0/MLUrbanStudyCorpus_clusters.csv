HDBSCAN_Cluster,DocId,Cited by,Year,Document Type,Title,Abstract,Author Keywords,Authors,DOI,x,y
-1,1,315.0,2018,Article,Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework,"In this paper, we designed an end-to-end spectral-spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia. © 1980-2012 IEEE.",3-D deep learning; hyperspectral image classification; spectral-spatial feature extraction; spectral-spatial residual network (SSRN),"Zhong Z., Li J., Luo Z., Chapman M.",10.1109/TGRS.2017.2755542,7.29,2.19
1,2,274.0,2012,Article,Monitoring land cover change in urban and peri-urban areas using dense time stacks of Landsat satellite data and a data mining approach,"Given the pace and scale of urban expansion in many parts of the globe, urban environments are playing an increasingly important role in daily quality-of-life issues, ecological processes, climate, material flows, and land transformations. Remote sensing has emerged as a powerful tool to monitor rates and patterns of urban expansion, but many early challenges - such as distinguishing new urban land from bare ground - remain unsolved. To deal with the high temporal and spatial variability as well as complex, multi-signature classes within settlements, this paper presents a new approach that exploits multi-seasonal information in dense time stacks of Landsat imagery using a multi-date composite change detection technique. The central premise of the approach is that lands within/near urban areas have distinct temporal trajectories both before and after change occurs, and that these lead to characteristic temporal signatures in several spectral regions. The method relies on a supervised classification that exploits training data of stable/changed areas interpreted from Google Earth images, and a 'brute force' approach of providing all available Landsat data as input, including scenes with data gaps due to the Scan Line Corrector (SLC) problem. Three classification algorithms (maximum likelihood, boosted decision trees, and support vector machines) were tested for their ability to monitor expansion across five time periods (1988-1995, 1996-2000, 2001-2003, 2004-2006, 2007-2009) in three study areas that differ in size, eco-climatic conditions, and rates/patterns of development. Both the decision trees and support vector machines outperformed the maximum likelihood classifier (overall accuracy of 90-93%, compared to 65%), but the decision trees were superior at handling missing data. Adding transformed features such as band metrics to the Landsat data stack increased accuracy 1-4%, while experiments with a reduced number of features (designed to mimic noisy or missing data) led to a drop in accuracy of 1-9%. The methodology also proved particularly effective for monitoring peri-urbanization outside the urban core, capturing > 98% of village settlements. © 2012 Elsevier Inc.",Change detection; Cities; Classification; Decision trees; Environment; Land cover; Machine learning; Peri-urban; Random forests; Support vector machines; Urban areas; Urbanization,Schneider A.,10.1016/j.rse.2012.06.006,7.84,0.23
-1,3,181.0,2015,Conference Paper,Building detection in very high resolution multispectral data with deep learning features,"The automated man-made object detection and building extraction from single satellite images is, still, one of the most challenging tasks for various urban planning and monitoring engineering applications. To this end, in this paper we propose an automated building detection framework from very high resolution remote sensing data based on deep convolutional neural networks. The core of the developed method is based on a supervised classification procedure employing a very large training dataset. An MRF model is then responsible for obtaining the optimal labels regarding the detection of scene buildings. The experimental results and the performed quantitative validation indicate the quite promising potentials of the developed approach. © 2015 IEEE.",deep convolutional networks; extraction; ImageNet; Machine learning; man made objects,"Vakalopoulou M., Karantzalos K., Komodakis N., Paragios N.",10.1109/IGARSS.2015.7326158,5.72,1.94
-1,12,88.0,2012,Article,Mining urban land-use patterns from volunteered geographic information by means of genetic algorithms and artificial neural networks,"In the context of OpenStreetMap (OSM), spatial data quality, in particular completeness, is an essential aspect of its fitness for use in specific applications, such as planning tasks. To mitigate the effect of completeness errors in OSM, this study proposes a methodological framework for predicting by means of OSM urban areas in Europe that are currently not mapped or only partially mapped. For this purpose, a machine learning approach consisting of artificial neural networks and genetic algorithms is applied. Under the premise of existing OSM data, the model estimates missing urban areas with an overall squared correlation coefficient (R 2) of 0.589. Interregional comparisons of European regions confirm spatial heterogeneity in the model performance, whereas the R 2 ranges from 0.129 up to 0.789. These results show that the delineation of urban areas by means of the presented methodology depends strongly on location. © 2012 Taylor &amp; Francis Group, LLC.",Machine learning; OpenStreetMap UK; Spatial data quality; Volunteered geographic information,"Hagenauer J., Helbich M.",10.1080/13658816.2011.619501,7.39,-1.59
-1,17,77.0,2008,Article,Land-cover change and environmental impact analysis in the Greater Mankato area of Minnesota using remote sensing and GIS modelling,"Land use and land-cover (LULC) data provide essential information for environmental management and planning. This research evaluates the land-cover change dynamics and their effects for the Greater Mankato Area of Minnesota using image classification and Geographic Information Systems (GIS) modelling in high-resolution aerial photography and QuickBird imagery. Results show that from 1971 to 2003, urban impervious surfaces increased from 18.3% to 32.6%, while cropland and grassland decreased from 54.2% to 39.1%. The dramatic urbanization caused evident environmental impacts in terms of runoff and water quality, whereas the annual air pollution removal rate and carbon storage/sequestration remained consistent since urban forests were steady over the 32-year span. The results also indicate that highly accurate land-cover features can be extracted effectively from high-resolution imagery by incorporating both spectral and spatial information, applying an image-fusion technique, and utilizing the hierarchical machine-learning Feature Analyst classifier. This research fills the high-resolution LULC data gap for the Greater Mankato Area. The findings of the study also provide valuable inputs for local decision-makers and urban planners.",,Yuan F.,10.1080/01431160701294703,7.95,-0.14
0,19,69.0,2017,Conference Paper,Using convolutional networks and satellite imagery to identify patterns in urban environments at a large scale,"Urban planning applications (energy audits, investment, etc.) require an understanding of built infrastructure and its environment, i.e., both low-level, physical features (amount of vegetation, building area and geometry etc.), as well as higher-level concepts such as land use classes (which encode expert understanding of socioeconomic end uses). This kind of data is expensive and labor-intensive to obtain, which limits its availability (particularly in developing countries). We analyze patterns in land use in urban neighborhoods using large-scale satellite imagery data (which is available worldwide from third-party providers) and state-of-the-art computer vision techniques based on deep convolutional neural networks. For supervision, given the limited availability of standard benchmarks for remote-sensing data, we obtain ground truth land use class labels carefully sampled from open-source surveys, in particular the Urban Atlas land classification dataset of 20 land use classes across 300 European cities. We use this data to train and compare deep architectures which have recently shown good performance on standard computer vision tasks (image classification and segmentation), including on geospatial data. Furthermore, we show that the deep representations extracted from satellite imagery of urban environments can be used to compare neighborhoods across several cities. We make our dataset available for other machine learning researchers to use for remote-sensing applications. © 2017 Copyright held by the owner/author(s).",Convolutional networks; Land use classification; Satellite imagery,"Albert A., Kaur J., Gonzalez M.C.",10.1145/3097983.3098070,6.3,2.21
-1,20,61.0,2014,Article,Building type classification using spatial and landscape attributes derived from LiDAR remote sensing data,"Building information is one of the key elements for a range of urban planning and management practices. In this study, an investigation was performed to classify buildings delineated from light detection and ranging (LiDAR) remote sensing data into three types: single-family houses, multiple-family houses, and non-residential buildings. Four kinds of spatial attributes describing the shape, location, and surrounding environment of buildings were calculated and subsequently employed in the classification. Experiments were performed in suburban and downtown sites in Denver, CO, USA, considering different building components and neighborhood environments. Building type classification results yielded overall accuracy > 70% and Kappa > 0.5 for both sites, demonstrating the feasibility of obtaining building type information from LiDAR data. The shape attributes, such as width, footprint area, and perimeter, were most useful for identifying building types. Environmental landscape attributes surrounding buildings, such as the number of road and parking lot pixels, also contributed to obtaining building type information. Combining shape and environmental landscape attributes was necessary to obtain accurate and consistent classification results. © 2014 Elsevier B.V.",Building classification; Decision trees; LiDAR; Machine learning; Random forest; Support vector machines,"Lu Z., Im J., Rhee J., Hodgson M.",10.1016/j.landurbplan.2014.07.005,5.09,0.73
-1,21,59.0,2015,Article,Urban land use and land cover classification using remotely sensed sar data through deep belief networks,"Land use and land cover (LULC) mapping in urban areas is one of the core applications in remote sensing, and it plays an important role in modern urban planning and management. Deep learning is springing up in the field of machine learning recently. By mimicking the hierarchical structure of the human brain, deep learning can gradually extract features from lower level to higher level. The Deep Belief Networks (DBN) model is a widely investigated and deployed deep learning architecture. It combines the advantages of unsupervised and supervised learning and can archive good classification performance. This study proposes a classification approach based on the DBN model for detailed urban mapping using polarimetric synthetic aperture radar (PolSAR) data. Through the DBN model, effective contextual mapping features can be automatically extracted from the PolSAR data to improve the classification performance. Two-date high-resolution RADARSAT-2 PolSAR data over the Great Toronto Area were used for evaluation. Comparisons with the support vector machine (SVM), conventional neural networks (NN), and stochastic Expectation-Maximization (SEM) were conducted to assess the potential of the DBN-based classification approach. Experimental results show that the DBN-based method outperforms three other approaches and produces homogenous mapping results with preserved shape details. © 2015 Qi Lv et al.",,"Lv Q., Dou Y., Niu X., Xu J., Xu J., Xia F.",10.1155/2015/538063,7.11,2.25
-1,25,51.0,2018,Article,Exploring the optimal integration levels between SAR and optical data for better urban land cover mapping in the Pearl River Delta,"Integrating synthetic aperture radar (SAR) and optical data to improve urban land cover classification has been identified as a promising approach. However, which integration level is the most suitable remains unclear but important to many researchers and engineers. This study aimed to compare different integration levels for providing a scientific reference for a wide range of studies using optical and SAR data. SAR data from TerraSAR-X and ENVISAT ASAR in both WSM and IMP modes were used to be combined with optical data at pixel level, feature level and decision levels using four typical machine learning methods. The experimental results indicated that: 1) feature level that used both the original images and extracted features achieved a significant improvement of up to 10% compared to that using optical data alone; 2) different levels of fusion required different suitable methods depending on the data distribution and data resolution. For instance, support vector machine was the most stable at both the feature and decision levels, while random forest was suitable at the pixel level but not suitable at the decision level. 3) By examining the distribution of SAR features, some features (e.g., homogeneity) exhibited a close-to-normal distribution, explaining the improvement from the maximum likelihood method at the feature and decision levels. This indicated the benefits of using texture features from SAR data when being combined with optical data for land cover classification. Additionally, the research also shown that combining optical and SAR data does not guarantee improvement compared with using single data source for urban land cover classification, depending on the selection of appropriate fusion levels and fusion methods. © 2017 Elsevier B.V.",Fusion level; Fusion strategies; Optical and SAR fusion; Urban land cover,"Zhang H., Xu R.",10.1016/j.jag.2017.08.013,6.88,0.78
-1,26,51.0,2015,Article,Combining Pixel-and Object-Based Machine Learning for Identification of Water-Body Types from Urban High-Resolution Remote-Sensing Imagery,"Water is one of the vital components for the ecological environment, which plays an important role in human survival and socioeconomic development. Water resources in urban areas are gradually decreasing due to the rapid urbanization, especially in developing countries. Therefore, the precise extraction and automatic identification of water bodies are of great significance and urgently required for urban planning. It should be noted that although some studies have been reported regarding the water-area extraction, to our knowledge, few papers concern the identification of urban water types (e.g., rivers, lakes, canals, and ponds). In this paper, a novel two-level machine-learning framework is proposed for identifying the water types from urban high-resolution remote-sensing images. The framework consists of two interpretation levels: 1) water bodies are extracted at the pixel level, where the water/shadow/vegetation indexes are considered and 2) water types are further identified at the object level, where a set of geometrical and textural features are used. Both levels employ machine learning for the image interpretation. The proposed framework is validated using the GeoEye-1 and WorldView-2 images, over two mega cities in China, i.e., Wuhan and Shenzhen, respectively. The experimental results show that the proposed method achieved satisfactory accuracies for both water extraction [95.4% (Shenzhen), 96.2% (Wuhan)], and water type classification [94.1% (Shenzhen), 95.9% (Wuhan)] in complex urban areas. © 2015 IEEE.",High resolution; machine learning; object-oriented; water detection; water extraction; water index,"Huang X., Xie C., Fang X., Zhang L.",10.1109/JSTARS.2015.2420713,6.44,-0.1
-1,30,45.0,2014,Article,From land cover-graphs to urban structure types,"Urban structure types (UST) are an initial interest and basic instrument for monitoring, controlling and modeling tasks of urban planners and decision makers during ongoing urbanization processes. This study focuses on a method to classify UST from land cover (LC) objects, which were derived from high resolution satellite images. The topology of urban LC objects is analyzed by implementing neighborhood LC-graphs. Various graph measures are examined by their potential to distinguish between different UST, using the machine learning classifier random forest. Additionally the influence of different parameter settings of the random forest model, the reduction of training samples, and the graph measure importance is analyzed. An independent test set is classified and validated, achieving an overall accuracy of 87%. It was found that the height of the building with the highest node degree has a strong impact on the classification result. © 2014 © Taylor & Francis.",adjacency-graphs; land cover; land use; urban; urban structure types,"Walde I., Hese S., Berger C., Schmullius C.",10.1080/13658816.2013.865189,6.33,-0.51
1,31,45.0,2009,Article,Land-use-change modeling using unbalanced support-vector machines,"Modeling land-use change is a prerequisite to understanding the complexity of land-use-change patterns. This paper presents a novel method to model urban land-use change using support-vector machines (SVMs), a new generation of machine learning algorithms used in classification and regression domains. An SVM modeling framework has been developed to analyze land-use change in relation to various factors such as population, distance to roads and facilities, and surrounding land use. As land-use data are generally unbalanced, in the sense that the unchanged data overwhelm the changed data, traditional methods are incapable of classifying relatively minor land-use changes with high accuracy. To circumvent this problem, an unbalanced SVM has been adopted by enhancing the standard SVMs. A case study of Calgary land-use change demonstrates that the unbalanced SVMs can achieve high and reliable performance for land-use-change modeling. © 2008 Pion Ltd and its Licensors.",,"Huang B., Xie C., Tay R., Wu B.",10.1068/b33047,7.11,-0.96
-1,37,39.0,2015,Conference Paper,Improving Spatial Feature Representation from Aerial Scenes by Using Convolutional Networks,"The performance of image classification is highly dependent on the quality of extracted features. Concerning high resolution remote image images, encoding the spatial features in an efficient and robust fashion is the key to generating discriminatory models to classify them. Even though many visual descriptors have been proposed or successfully used to encode spatial features of remote sensing images, some applications, using this sort of images, demand more specific description techniques. Deep Learning, an emergent machine learning approach based on neural networks, is capable of learning specific features and classifiers at the same time and adjust at each step, in real time, to better fit the need of each problem. For several task, such image classification, it has achieved very good results, mainly boosted by the feature learning performed which allows the method to extract specific and adaptable visual features depending on the data. In this paper, we propose a novel network capable of learning specific spatial features from remote sensing images, with any pre-processing step or descriptor evaluation, and classify them. Specifically, automatic feature learning task aims at discovering hierarchical structures from the raw data, leading to a more representative information. This task not only poses interesting challenges for existing vision and recognition algorithms, but also brings huge opportunities for urban planning, crop and forest management and climate modelling. The propose convolutional neural network has six layers: three convolutional, two fully-connected and one classifier layer. So, the five first layers are responsible to extract visual features while the last one is responsible to classify the images. We conducted a systematic evaluation of the proposed method using two datasets: (i) the popular aerial image dataset UCMerced Land-use and, (ii) a multispectral high-resolution scenes of the Brazilian Coffee Scenes. The experiments show that the proposed method outperforms state-of-the-art algorithms in terms of overall accuracy. © 2015 IEEE.",Deep Learning; Feature Learning; High-resolution Images; Image Classification; Machine Learning; Remote Sensing,"Nogueira K., Miranda W.O., Santos J.A.D.",10.1109/SIBGRAPI.2015.39,6.7,2.79
-1,41,36.0,2017,Article,Building block level urban land-use information retrieval based on Google Street View images,"Land-use maps are important references for urban planning and urban studies. Given the heterogeneity of urban land-use types, it is difficult to differentiate different land-use types based on overhead remotely sensed data. Google Street View (GSV) images, which capture the façades of building blocks along streets, could be better used to judge the land-use types of different building blocks based on their façade appearances. Recently developed scene classification algorithms in computer vision community make it possible to categorize different photos semantically based on various image feature descriptors and machine-learning algorithms. Therefore, in this study, we proposed a method to derive detailed land-use information at building block level based on scene classification algorithms and GSV images. Three image feature descriptors (i.e., scale-invariant feature transform-Fisher, histogram of oriented gradients, GIST) were used to represent GSV images of different buildings. Existing land-use maps were used to create training datasets to train support vector machine (SVM) classifiers for categorizing GSV images. The trained SVM classifiers were then applied to case study areas in New York City, Boston, and Houston, to predict the land-use information at building block level. Accuracy assessment results show that the proposed method is suitable for differentiating residential buildings and nonresidential buildings with an accuracy of 85% or so. Since the GSV images are publicly accessible, this proposed method would provide a new way for building block level land-use mapping in future. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",GSV (Google Street View); image features; machine learning; urban land-use mapping,"Li X., Zhang C., Li W.",10.1080/15481603.2017.1338389,5.56,0.39
1,53,30.0,2017,Article,Land-cover classification and analysis of change using machine-learning classifiers and multi-temporal remote sensing imagery,"Frequent human activity and rapid urbanization have led to an assortment of environmental issues. Monitoring land-cover change is critical to efficient environmental management and urban planning. The current study had two objectives. The first was to compare pixel-based random forest (RF) and decision tree (DT) classifier methods and a support vector machine (SVM) algorithm both in pixel-based and object-based approaches for classification of land-cover in a heterogeneous landscape for 2010. The second was to examine spatio-temporal land-cover change over the last two decades (1990–2010) using Landsat data. This study found that the object-based SVM classifier is the most accurate with an overall classification accuracy of 93.54% and a kappa value of 0.88. A post-classification change detection algorithm was used to determine the trend of change between land-cover classes. The most significant change from 1990 to 2010 was caused by the expansion of built-up areas. In addition to the net changes, the rate of annual change for each phenomenon was calculated to obtain a better understanding of the process of change. Between 1990 and 2010, an average of 4.53% of lands turned to the built-up annually and there was an annual decrease of about 0.81% in natural land. If the current trend of change continues, regardless of the actions of sustainable development, drastic declines in natural areas will ensue. The results of this study can be a valuable baseline for land-cover managers in the region to better understand the current situation and adopt appropriate strategies for management of land-cover. © 2017, Saudi Society for Geosciences.",Decision tree; Land-cover; Object-based; Random forest; Support vector machines,"Keshtkar H., Voigt W., Alizadeh E.",10.1007/s12517-017-2899-y,7.75,0.09
0,54,30.0,2016,Article,Building detection from orthophotos using a machine learning approach: An empirical study on image segmentation and descriptors,"Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling. © 2016 Elsevier Ltd. All rights reserved.",Automatic building detection and delineation; Classifier; Image descriptors; Image segmentation; Orthophotos; Supervised learning,"Dornaika F., Moujahid A., El Merabet Y., Ruichek Y.",10.1016/j.eswa.2016.03.024,5.3,1.52
-1,56,29.0,2016,Article,A supervoxel-based spectro-spatial approach for 3D urban point cloud labelling,"ABSTRACT: Three-dimensional (3D) point cloud labelling of airborne lidar (light detection and ranging) data has promising applications in urban city modelling. Automatic and efficient methods for semantic labelling of airborne urban point cloud data with multiple classes still remains a challenge. We propose a novel 3D object-based classification framework for labelling urban lidar point cloud using a computer vision technique, supervoxels. The supervoxel approach is promising for representing dense lidar point cloud in a compact manner for 3D segmentation and for improving the computational efficiency. Initially, supervoxels are generated by over-segmenting the coloured point cloud using the voxel-based cloud connectivity algorithm in the geometric space. The local connectivity established between supervoxels has been used to produce meaningful and realistic objects (segments). The segments are classified by different machine learning techniques based on several spectral and geometric features extracted from the segments. All the points within a labelled segment are assigned the same segment label. Furthermore, the effect of different feature vectors and varying point density on the classification accuracy has been studied. Results indicate an accurate labelling of points in realistic 3D space conforming to the boundaries of objects. An overall classification accuracy of 90% is achieved by the proposed method. The labelled 3D points can be used directly for the reconstruction of buildings and other man-made objects. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",,"Ramiya A.M., Nidamanuri R.R., Ramakrishnan K.",10.1080/01431161.2016.1211348,4.75,1.47
-1,58,28.0,2006,Article,An adaptive and iterative method of urban area extraction from SAR images,"This letter presents a new method for unsupervised urban area extraction from synthetic aperture radar (SAR) images based on the ffmax algorithm proposed by C. Gouinaud specially for acquiring urban areas in SPOT imagery. According to the statistical characteristics of urban areas, an adaptive and iterative method based on the low-level extraction given by the ffmax algorithm using a large window is proposed. Experimental results on real SAR images show that the proposed automatic method works quickly and can preserve the borders of urban areas as well as avoid the disturbance of other classes and the extractions of urban areas are reliable and precise. © 2006 IEEE.",Adaptive and iterative (AI); Ffmax algorithm; Synthetic aperture radar (SAR) image; Urban area extraction,"He C., Xia G.-S., Sun H.",10.1109/LGRS.2006.878447,5.98,0.36
-1,61,27.0,2007,Conference Paper,Conditional random field for 3D point clouds with adaptive data reduction,"We proposed using Conditional Random Fields with adaptive data reduction for the classification of 3D point clouds acquired from a Riegl Terrestrial laser scanner. The training and inference of the acquired large outdoor urban data can be time consuming. We approach the problem by computing an adaptive support region for each data point using 3D scale theory. For training and inference of the discriminative Conditional Random Fields, smaller set of data samples that contains relevant information within the support region is selected instead of using all point cloud data. We tested the algorithm on synthetically generated data and urban point clouds data acquired from the laser scanner. The computed support region is also used in feature extraction for urban point clouds data. The results showed improvement in the training and inference rate while maintaining comparable classification accuracy. © 2007 IEEE.",Classifications; Conditional random fields; LIDAR data; Machine learning; Scale theory,"Lim E.H., Suter D.",10.1109/CW.2007.24,4.74,1.54
-1,63,26.0,2019,Article,Support Vector Machine accuracy assessment for extracting green urban areas in towns,"The most commonly used model for analyzing satellite imagery is the Support Vector Machine (SVM). Since there are a large number of possible variables for use in SVM, this paper will provide a combination of parameters that fit best for extracting green urban areas from Copernicus mission satellite images. This paper aims to provide a combination of parameters to extract green urban areas with the highest degree of accuracy, in order to speed up urban planning and ultimately improve town environments. Two different towns in Croatia were investigated, and the results provide an optimal combination of parameters for green urban areas extraction with an overall kappa index of 0.87 and 0.89, which demonstrates a very high classification accuracy. © 2019 by the authors.",Green urban areas extraction; Kernels; Machine learning; Satellite images; Support vector machine,"Kranjčić N., Medak D., Župan R., Rezo M.",10.3390/rs11060655,6.21,0.13
-1,64,26.0,2016,Article,Land Classification Using Remotely Sensed Data: Going Multilabel,"Obtaining an up-to-date high-resolution description of land cover is a challenging task due to the high cost and labor-intensive process of human annotation through field studies. This work introduces a radically novel approach for achieving this goal by exploiting the proliferation of remote sensing satellite imagery, allowing for the up-to-date generation of global-scale land cover maps. We propose the application of multilabel classification, a powerful framework in machine learning, for inferring the complex relationships between the acquired satellite images and the spectral profiles of different types of surface materials. Introducing a drastically different approach compared to unsupervised spectral unmixing, we employ contemporary ground-collected data from the European Environment Agency to generate the label set and multispectral images from the MODIS sensor to generate the spectral features, under a supervised classification framework. To validate the merits of our approach, we present results using several state-of-the-art multilabel learning classifiers and evaluate their predictive performance with respect to the number of annotated training examples, as well as their capability to exploit examples from neighboring regions or different time instances. We also demonstrate the application of our method on hyperspectral data from the Hyperion sensor for the urban land cover estimation of New York City. Experimental results suggest that the proposed framework can achieve excellent prediction accuracy, even from a limited number of diverse training examples, surpassing state-of-the-art spectral unmixing methods. © 2016 IEEE.",CORINE; data processing; land cover; MODIS; pattern classification; remote sensing; satellite applications; time series; unmixing,"Karalas K., Tsagkatakis G., Zervakis M., Tsakalides P.",10.1109/TGRS.2016.2520203,7.67,1.47
1,68,24.0,2017,Article,Analyzing land cover change and urban growth trajectories of the mega-urban region of Dhaka using remotely sensed data and an ensemble classifier,"Accurate information on, and human interpretation of, urban land cover using satellite-derived sensor imagery is critical given the intricate nature and niches of socioeconomic, demographic, and environmental factors occurring at multiple temporal and spatial scales. Detailed knowledge of urban land and their changing pattern over time periods associated with ecological risk is, however, required for the best use of critical land and its environmental resources. Interest in this topic has increased recently, driven by a surge in the use of open-source computing software, satellite-derived imagery, and improved classification algorithms. Using the machine learning algorithm Random Forest, combined with multi-date Landsat imagery, we classified eight periods of land cover maps with up-to-date spatial and temporal information of urban land between the period of 1972 and 2015 for the mega-urban region of greater Dhaka in Bangladesh. Random Forest-a non-parametric ensemble classifier-has shown a quantum increase in satellite-derived image classification accuracy due to its outperformance over traditional approaches, e.g., Maximum Likelihood. Employing Random Forest as an image classification approach for this study with independent cross-validation techniques, we obtained high classification accuracy, user and producer accuracy. Our overall classification accuracy ranges were between 85% and 97% with kappa values between 0.81 and 0.94. The area statistics derived from the thematic land cover map show that the built-up area in the 43-year study period expanded quickly, from 35 km2 in 1972 to 378 km2 in 2015, with a net increase rate of approximately 980% and an average annual growth rate of 6%. This growth rate, however, was higher in peripheral areas, with a 2903% increase and an annual expansion rate of 8%, compared to a 460% increase with an annual growth rate of 4% in the core city area (Dhaka City Corporation). This huge urban expansion took place in the north, northwest, and southwest regions of Dhaka, transforming areas that were previously agricultural land, vegetation cover, wetland, and water bodies. The main factors driving the city towards northern corridors include flood-free higher land, the availability of a transportation network, and the agglomeration of manufacturing-based employment centers. The resulting thematic map and spatial information produced from this study therefore serve to facilitate a detailed understanding of urban growth dynamics and land cover change patterns in the mega-urban region of Dhaka, Bangladesh. © 2017 by the authors.",Ensemble classifier; Greater Dhaka; Land cover change; Random forest; Remote sensing; Urban growth,"Hassan M.M., Southworth J.",10.3390/su10010010,7.62,0.12
-1,70,24.0,2014,Article,Driving forces analysis of urban expansion based on boosted regression trees and Logistic regression,"The rapid relentless urban area expansion has led to a series of problems in China. Many researches focused on this issue in recent years. Driving forces are the core topic in urban expansion,as well as the basic component of modeling and predicting. It is very useful and meaningful to analyze the driving force of urban expansion, which may provide us with a scientific basis to rationally utilize land resources, determining the law of urban development, researching the evolution process, predicting the urban expansion trends, and also providing guidance for the development of rational control policies. The Shenyang city was chosen as study area. Eight categories of land use types were extracted from remote sensing images (1997 and 2010) with ArcGIS software. Ten driving forces were chosen, including three natural factors, three distance factors, four social and economic factors. which were calculated based on the land use maps, DEM, topographic maps, zoning maps and the statistical yearbooks. The dependent variable was the change of built-up area of Shenyang from 1997 to 2010. Boosted regression trees (BRT) is an ensemble method and is a combination of techniques between statistical and machine learning traditions that has shown to be effective to identify relationships between results and influencing factors. Logistic regression is a method to discover the empirical relationships between a binary dependent and several independent categorical and continuous variables. Boosted Regression Trees and Logistic regression were used to analyze the main driving force of urban expansion synthetically. The result illustrated the relative influence of driving factors was followed by distance from urban area of 1997, distance from river, DEM, distance from highway and railway, land use types, development plan, GDP, population density, aspect, and slope based on BRT analysis. According to Logistic regression analysis, the relative influence of important factors was followed by development zone, distance from urban land of 1997, DEM, distance from highway and railway, population density, distance from river, rural residential areas and slope. The most important driving forces affecting the expansion of Shenyang are distance from urban area of 1997, DEM, distance from highway and railway. Meanwhile, they were all located in the top four of the main factors. The results revealed that the distance factors were the most important factors, and the total contribution rate of relative influence was up to 61.4%. It is demonstrated distance factors are the main driving forces of urban expansion. Natural factorswere less important, but the relative influence of DEM was important, and the contribution rate was 12.5%. Development zones and rural settlements are the only two factors have much influence in the socio-economic factors. On the whole, location factors, which refer to the distance from urban land in this study, were the leading factors of urban expansion. Natural factors, such as DEM, rivers and so on, are the basis of urban development, determining the overall urban spatial form. The construction of infrastructures, such as roads and railways, are the frame of the city. The social and economic factors decided the speed of urban expansion. Urban planning and development zone construction provided the direction of urban expansion.",Boosted regression trees; Driving forces; Logistic regression; Shenyang city; Urban expansion,"Li C.L., Liu M., Hu Y.M., Xu Y.Y., Sun F.Y.",10.5846/stxb201212121790,7.79,-1.56
-1,71,23.0,2020,Review,Change detection based on artificial intelligence: State-of-the-art and challenges,"Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field. © 2020 by the authors.",Artificial intelligence; Change detection; Deep learning; Hyperspectral; Multispectral; Neural network; Remote sensing; SAR; Street view; Unsupervised learning,"Shi W., Zhang M., Zhang R., Chen S., Zhan Z.",10.3390/rs12101688,6.54,1.43
-1,72,23.0,2020,Article,Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review,"Remote sensing (RS) systems have been collecting massive volumes of datasets for decades, managing and analyzing of which are not practical using common software packages and desktop computing resources. In this regard, Google has developed a cloud computing platform, called Google Earth Engine (GEE), to effectively address the challenges of big data analysis. In particular, this platform facilitates processing big geo data over large areas and monitoring the environment for long periods of time. Although this platform was launched in 2010 and has proved its high potential for different applications, it has not been fully investigated and utilized for RS applications until recent years. Therefore, this study aims to comprehensively explore different aspects of the GEE platform, including its datasets, functions, advantages/limitations, and various applications. For this purpose, 450 journal articles published in 150 journals between January 2010 and May 2020 were studied. It was observed that Landsat and Sentinel datasets were extensively utilized by GEE users. Moreover, supervised machine learning algorithms, such as Random Forest, were more widely applied to image classification tasks. GEE has also been employed in a broad range of applications, such as Land Cover/land Use classification, hydrology, urban planning, natural disaster, climate analyses, and image processing. It was generally observed that the number of GEE publications have significantly increased during the past few years, and it is expected that GEE will be utilized by more users from different fields to resolve their big data processing challenges. © 2008-2012 IEEE.",Big data; cloud computing; Google Earth Engine (GEE); remote sensing (RS),"Amani M., Ghorbanian A., Ahmadi S.A., Kakooei M., Moghimi A., Mirmazloumi S.M., Moghaddam S.H.A., Mahdavi S., Ghahremanloo M., Parsian S., Wu Q., Brisco B.",10.1109/JSTARS.2020.3021052,8.0,0.74
-1,74,23.0,2015,Article,Performance analysis of radial basis function networks and multi-layer perceptron networks in modeling urban change: a case study,"The majority of cities are rapidly growing. This makes the monitoring and modeling of urban change’s spatial patterns critical to urban planners, decision makers, and environment protection activists. Although a wide range of methods exists for modeling and simulating urban growth, machine learning (ML) techniques have received less attention despite their potential for producing highly accurate predictions of future urban extents. The aim of this study is to investigate two ML techniques, namely radial basis function network (RBFN) and multi-layer perceptron (MLP) networks, for modeling urban change. By predicting urban change for 2010, the models’ performance is evaluated by comparing results with a reference map and by using a set of pertinent statistical measures, such as average spatial distance deviation and figure of merit. The application of these techniques employs the case study area of Mumbai, India. The results show that both models, which were tested using the same explanatory variables, produced promising results in terms of predicting the size and extent of future urban areas. Although a close match between RBFN and MLP is observed, RBFN demonstrates higher spatial accuracy of prediction. Accordingly, RBFN was utilized to simulate urban change for 2020 and 2030. Overall, the study provides evidence that RBFN is a robust and efficient ML technique and can therefore be recommended for land use change modeling. © 2015, © 2015 Taylor & Francis.",GIS; multi-layer perceptron network; radial basis function network; spatial accuracy assessment; urban change,"Shafizadeh-Moghadam H., Hagenauer J., Farajzadeh M., Helbich M.",10.1080/13658816.2014.993989,7.56,-1.41
1,76,22.0,2018,Article,A Random Forests classification method for urban land-use mapping integrating spatial metrics and texture analysis,"Rapid urban growth in developing countries is causing a great number of urban planning problems. To control and analyse this growth, new and better methods for urban land use mapping are needed. This article proposes a new method for urban land-use mapping, which integrates spatial metrics and texture analysis in an object-based image analysis classification. A high-resolution satellite image was used to generate spatial and texture metrics from the machine learning algorithm of Random Forests landcover classification. The most meaningful spatial indices were selected by visual inspection and then combined with the image and texture values to generate the classification. The proposed method for land-use mapping was tested using a 10-fold crossvalidation scheme, achieving an overall accuracy of 92.3% and a kappa coefficient of 0.896. These steps produced an accurate model of urban land use, without the use of any census or ancillary data, and suggest that the combined use of spatial metrics and texture is promising for urban land-use mapping in developing countries. The maps produced can provide the landuse data needed by urban planners for effective planning in developing countries. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,"Ruiz Hernandez I.E., Shi W.",10.1080/01431161.2017.1395968,7.46,0.35
1,77,22.0,2010,Article,Urban land cover and land use classification of an informal settlement area using the open-source knowledge-based system InterIMAGE,"This study uses the InterIMAGE system and imagery from the Quick Bird sensor for land cover and land use classification at two test sites with informal settlements in the metropolis of São Paulo, Brazil. InterIMAGE is an open source and free access system for knowledge-based image classification. Within InterIMAGE human knowledge is represented as a semantic net and by user-defined rules based on the paradigms of object-oriented image analysis. In the land cover classification step, a genetic algorithm was used for determining appropriate segmentation parameters. For the description of the land cover classes in terms of features and thresholds, a strategy combining machine learning algorithms and a semantic net was elaborated. Based on the land cover classifications, the land use classifications were carried out considering the urban blocks of the test sites as the analysis units. Customized features related to the composition and geometrical structures of the land cover objects within these blocks were used for the description of the land use classes. The proposed methodology has been shown to be efficient for the automatic mapping of the land cover and land use in complex urban areas. The land cover classifications achieved overall accuracies above 70 percent and Kappa indexes above 0.65. Referring to the land use classifications, overall accuracies above 87 percent and Kappa indexes above 0.71 were obtained. This study has explored the main functionalities of the InterIMAGE system, presenting its potential for object-based and knowledge-based image classification. © 2010 Surveying and Spatial Sciences Institute and Mapping Sciences Institute, Australia.",Informal settlements; InterIMAGE; Knowledge-based image classification; Urban land cover; Urban land use; Urban planning,"Novack T., Kux H.J.H.",10.1080/14498596.2010.487640,6.98,0.27
0,81,21.0,2019,Article,Building extraction from LiDAR data applying deep convolutional neural networks,"Deep learning paradigm has been shown to be a very efficient classification framework for many application scenarios, including the analysis of Light Detection and Ranging (LiDAR) data for building detection. In fact, deep learning acts as a set of mathematical transformations, encoding the raw input data into appropriate forms of representations that maximize the classification performance. However, it is clear that mathematical computations alone, even highly nonlinear, are not adequate to model the physical properties of a problem, distinguishing, for example, the building structures from vegetation. In this letter, we address this difficulty by augmenting the raw LiDAR data with features coming from a physical interpretation of the information. Then, we exploit a deep learning paradigm based on a convolutional neural network model to find out the best input representations suitable for the classification. As test sites, three complex urban study areas with various kinds of building structures through the LiDAR data set of Vaihingen, Germany were selected. Our method has been evaluated in the context of 'ISPRS Test Project on Urban Classification and 3-D Building Reconstruction.' Comparisons with traditional methods, such as artificial neural networks and support vector machine-based classifiers, indicate the outperformance of the proposed approach in terms of robustness and efficiency. © 2004-2012 IEEE.",Building classification; convolutional neural networks (CNNs); Light Detection and Ranging (LiDAR); machine learning; point cloud,"Maltezos E., Doulamis A., Doulamis N., Ioannidis C.",10.1109/LGRS.2018.2867736,5.25,1.94
1,84,21.0,2016,Article,Modeling Urban Land Use Changes Using Support Vector Machines,"Support Vector Machines (SVM) is a machine learning (ML) algorithm commonly applied to the classification of remotely sensing data and more recently for modeling land use changes. However, in most geospatial applications the current literature does not elaborate on specifications of the SVM method with respect to data sampling, attribute selection and optimal parameters choices. Therefore the main objective of this study is to present and investigate the SVM technique for modeling urban land use change. The SVM model building procedure is presented together with the detailed evaluation of the output results with respect to the choice of datasets, attributes and the change of SVM parameters. Geospatial datasets containing nine land use classes and spatial attributes for the Municipality of Zemun, Republic of Serbia were used for years 2001, 2003, 2007 and 2011. The Correlation-based Feature Subset method, kappa coefficient, Area Under Receiver Operating Characteristic Curve (AUC) and kappa simulation were used to perform the model evaluation and compare the model outputs with the real land use datasets. The obtained results indicate that the SVM-based models perform better when implementing balanced data sampling, reduced data sets to informative subsets of attributes and properly identify the optimal learning parameters. © 2015 John Wiley & Sons Ltd",,"Samardžić-Petrović M., Dragićević S., Kovačević M., Bajat B.",10.1111/tgis.12174,7.17,-0.76
-1,90,19.0,2019,Article,"Spatiotemporal detection of land use/land cover change in the large basin using integrated approaches of remote sensing and GIS in the Upper Awash basin, Ethiopia","Assessment of the changing environmental conditions is essential for planning the wise use of natural resources. The main objective of this paper is to analyze the historical and future modeled LULC changes using multi-temporal Landsat images in the Upper Awash basin, Ethiopia. The supervised image classification method was used to determine the historical LULC changes based on Landsat 1 MSS 1972, Landsat 5 TM 1984, Landsat 7 ETM + 2000, and Landsat 8 OLI TIRS 2014. The future LULC change was predicted using the machine-learning approaches of Land Change Modeler (LCM). The LULC change detection analysis exhibited significant increment in the areal extent of the cropland and urban areas, and decreasing trends in the pasture, forests and shrubland coverage. Mainly, the LULC change matrices indicated that larger conversion rate was observed from shrubland to cropland area. The urban area found to increase by 606.2% from the year 1972 to 2014 and cropland has also increased by 47.3%. Whereas, a decreasing trend was obtained in the forest by − 25.1%, pasture − 87.4%, shrubland − 28.8% and water − 21.0% in the same period. The modeled future LULC change scenarios of the year 2025 and 2035 have exhibited significant expansion of cropland and urban areas at the expense of forest, pasture and shrubland areas. The study has revealed the extent and the rate of LULC change at larger basin and subbasin level which can be useful for knowledge-based future land management practice in the Upper Awash basin. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Agricultural expansion; Classification accuracy; Land change modeler; Land cover change; Upper Awash basin; Urban sprawl,"Shawul A.A., Chakma S.",10.1007/s12665-019-8154-y,7.68,-0.09
-1,96,17.0,2018,Article,Predicting multiple land use transitions under rapid urbanization and implications for land management and urban planning: The case of Zhanggong District in central China,"Numerous machine learning-based land change models have been presented by researchers over the last two decades. To date, however, far less have simulated multiple land use classes and specific land use subclasses at the same time. In some areas of the world, it is important to simulate both of these dynamics to understand fully the drivers and consequences of land change. One important example is the process of urbanization in China, as urban policies have been developed that guide urban expansion, rural protections, and urban subclass development. This paper presents a new model integrating geographic information systems (GIS) with artificial neural networks (ANNs) to predict multiple transitions among land use types and urban subclasses in the Zhanggong District of Ganzhou city in China. We show that the model produces satisfactory goodness of fit values-based on location, quantity and spatial configuration-between simulated and observed land use maps for 2015. Our simulated future maps produced by the model for 2020 and 2025 demonstrate that transitions from farmland and forest to urban will remain the main pathway of urbanization although we predict that the rate will slow after 2025. The goals of urban planning should be aligned with land use planning according to “Combining multiple laws and regulations” in China. Taking into account the current and future land use transitions will enhance the accuracy and timeliness of land use policy making and urban land planning. For the sustainable land use in Zhanggong District, we argue for a strengthened regulation of the land market by government and believe that planning officials should guide the spatial distribution of land supply actively. Furthermore, improving the production, living and ecological functions of land resources are the key points to optimize urban land use functions and the allocation of land resources. We discuss how our model can be adapted to other areas to benefit land use management and urban planning in China. © 2018 Elsevier Ltd",Artificial neural networks; China; Land use management; Multiple land use transitions; Urban planning; Urbanization,"Wang L., Pijanowski B., Yang W., Zhai R., Omrani H., Li K.",10.1016/j.habitatint.2018.08.007,7.96,-1.31
0,99,16.0,2020,Article,Local climate zone mapping as remote sensing scene classification using deep learning: A case study of metropolitan China,"China, with the world's largest population, has gone through rapid development in the last forty years and now has over 800 million urban citizens. Although urbanization leads to great social and economic progress, they may be confronted with other issues, including extra heat and air pollution. Local climate zone (LCZ), a new concept developed for urban heat island research, provides a standard classification system for the urban environment. LCZs are defined by the context of the urban environment; the minimum diameter of an LCZ is expected to be 400–1,000 m so that it can have a valid effect on the urban climate. However, most existing methods (e.g., the WUDAPT method) regard this task as pixel-based classification, neglecting the spatial information. In this study, we argue that LCZ mapping should be considered as a scene classification task to fully exploit the environmental context. Fifteen cities covering 138 million population in three economic regions of China are selected as the study area. Sentinel-2 multispectral data with a 10 m spatial resolution are used to classify LCZs. A deep convolutional neural network composed of residual learning and the Squeeze-and-Excitation block, namely the LCZNet, is proposed. We obtained an overall accuracy of 88.61% by using a large image (48×48 corresponding to 480×480 m2) as the representation of an LCZ, 7.5% higher than that using a small image representation (10×10) and nearly 20% higher than that obtained by the standard WUDAPT method. Image sizes from 32×32 to 64×64 were found suitable for LCZ mapping, while a deeper network achieved better classification with larger inputs. Compared with natural classes, urban classes benefited more from a large input size, as it can exploit the environment context of urban areas. The combined use of the training data from all three regions led to the best classification, but the transfer of LCZ models cannot achieve satisfactory results due to the domain shift. More advanced domain adaptation methods should be applied in this application. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Convolutional neural network; Local climate zone; Metropolitan China; Scene classification; Urban climate,"Liu S., Shi Q.",10.1016/j.isprsjprs.2020.04.008,6.88,2.61
0,100,16.0,2019,Article,Multiscale road centerlines extraction from high-resolution aerial imagery,"Accurate road extraction from high-resolution aerial imagery has many applications such as urban planning and vehicle navigation system. The common road extraction methods are based on classification algorithm, which needs to design robust handcrafted features for road. However, designing such features is difficult. For the road centerlines extraction problem, the existing algorithms have some limitations, such as spurs, time consuming. To address the above issues to some extent, we introduce the feature learning based on deep learning to extract robust features automatically, and present a method to extract road centerlines based on multiscale Gabor filters and multiple directional non-maximum suppression. The proposed algorithm consists of the following four steps. Firstly, the aerial imagery is classified by a pixel-wise classifier based on convolutional neural network (CNN). Specifically, CNN is used to learn features from raw data automatically, especially the structural features. Then, edge-preserving filtering is conducted on the resulting classification map, with the original imagery serving as the guidance image. It is exploited to preserve the edges and the details of the road. After that, we do some post-processing based on shape features to extract more reliable roads. Finally, multiscale Gabor filters and multiple directional non-maximum suppression are integrated to get a complete and accurate road network. Experimental results show that the proposed method can achieve comparable or higher quantitative results, as well as more satisfactory visual performance. © 2018 Elsevier B.V.",Centerlines extraction; Convolutional neural network (CNN); Edge-preserving filtering; Multiscale Gabor filters,"Liu R., Miao Q., Song J., Quan Y., Li Y., Xu P., Dai J.",10.1016/j.neucom.2018.10.036,5.88,1.25
1,102,16.0,2015,Article,Automatic classification of high resolution land cover using a new data weighting procedure: The combination of k-means clustering algorithm and central tendency measures (KMC-CTM),"Information on a well-scale urban land cover is important for a number of urban planning practices involving tree shade mapping, green space analysis, urban hydrologic modeling and urban land use mapping. In this study, an urban land cover dataset received from the database of UCI (University of California at Irvine) machine learning was used as the urban land cover data. This dataset is the urban area located in Deerfield Beach, FL, USA. Separately, this dataset is a high definition atmospheric image consisting of 9 different urban land covers. The characteristics of a multi-scale spectral, magnitude and formal tectology were used to sort out and classify these different images. The dataset comprises a total of 147 features and land covers of 9 different areas involving trees, grass, soil, concrete, asphalt, buildings, cars, pools and shadows. A new data weighting method was recommended to classify these 9 different patterns automatically. This recommended data weighting method is based on the combination of the measures of central tendency composed of mean value, harmonic value, mode and median along with the k-means clustering method. In the data weighting method, the data sets belonging to each class within the dataset are first calculated by using k-means clustering method, after which the measures of central tendency belonging to each class are calculated, as well. The measure of central tendency belonging to each class is divided by the set central value belonging to the class in question, as the result of which the data weight coefficient of that class has already been calculated. This calculation process is performed separately for 9 different land covers, and afterwards, these data weighting coefficients found are multiplied by the dataset, and thus, the dataset has been weighted. In the second stage, on the other hand, 3 different classification algorithms containing k-NN (k-nearest neighbor), extreme learning machine (ELM) and support vector machine (SVM) were used to classify 9 different urban land covers after the data weighting method. In determining the educational and test data sets, the 10-fold cross validation was used. When classification through raw data was performed along with k-NN (for k = 1), ELM and SVM classification algorithms, the overall classification accuracy obtained was 77.15%, 84.70% and 84.79%, respectively. When classification through data weighting method (the combination of k-means clustering and mode measure) along with k-NN (for k = 1), ELM and SVM classification algorithms was made, the overall classification accuracy obtained proved to be 98.58%, 98.62% and 98.77%, respectively. The obtained results suggest that the urban land cover in an atmospheric image via the recommended data weighting method was classified as 9 different areas with a high classification success rate. © 2015 Elsevier B.V. All rights reserved.",Classification; Data pre-processing; Data weighting; The combination of k-means clustering algorithm and central tendency measures (KMC-CTM); Urban land cover,Durduran S.S.,10.1016/j.asoc.2015.06.025,7.05,0.35
-1,105,15.0,2018,Article,Progressively Expanded Neural Network (PEN Net) for hyperspectral image classification: A new neural network paradigm for remote sensing image analysis,"Hyperspectral image (HSI) has been used for a wide range of applications including forestry, urban planning, and precision agriculture. In recent years, machine learning based algorithms, such as support vector machines, decision trees, ensemble learning, and their variations have shown promising results in HSI analysis. Such methodologies, nevertheless, can lead to insufficient information abstraction in interpreting hyperspectral pixels. In this paper, we propose a novel neural network based classification algorithm, named Progressively Expanded Neural Network (PEN Net), that can effectively interpret hyperspectral pixels in nonlinear feature spaces and then determine their categories. Furthermore, a spectral-spatial HSI classification framework is also introduced to test the generality and robustness of the PEN Net. Experimental results on four standard hyperspectral datasets illustrate that: (1) PEN Net classifier yields better accuracy and competitive processing speed in HSI classification tasks compared to the state-of-the-art methods; (2) Multi-hidden layer based PEN Net generally provides better performance than single hidden layer one; (3) Combination of spectral and spatial features in the PEN Net classifier can significantly improve the classification accuracy by 6–15% compared to the spectral only based HSI classification. This study implies that the proposed neural network architecture opens a new window for future research and the potential for remote sensing image analysis. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Classification; Hyperspectral image (HSI); Machine learning; Neural network; Remote sensing,"Sidike P., Asari V.K., Sagan V.",10.1016/j.isprsjprs.2018.09.007,7.31,1.71
-1,109,14.0,2020,Article,Comparative assessment of machine learning methods for urban vegetation mapping using multitemporal Sentinel-1 imagery,"Mapping of green vegetation in urban areas using remote sensing techniques can be used as a tool for integrated spatial planning to deal with urban challenges. In this context, multitemporal (MT) synthetic aperture radar (SAR) data have not been equally investigated, as compared to optical satellite data. This research compared various machine learning methods using single-date and MT Sentinel-1 (S1) imagery. The research was focused on vegetation mapping in urban areas across Europe. Urban vegetation was classified using six classifiers-random forests (RF), support vector machine (SVM), extreme gradient boosting (XGB), multi-layer perceptron (MLP), AdaBoost. M1 (AB), and extreme learning machine (ELM). Whereas, SVM showed the best performance in the single-date image analysis, the MLP classifier yielded the highest overall accuracy in the MT classification scenario. Mean overall accuracy (OA) values for all machine learning methods increased from 57% to 77% with speckle filtering. Using MT SAR data, i.e., three and five S1 imagery, an additional increase in the OA of 8.59% and 13.66% occurred, respectively. Additionally, using three and five S1 imagery for classification, the F1 measure for forest and low vegetation land-cover class exceeded 90%. This research allowed us to confirm the possibility of MT C-band SAR imagery for urban vegetation mapping. © 2020 by the authors.",Land-cover classification; Multitemporal; Sentinel-1; Speckle filtering; Synthetic aperture radar (SAR); Urban vegetation,"Gašparović M., Dobrinić D.",10.3390/rs12121952,7.25,0.72
-1,110,14.0,2019,Article,Deprivation pockets through the lens of convolutional neural networks,"Machine learning techniques have been frequently applied to map urban deprivation (commonly referred to as slums) in very high-resolution satellite images. Among these, Deep Convolutional Neural Networks have shown exceptional efficiency in automated deprivation mapping at the local scale. Yet these networks have never been used to map very small heterogeneous deprivation areas (pockets) at large scale. This study proposes and evaluates a U-Net-Compound model to map deprivation pockets in Bangalore, India. The model only relies on RGB satellite images with a resolution of 2 m as these are more commonly accessible to local urban planning departments. The experiment assumes a practical situation where only limited reference data is available for the model to learn the spatial morphology of deprivation pockets. It tests whether an updated map of deprivation pockets can be obtained with limited information. The model performance to map a large number of deprivation pockets is examined by incrementally changing the model architecture and the amount of training data. Results show that the proposed model is sensitive to the amount of spatial information contained in the training data. Once sufficient spatial information is learnt through a few samples, the city scale mapping accuracy outperforms existing models in mapping small deprivation pockets, achieving a Jaccard Index of 54%. This study demonstrated that a well-designed convolutional neural network can map the existence, extent, as well as distribution patterns of deprivation pockets at the city scale with limited training data, which is essential for upscaling research outputs to provide important information for the formulation of pro-poor policies. © 2019",Bangalore; Convolutional neural networks; Deep learning; Deprivation pockets; Slums,"Wang J., Kuffer M., Roy D., Pfeffer K.",10.1016/j.rse.2019.111448,6.75,2.12
-1,111,14.0,2018,Article,Road centerline extraction from very-high-resolution aerial image and LiDAR data based on road connectivity,"The road networks provide key information for a broad range of applications such as urban planning, urban management, and navigation. The fast-developing technology of remote sensing that acquires high-resolution observational data of the land surface offers opportunities for automatic extraction of road networks. However, the road networks extracted from remote sensing images are likely affected by shadows and trees, making the road map irregular and inaccurate. This research aims to improve the extraction of road centerlines using both very-high-resolution (VHR) aerial images and light detection and ranging (LiDAR) by accounting for road connectivity. The proposed method first applies the fractal net evolution approach (FNEA) to segment remote sensing images into image objects and then classifies image objects using the machine learning classifier, random forest. A post-processing approach based on the minimum area bounding rectangle (MABR) is proposed and a structure feature index is adopted to obtain the complete road networks. Finally, a multistep approach, that is, morphology thinning, Harris corner detection, and least square fitting (MHL) approach, is designed to accurately extract the road centerlines from the complex road networks. The proposed method is applied to three datasets, including the New York dataset obtained from the object identification dataset, the Vaihingen dataset obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D semantic labelling benchmark and Guangzhou dataset. Compared with two state-of-the-art methods, the proposed method can obtain the highest completeness, correctness, and quality for the three datasets. The experiment results show that the proposed method is an efficient solution for extracting road centerlines in complex scenes from VHR aerial images and light detection and ranging (LiDAR) data. © 2018 by the authors.",LiDAR data; Object recognition; Road centerline; Road connectivity; Very-high-resolution image,"Zhang Z., Zhang X., Sun Y., Zhang P.",10.3390/rs10081284,5.86,1.06
1,112,13.0,2020,Letter,Regional mapping of essential urban land use categories in China: A segmentation-based approach,"Understanding distributions of urban land use is of great importance for urban planning, decision support, and resource allocation. The first mapping results of essential urban land use categories (EULUC) in China for 2018 have been recently released. However, such kind of national maps may not sufficiently meet the growing demand for regional analysis. To address this shortcoming, here we proposed a segmentation-based framework named EULUC-seg to improve the mapping results of EULUC at the city scale. An object-based segmentation approach was first applied to generate the basic mapping units within urban parcels. Multiple features derived from high-resolution remotely sensed and social sensing data were updated and then recalculated within each unit. Random forest was adopted as the machine learning algorithm for classifying urban land use into five Level I classes and twelve Level II classes. Finally, an accuracy assessment was carried out based on a collection of manually interpreted samples. Results showed that our derived map achieved an overall accuracy of 87.58% for Level I, and 73.53% for Level II. The accurate and refined map of EULUC-seg is expected to better support various applications in the future. © 2020, by the authors.",Machine learning; Ningbo; Segmentation; Urban land use,"Tu Y., Chen B., Zhang T., Xu B.",10.3390/rs12071058,8.32,-0.04
1,113,13.0,2019,Article,Evaluation and comparison of eight machine learning models in land use/land cover mapping using Landsat 8 OLI: a case study of the northern region of Iran,"Land use land cover change mapping has been used for monitoring environmental changes as an essential factor to study on the earth’s surface land cover in the field of climate change phenomena such as floods and droughts. Remote sensing images have been suggested to present inexpensive and fine-scale data offering multi-temporal coverage. This tool is useful in the field of environmental monitoring, land-cover mapping, and urban planning. This study aims to evaluate eight machine learning algorithms for image classification implemented in WEKA and R programming language. Firstly, Landsat 8 OLI/TIRS Level-2 images based on eight machine learning techniques including Random Forest, Decision Table, DTNB, J48, Lazy IBK, Multilayer Perceptron, Non-Nested Generalized Exemplars (NN ge), and Simple Logistic are classified. Then, obtained results are compared in term of Overall Accuracy (OA), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) for land use land cover mapping. Among the eight machine learning algorithms used for image classification based on the training and test dataset, NN ge classifier is ranked first with values of 100, 0, and 0 for Overall Accuracy, Mean Absolute Error and Root Mean Squared Error respectively. All machine learning algorithms had an Overall Accuracy of more than 99% for the training dataset. On the other hand, for the test dataset, J48 and DTNB algorithms had the worst performance with values of 88.1188 and 76.9802 respectively for the Overall Accuracy. © 2019, Springer Nature Switzerland AG.",Image classification; LULCC; Machine learning; R statistical packages; WEKA,Jamali A.,10.1007/s42452-019-1527-8,7.31,0.44
0,125,12.0,2018,Article,Object-based detection of vehicles using combined optical and elevation data,"The detection of vehicles is an important and challenging topic that is relevant for many applications. In this work, we present a workflow that utilizes optical and elevation data to detect vehicles in remotely sensed urban data. This workflow consists of three consecutive stages: candidate identification, classification, and single vehicle extraction. Unlike in most previous approaches, fusion of both data sources is strongly pursued at all stages. While the first stage utilizes the fact that most man-made objects are rectangular in shape, the second and third stages employ machine learning techniques combined with specific features. The stages are designed to handle multiple sensor input, which results in a significant improvement. A detailed evaluation shows the benefits of our workflow, which includes hand-tailored features; even in comparison with classification approaches based on Convolutional Neural Networks, which are state of the art in computer vision, we could obtain a comparable or superior performance (F1 score of 0.96–0.94). © 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Cluster analysis; Data fusion; Elevation data; Feature extraction; High-resolution; Object-based classification; Random forest; Vehicle detection,"Schilling H., Bulatov D., Middelmann W.",10.1016/j.isprsjprs.2017.11.023,5.52,2.69
-1,126,12.0,2017,Article,Semi-automatic mapping of anthropogenic impervious surfaces in an urban/suburban area using Landsat 8 satellite data,"Impervious surfaces have a significant impact on urban runoff, groundwater, base flow, water quality, and climate. Increase in Anthropogenic Impervious Surfaces (AIS) for a region is a true representation of urban expansion. Monitoring of AIS in an urban region is helpful for better urban planning and resource management. Cost effective and efficient maps of AIS can be obtained for larger areas using remote sensing techniques. In the present study, extraction of AIS has been carried out using Double window Flexible Pace Search (DFPS) from a new index named as Normalized Difference Impervious Surface Index (NDAISI). NDAISI is developed by enhancing Biophysical Composition Index (BCI) in two stages using a new Modified Normalized Difference Soil Index (MNDSI). MNDSI has been developed from Band 7 and Band 8 (PAN) of Landsat 8 data. In comparison to existing impervious surface extraction methods, the new NDAISI approach is able to improve Spectral Discrimination Index (SDI) for bare soil and AIS significantly. Overall accuracy of mapping of AIS, using NDAISI approach has been found to be increased by nearly 23% when compared with existing impervious surface extraction methods. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",BCI; DFPS; HPF resolution merge; MNDSI; NDAISI,"Piyoosh A.K., Ghosh S.K.",10.1080/15481603.2017.1282414,6.95,-0.06
-1,137,11.0,2014,Article,Ensemble methods for binary classifications of airborne LIDAR data,"This paper presents a framework that is aimed at improving the performance of two existing ensemble methods (namely, AdaBoost and Bagging) for airborne light detection and ranging (LIDAR) classification. LIDAR is one of the fastest growing technologies to support a multitude of civil engineering applications, such as transportation, urban planning, flood control, and city 3D reconstruction. For the above applications, LIDAR data need to be classified into binary classes (i.e., terrain and nonterrain) or multiple classes (e.g., ground, vegetation, and buildings). The proposed framework is designed to enhance the generalization performance of binary classification approach by minimizing type II errors. The authors developed and tested the framework on different LIDAR data sets representing geographic sites in Germany and the United States. The results showed that the proposed ensemble framework performed better compared to the existing methods. In addition, the AdaBoost method outperformed the Bagging method on all the terrain types. However, the framework has some limitations in terms of dealing with rough terrain and discontinuous surfaces. © 2014 American Society of Civil Engineers.",Computing; Ensemble method; LIDAR; Machine learning; Remote sensing,"Nourzad S.H.H., Pradhan A.",10.1061/(ASCE)CP.1943-5487.0000276,4.9,1.03
1,139,10.0,2020,Article,Patterns of historical and future urban expansion in Nepal,"Globally, urbanization is increasing at an unprecedented rate at the cost of agricultural and forested lands in peri-urban areas fringing larger cities. Such land-cover change generally entails negative implications for societal and environmental sustainability, particularly in South Asia, where high demographic growth and poor land-use planning combine. Analyzing historical land-use change and predicting the future trends concerning urban expansion may support more effective land-use planning and sustainable outcomes. For Nepal's Tarai region-a populous area experiencing land-use change due to urbanization and other factors-we draw on Landsat satellite imagery to analyze historical land-use change focusing on urban expansion during 1989-2016 and predict urban expansion by 2026 and 2036 using artificial neural network (ANN) and Markov chain (MC) spatial models based on historical trends. Urban cover quadrupled since 1989, expanding by 256 km2 (460%), largely as small scattered settlements. This expansion was almost entirely at the expense of agricultural conversion (249 km2). After 2016, urban expansion is predicted to increase linearly by a further 199 km2 by 2026 and by another 165 km2 by 2036, almost all at the expense of agricultural cover. Such unplanned loss of prime agricultural lands in Nepal's fertile Tarai region is of serious concern for food-insecure countries like Nepal. © 2020 by the author.",Cropland loss; Machine learning models; Markov chain; Urban expansion,"Rimal B., Sloan S., Keshtkar H., Sharma R., Rijal S., Shrestha U.B.",10.3390/rs12040628,7.71,-0.64
0,144,9.0,2019,Conference Paper,Aerial point cloud classification with deep learning and machine learning algorithms,"With recent advances in technology, 3D point clouds are getting more and more frequently requested and used, not only for visualization needs but also e.g. by public administrations for urban planning and management. 3D point clouds are also a very frequent source for generating 3D city models which became recently more available for many applications, such as urban development plans, energy evaluation, navigation, visibility analysis and numerous other GIS studies. While the main data sources remained the same (namely aerial photogrammetry and LiDAR), the way these city models are generated have been evolving towards automation with different approaches. As most of these approaches are based on point clouds with proper semantic classes, our aim is to classify aerial point clouds into meaningful semantic classes, e.g. ground level objects (GLO, including roads and pavements), vegetation, buildings' facades and buildings' roofs. In this study we tested and evaluated various machine learning algorithms for classification, including three deep learning algorithms and one machine learning algorithm. In the experiments, several hand-crafted geometric features depending on the dataset are used and, unconventionally, these geometric features are used also for deep learning. © 2019 E. Özdemir et al.",Classification; Deep learning; Geometric features; Machine learning; Point cloud; Urban areas,"Özdemir E., Remondino F., Golkar A.",10.5194/isprs-archives-XLII-4-W18-843-2019,5.07,1.88
1,147,9.0,2019,Article,Geographic object based image analysis of world view-3 imagery for urban hydrologic modelling at the catchment scale,"China's Sponge City initiative will involve widespread installation of new stormwater infrastructure including green roofs, permeable pavements and rain gardens in at least 30 cities. Hydrologic modelling can support the planning of Sponge Cities at the catchment scale, however, highly detailed spatial data for model input can be challenging to compile from the various authorities, or, if available, may not be sufficiently detailed or updated. Remote sensing methods show great promise for mitigating this challenge due to their ability to efficiently classify satellite images into categories relevant to a specific application. In this study Geographic Object Based Image Analysis (GEOBIA) was applied to WorldView-3 satellite imagery (2017) to create a detailed land cover map of an urban catchment area in Beijing. While land cover classification results based on a Bayesian machine learning classifier alone provided an overall land cover classification accuracy of 63%, the subsequent inclusion of a series of refining rules in combination with supplementary data (including elevation and parcel delineations), yielded the significantly improved overall accuracy of 76%. Results of the land cover classification highlight the limitations of automated classification based on satellite imagery alone and the value of supplementary data and additional rules to refine classification results. Catchment scale hydrologic modelling based on the generated land cover results indicated that 61 to 82% of rainfall volume could be captured for a range of 24 h design storms under varying degrees of Sponge City implementation. © 2019 by the authors.",Geographic object based image analysis; Low impact development; Remote sensing; Sponge city; SWMM; Urban hydrology,"Randall M., Fensholt R., Zhang Y., Jensen M.B.",10.3390/w11061133,6.73,-0.32
0,148,9.0,2019,Conference Paper,Self-supervised feature learning for semantic segmentation of overhead imagery,"Overhead imageries play a crucial role in many applications such as urban planning, crop yield forecasting, mapping, and policy making. Semantic segmentation could enable automatic, efficient, and large-scale understanding of overhead imageries for these applications. However, semantic segmentation of overhead imageries is a challenging task, primarily due to the large domain gap from existing research in ground imageries, unavailability of large-scale dataset with pixel-level annotations, and inherent complexity in the task. Readily available vast amount of unlabeled overhead imageries share more common structures and patterns compared to the ground imageries, therefore, its large-scale analysis could benefit from unsupervised feature learning techniques. In this work, we study various self-supervised feature learning techniques for semantic segmentation of overhead imageries. We choose image semantic inpainting as a self-supervised task [36] for our experiments due to its proximity to the semantic segmentation task. We (i) show that existing approaches are inefficient for semantic segmentation, (ii) propose architectural changes towards self-supervised learning for semantic segmentation, (iii) propose an adversarial training scheme for self-supervised learning by increasing the pretext task's difficulty gradually and show that it leads to learning better features, and (iv) propose a unified approach for overhead scene parsing, road network extraction, and land cover estimation. Our approach improves over training from scratch by more than 10% and ImageNet pre-trained network by more than 5% mIOU. © 2018. The copyright of this document resides with its authors.",,"Singh S., Batra A., Pang G., Torresani L., Basu S., Paluri M., Jawahar C.V.",,6.12,2.57
-1,150,9.0,2018,Article,Ultra-Light aircraft-based hyperspectral and colour-infrared imaging to identify deciduous tree species in an urban environment,"One may consider the application of remote sensing as a trade-off between the imaging platforms, sensors, and data gathering and processing techniques. This study addresses the potential of hyperspectral imaging using ultra-light aircraft for vegetation species mapping in an urban environment, exploring both the engineering and scientific aspects related to imaging platform design and image classification methods. An imaging system based on simultaneous use of Rikola frame format hyperspectral and Nikon D800E adopted colour infrared cameras installed onboard a Bekas X32 manned ultra-light aircraft is introduced. Two test imaging flight missions were conducted in July of 2015 and September of 2016 over a 4000 ha area in Kaunas City, Lithuania. Sixteen and 64 spectral bands in 2015 and 2016, respectively, in a spectral range of 500-900 nm were recorded with colour infrared images. Three research questions were explored assessing the identification of six deciduous tree species: (1) Pre-treatment of spectral features for classification, (2) testing five conventional machine learning classifiers, and (3) fusion of hyperspectral and colour infrared images. Classification performance was assessed by applying leave-one-out cross-validation at the individual crown level and using as a reference at least 100 field inventoried trees for each species. The best-performing classification algorithm-multilayer perceptron, using all spectral properties extracted from the hyperspectral images-resulted in a moderate classification accuracy. The overall classification accuracy was 63%, Cohen's Kappa was 0.54, and the species-specific classification accuracies were in the range of 51-72%. Hyperspectral images resulted in significantly better tree species classification ability than the colour infrared images and simultaneous use of spectral properties extracted from hyperspectral and colour infrared images improved slightly the accuracy over the 2015 image. Even though classifications using hyperspectral data cubes of 64 bands resulted in relatively larger accuracies than with 16 bands, classification error matrices were not statistically different. Alternative imaging platforms (like an unmanned aerial vehicle and a Cessna 172 aircraft) and settings of the flights were discussed using simulated imaging projects assuming the same study area and field of application. Ultra-light aircraft-based hyperspectral and colour-infrared imaging was considered to be a technically and economically sound solution for urban green space inventories to facilitate tree mapping, characterization, and monitoring. © 2018 by the authors.",Classification; Colour infrared; Hyperspectral; Ultra-light aircraft; Urban trees,"Mozgeris G., Juodkiene V., Jonikavičius D., Straigyte L., Gadal S., Ouerghemmi W.",10.3390/rs10101668,7.45,1.17
-1,156,8.0,2020,Article,A locally-constrained YOLO framework for detecting small and densely-distributed building footprints,"Building footprints are among the most predominant features in urban areas, and provide valuable information for urban planning, solar energy suitability analysis, etc. We aim to automatically and rapidly identify building footprints by leveraging deep learning techniques and the increased availability of remote sensing datasets at high spatial resolution. The task is computationally challenging due to the use of large training datasets and large number of parameters. In related work, You-Only-Look-Once (YOLO) is a state-of-the-art deep learning framework for object detection. However, YOLO is limited in its capacity to identify small objects that appear in groups, which is the case for building footprints. We propose a LOcally-COnstrained (LOCO) You-Only-Look-Once framework to detect small and densely-distributed building footprints. LOCO is a variant of YOLO. Its layer architecture is determined by the spatial characteristics of building footprints and it uses a constrained regression modeling to improve the robustness of building size predictions. We also present an invariant augmentation based voting scheme to further improve the precision in the prediction phase. Experiments show that LOCO can greatly improve the solution quality of building detection compared to related work. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",Building detection; deep learning; locally constrained; remote sensing; YOLO,"Xie Y., Cai J., Bhojwani R., Shekhar S., Knight J.",10.1080/13658816.2019.1624761,5.47,2.01
1,166,8.0,2014,Article,Analysis of land use and land cover change in a coastal area of Rio de Janeiro using high-resolution remotely sensed data,"Coastal areas offer great recreational and economic opportunities, but require intensive resource management and environmental protection. Land use and land cover information provides a rapid and cost-effective means for monitoring and planning coastal area development. This study quantitatively describes spatiotemporal changes of land use and land cover over the last four decades in a coastal area of the state of Rio de Janeiro, Brazil. Historical aerial photographs from 1976 and satellite images from 1990 and 2012 were classified and analyzed. We used supervised classification and machine learning techniques to classify the images. An accuracy assessment of results was performed. Land use change statistics for the period indicate that urban areas have increased to the detriment of dense vegetation, salines, and bare soil. The analysis provides a basis for better control of anthropogenic impacts and geoconservation activities in this coastal area of Rio de Janeiro. © 2014 Society of Photo-Optical Instrumentation Engineers.",AdaBoost; coastal environments; land use and land cover change; Regĩo dos Lagos,"Avelar S., Tokarczyk P.",10.1117/1.JRS.8.083631,7.29,0.12
-1,171,7.0,2020,Article,A robust segmentation framework for closely packed buildings from airborne LiDAR point clouds,"Urban villages (UVs) are commonly found in many Asian cities. These villages contain many closely packed buildings constructed decades ago without proper urban planning. There is a need for those buildings to be identified and put into statistics. In this paper, we present a segmentation framework that invokes multiple machine learning techniques and point cloud/image processing algorithms to segment individual closely packed buildings from large urban scenes. The presented framework consists of two major segmentation processes. The framework first filters out the non-ground objects from the point cloud, then it classified them by using the Random Forest classifier to isolate buildings from the entire scene. After that, the building point clouds will be segmented based on several building attribute analysis methods. This is followed by using the Random Sample Consensus (RANSAC) plane filtering method to expand the space between two closely packed buildings, so that the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering technique can be used to more accurately segment each individual building from the closely packed building areas. Two airborne Light Detection and Ranging (LiDAR) datasets collected in two different cities with some typical closely packed buildings were used to verify the proposed framework. The results show that the framework can effectively identify the closely packed buildings with unified structures from large airborne LiDAR datasets. The overall segmentation accuracy reaches 84% for the two datasets. The proposed framework can serve as a basis for analysis and segmentation of closely packed buildings with a more complicated structure. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",,"Wang X., Chan T.O., Liu K., Pan J., Luo M., Li W., Wei C.",10.1080/01431161.2020.1727053,4.82,1.35
-1,172,7.0,2020,Article,Analyzing the spatial factors related to the distributions of building heights in urban areas: A comparative case study in Guangzhou and Shenzhen,"Rapid urbanization has become an increasingly serious issue worldwide. While most previous studies focused on two-dimensional urban development, the spatial characteristics of building heights are rarely explored. Such information could provide valuable implications for smart urban planning and management. However, previous attempts did not systematically investigate the spatial factors that influence building heights and their associations with urban development. Therefore, this study developed a machine learning-based method to compare the distributions of building heights in Guangzhou and Shenzhen, two cities with different development patterns. First, we collected detailed information on the buildings, such as the location and land values. Second, the height of each building was simulated based on the above information using the well-known random forests, k-nearest neighbor algorithm, and artificial neural network. The random forests algorithm outperformed the other two in both cities. We also found that the commercial land value is the most important factor associated with building heights. Moreover, the building heights in Guangzhou are more sensitive to the distances to administrative centers, while the distances to transportation networks exert stronger influences on the building heights in Shenzhen. Overall, these findings could support urban planning and management. More importantly, the proposed method can be used to predict the heights of new buildings and investigate the distributions of building heights in other regions. © 2019 Elsevier Ltd",Building heights; Machine learning; Spatial factors; Urban modeling,"Lin J., Wan H., Cui Y.",10.1016/j.scs.2019.101854,7.79,-1.79
-1,176,7.0,2019,Review,"Landscape Transformations in Rapidly Developing Peri-urban Areas of Accra, Ghana: Results of 30 years","Beyond the loss of peri-urban agricultural and forested land as a result of built-up expansion, not much information exists on the changes in the structure of the peri-urban landscape in Ghana. The aim of this paper is to examine the extent to which urban expansion is driving changes in landscape structure of the peri-urban fringes of Accra.We submit that rapid peri-urbanisation will fragment the existing agricultural and forested landscape with consequent ecological, socio-economic and urban governance implications. Using Landsat satellite images for the years 1985, 1991, 2002 and 2015 the study area was classified into four land cover classes. The study adopted the use of Urban Intensity Index (UII) and the Annual Rate of Urbanization (R) as measures of urbanization. Edge density (ED), largest patch index (LPI) and Aggregation index (AI) were used as proxies to measure landscape structural transformations. The study reveals substantial reductions and fragmentation in agricultural lands, riverine and open forests, while there has been over 200 percent increase in built-up areas. Beyond these revelations in spatiotemporal changes in landscape structure, the paper points to the ecological implications of the changes, and three key socio-economic and urban governance implications. © 2019 G. Ashiagbor et al.",,"Ashiagbor G., Amoako C., Asabere S.B., Quaye-Ballard J.A.",10.1515/geo-2019-0014,7.82,-0.31
-1,177,7.0,2019,Article,Mapping long-term dynamics of population and dwellings based on a multi-temporal analysis of urban morphologies,"Information on the distribution and dynamics of dwellings and their inhabitants is essential to support decision-making in various fields such as energy provision, land use planning, risk assessment and disaster management. However, as various different of approaches to estimate the current distribution of population and dwellings exists, further evidence on past dynamics is needed for a better understanding of urban processes. This article therefore addresses the question of whether and how accurately historical distributions of dwellings and inhabitants can be reconstructed with commonly available geodata from national mapping and cadastral agencies. For this purpose, an approach for the automatic derivation of such information is presented. The data basis is constituted by a current digital landscape model and a 3D building model combined with historical land use information automatically extracted from historical topographic maps. For this purpose, methods of image processing, machine learning, change detection and dasymetric mapping are applied. The results for a study area in Germany show that it is possible to automatically derive decadal historical patterns of population and dwellings from 1950 to 2011 at the level of a 100 m grid with slight underestimations and acceptable standard deviations. By a differentiated analysis we were able to quantify the errors for different urban structure types. © 2018 by the authors.",Dasymetric mapping; Dwelling units; Dynamics; Estimation; Historical demography; Multi-temporal; Population; Topographic maps; Urban morphology; Urban planning,"Hecht R., Herold H., Behnisch M., Jehling M.",10.3390/ijgi8010002,7.54,-1.07
-1,178,7.0,2017,Conference Paper,Deep highway unit network for land cover type classification with GF-3 SAR imagery,"The fully polarized synthetic aperture radar (SAR) is an advanced earth observation system with day and night imaging capability, which can obtain rich information of terrain and has a wide range of applications in environmental protection, urban planning and resource investigation. As the first selfdeveloped C-band multi-polarized SAR image, the acquisition of massive data and operational operation of Chinese SAR remote sensing has entered the era of big data. Under the era of remote sensing large data, however, SAR image interpretation is a great challenge for scientific applications. At present, big data-based intelligent methods such as computer vision technology have achieved great success. Deep learning such as deep highway unit networks has revolutionized the computer vision area. However, due to the characteristics of SAR microwave band imaging and phase coherence processing, SAR images are very different from ordinary optical images in terms of band, projection direction, data composition and so on. Therefore, deep learning can not be directly used for quad-pol SAR image classification. In this paper, deep learning is applied to land cover type classification with GF-3 quad-pol SAR imagery. A deep highway unit network is employed to automatically extract a hierarchic feature representation from the data, based on which the land cover type classification can be conducted. Our classification model is trained on limited training data from forest resource inventory and planning data, and tested on a Radarsat-2 quad-pol images, which is the image of the same area acquired at different times. We also employ the machine learning such as SVM, Random Forest on the same samples for comparison. The deep highway unit network trained by the GF-3 images, which can reduce speckle, fully excavate the regularity of SAR images in time and space. © 2017 IEEE.",Deep highway unit networks; Deep learning; GaoFen-3; Land cover type classification,"Guo Y., Chen E., Guo Y., Li Z., Li C., Xu K.",10.1109/BIGSARDATA.2017.8124926,6.95,1.96
1,182,7.0,2013,Conference Paper,A comparative analysis of the urban web of the greater athens agglomeration for the last 20-years period on the basis of landsat imagery,"Athens, like most of the world's capital cities, is facing a continuous increase in both population and extent. Although the urban growth in Athens can be mostly attributed to the expansion of the residential areas, the total coverage by impervious surfaces in the city has been significantly increased during the last decade due to construction and new development projects that took place during the preparation period of the 2004 Olympic Games. In this study, a 20-year Landsat imagery archive (1988-2007) was used to map the dynamics of urban growth in greater Athens area, based on the urbanization rates. The characterization and quantification of urban land-cover changes was performed by applying urban feature extraction techniques based on machine learning classifiers. Such classifiers use inductive learning algorithms to generate production rules from training data. For results validation, remote sensing data of higher spatial resolution than Landsat were used, i.e. Ikonosand ASTER (Advanced Specaborn Thermal Emission and Reflection Radiometer) images of the greater Athens agglomeration acquired between 2001 and 2007. The validation procedure involved a set of randomly selected points and overall accuracy of 94.8, 93.3 and 95.9 % for the years 2007, 2004 and 2001, respectively, was observed. Analysis of the results revealed continuing growth of urban features in the study area, particularly in the Messogia plain, where the new international airport of El. Venizelos is located, as well as in the western parts of greater Athens, across the Thriassion industrial area. Growth rate of urban areas was found to be variable in time, obtaining its maximum between 2000 and 2004, as expected. The overall increase of the urban areas during the 20-year period was estimated to be about 30%.",Earth observation; Urban growth monitoring; Urban planning.,"Chrysoulakis N., Mitraka Z., Stathopoulou M., Cartalis C.",,6.94,-0.66
0,186,6.0,2019,Conference Paper,Mapping Urban Trees Within Cadastral Parcels Using an Object-Based Convolutional Neural Network,"Urban trees offer significant benefits for improving the sustainability and liveability of cities, but its monitoring is a major challenge for urban planners. Remote-sensing based technologies can effectively detect, monitor and quantify urban tree coverage as an alternative to field-based measurements. Automatic extraction of urban land cover features with high accuracy is a challenging task and it demands artificial intelligence workflows for efficiency and thematic quality. In this context, the objective of this research is to map urban tree coverage per cadastral parcel of Sandy Bay, Hobart from very high-resolution aerial orthophoto and LiDAR data using an Object Based Convolution Neural Network (CNN) approach. Instead of manual preparation of a large number of required training samples, automatically classified Object based image analysis (OBIA) output is used as an input samples to train CNN method. Also, CNN output is further refined and segmented using OBIA to assess the accuracy. The result shows 93.2% overall accuracy for refined CNN classification. Similarly, the overlay of improved CNN output with cadastral parcel layer shows that 21.5% of the study area is covered by trees. This research demonstrates that the accuracy of image classification can be improved by using a combination of OBIA and CNN methods. Such a combined method can be used where manual preparation of training samples for CNN is not preferred. Also, our results indicate that the technique can be implemented to calculate parcel level statistics for urban tree coverage that provides meaningful metrics to guide urban planning and land management practices. © 2019 Authors.",Cadastral Parcel; Convolutional Neural Network; GEOBIA; Machine Learning; Urban Trees,"Timilsina S., Sharma S.K., Aryal J.",10.5194/isprs-annals-IV-5-W2-111-2019,6.79,1.65
-1,197,6.0,2005,Conference Paper,Comparing machine learning classification schemes - A GIS approach,"This project examines the effectiveness of two classification schema: Support Vector Machines (SVM), and Artificial Neural Networks (NN) when applied to geographic (i.e. spatial) data. The context for this study is to examine patterns of urbanization in Mahoning County, OH in relation to several independent driving variables of urban development. These independent variables were constructed using Geographic Information Systems (CIS) and were compared to the dependent variable of the spatial locations of urban areas in Mahoning County. The classification techniques were used in conjunction with the GIS-created variables to predict the location of urban areas within Mahoning County. A comparison of the accuracy of the techniques is presented and conclusions drawn concerning which of the variables are the most influential on urban patterns in the region. Lastly, a spatial analysis of the prediction error is performed for each method. © 2005 IEEE.",,"Lazar A., Shellito B.A.",10.1109/ICMLA.2005.16,7.29,-1.47
-1,202,5.0,2020,Article,Spatiotemporal modeling of urban growth using machine learning,"This paper presents a general framework for modeling the growth of three important variables for cities: population distribution, binary urban footprint, and urban footprint in color. The framework models the population distribution as a spatiotemporal regression problem using machine learning, and it obtains the binary urban footprint from the population distribution through a binary classifier plus a temporal correction for existing urban regions. The framework estimates the urban footprint in color from its previous value, as well as from past and current values of the binary urban footprint using a semantic inpainting algorithm. By combining this framework with free data from the Landsat archive and the Global Human Settlement Layer framework, interested users can get approximate growth predictions of any city in the world. These predictions can be improved with the inclusion in the framework of additional spatially distributed input variables over time subject to availability. Unlike widely used growth models based on cellular automata, there are two main advantages of using the proposed machine learning-based framework. Firstly, it does not require to define rules a priori because the model learns the dynamics of growth directly from the historical data. Secondly, it is very easy to train new machine learning models using different explanatory input variables to assess their impact. As a proof of concept, we tested the framework in Valledupar and Rionegro, two Latin American cities located in Colombia with different geomorphological characteristics, and found that the model predictions were in close agreement with the ground-truth based on performance metrics, such as the root-mean-square error, zero-mean normalized cross-correlation, Pearson's correlation coefficient for continuous variables, and a few others for discrete variables such as the intersection over union, accuracy, and the f1 metric. In summary, our framework for modeling urban growth is flexible, allows sensitivity analyses, and can help policymakers worldwide to assess different what-if scenarios during the planning cycle of sustainable and resilient cities. © 2019 by the authors.",Computer vision; Machine learning; Spatiotemporal modeling; Urban growth; Urban planning tools; Urban science,"Gómez J.A., Patiño J.E., Duque J.C., Passos S.",10.3390/rs12010109,7.38,-1.2
-1,204,5.0,2019,Article,Understanding the spatial distribution of urban forests in China using Sentinel-2 images with Google Earth Engine,"Urban forests are vitally important for sustainable urban development and the well-being of urban residents. However, there is, as yet, no country-level urban forest spatial dataset of sufficient quality for the scientific management of, and correlative studies on, urban forests in China. At present, China attaches great importance to the construction of urban forests, and it is necessary to map a high-resolution and high-accuracy dataset of urban forests in China. The open-access Sentinel images and the Google Earth Engine platform provide a significant opportunity for the realization of this work. This study used eight bands (B2-B8, B11) and three indices of Sentinel-2 in 2016 to map the urban forests of China using the Random Forest machine learning algorithms at the pixel scale with the support of Google Earth Engine (GEE). The 7317 sample points for training and testing were collected from field visits and very high resolution images from Google Earth. The overall accuracy, producer's accuracy of urban forest, and user's accuracy of urban forest assessed by independent validation samples in this study were 92.30%, 92.27%, and 92.18%, respectively. In 2016, the percentage of urban forest cover was 19.2%. Nearly half of the cities had an urban forest cover between 10% and 20%, and the average percentage of large cities whose urban populations were over 5 million was 24.8%. Cities with less than half of the average were mainly distributed in northern and western parts of China, which should be focused on in urban greening planning. © 2019 by the authors.",China; Google Earth Engine; Sentinel-2; Urban area; Urban greening,"Duan Q., Tan M., Guo Y., Wang X., Xin L.",10.3390/f10090729,8.19,0.33
-1,211,5.0,2017,Conference Paper,3D shape descriptor for objects recognition,"3D point cloud classification is an important task in applications for many areas such as robotics, urban planning and augmented reality. 3D sensors measure a high amount of points in the 3D scene objects' surface at a high collect rate, so robust techniques are needed to process all input data and also deal with some imprecision. A common solution for these tasks is the use of robust features extraction techniques to gather representative scene information at the lowest computational cost possible. This paper presents a new approach for object recognition in 3D scenes, using a novel 3D shape descriptor which is used as input for a supervised machine learning method. Proposed robust 3D feature is invariant to translation and scale and provides a very simplified object representation for pattern recognition input. Experiments were performed using an Artificial Neural Network to recognize six different object shapes, and obtained results showed that the proposed method is a promising approach for object recognition in 3D scenes. © 2017 IEEE.",3D Feature Extraction; Object Classification; Pattern Recognition,"Sales D.O., Amaro J., Osório F.S.",10.1109/SBR-LARS-R.2017.8215285,4.83,1.78
0,220,4.0,2021,Article,Attention-Gate-Based Encoder-Decoder Network for Automatical Building Extraction,"Rapidly developing remote sensing technology provides massive data for urban planning, mapping, and disaster management. As a carrier of human productive activities, buildings are essential to both urban dynamic monitoring and suburban construction inspection. Fully-convolutional-network-based methods have provided a paradigm for automatically extracting buildings from high-resolution imagery. However, high intraclass variance and complexity are two problems in building extraction. It is hard to identify different scales of buildings by using a single receptive field. For this purpose, in this article, we use the stable encoder- decoder architecture, combined with a grid-based attention gate and atrous spatial pyramid pooling module, to capture and restore features progressively and effectively. A modified ResNet50 encoder is also applied to extract features. The proposed method could learn gated features and distinguish buildings from complex surroundings such as trees. We evaluate our model on two building datasets, WHU aerial building dataset and our DB UAV rural building dataset. Experiments show that our model outperforms other five most recent models. The results also exhibit great potential for extracting buildings with different scales and validate the effectiveness of deep learning in practical scenarios. © 2008-2012 IEEE.",Attention gate (AG); building extraction; deep learning; fully convolutional networks (FCNs); semantic segmentation,"Deng W., Shi Q., Li J.",10.1109/JSTARS.2021.3058097,5.74,2.32
-1,223,4.0,2020,Article,Using GIS and machine learning to classify residential status of urban buildings in low and middle income settings,"Utilising satellite images for planning and development is becoming a common practice as computational power and machine learning capabilities expand. In this paper, we explore the use of satellite image derived building footprint data to classify the residential status of urban buildings in low and middle income countries. A recently developed ensemble machine learning building classification model is applied for the first time to the Democratic Republic of the Congo, and to Nigeria. The model is informed by building footprint and label data of greater completeness and attribute consistency than have previously been available for these countries. A GIS workflow is described that semiautomates the preparation of data for input to the model. The workflow is designed to be particularly useful to those who apply the model to additional countries and use input data from diverse sources. Results show that the ensemble model correctly classifies between 85% and 93% of structures as residential and nonresidential across both countries. The classification outputs are likely to be valuable in the modelling of human population distributions, as well as in a range of related applications such as urban planning, resource allocation, and service delivery. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Building classification; Building footprint; Machine learning; Residential; Superlearner,"Lloyd C.T., Sturrock H.J.W., Leasure D.R., Jochem W.C., Lázár A.N., Tatem A.J.",10.3390/rs12233847,5.95,-0.12
1,224,4.0,2020,Article,Assessing urban growth in Ghana using machine learning and intensity analysis: A case study of the New Juaben Municipality,"Population growth coupled with economic, housing and environmental factors have significantly contributed into accelerated land use change in the New Juaben Municipality of Ghana. These factors have caused destruction of natural habitat and increased natural hazards such as flooding in the Municipality. Monitoring land use/land cover change is essential in respect to the dynamics of both human and natural factors that affect the biophysical and biochemical properties of the land surface. This research investigates the transitions among the major land use/land cover categories in the Municipality as a highly populated urban region that is facing some environmental challenges such as deforestation and degradation of the environment. Random Forest was adopted for the classification of 1985, 1991, 2002 and 2015 land cover maps while the analysis of the dynamics was conducted using intensity analysis. The unique contribution of this article is the combine usage of machine learning algorithm and intensity analysis to assess the changes in land use/land cover. The results showed that 1985–1991 and 2002–2015 periods experience fast change and the land use transformation has been accelerating over the whole period. The major changes were caused by the Built-up and Agricultural activities constituting 21.24 % and 13.19 % respectively in the category level. It is recommended that, authorities should consider several structural transformation measures within Ghana, including inter-sectoral land use harmonization policies (e.g. the Land Use and Spatial Planning Act 2016), land use planning and legal reforms to help address the underlying drivers of urban led deforestation. © 2020 Elsevier Ltd",Ghana; Intensity analysis; Random forest classification; UN sustainable development goals; Urbanization,"Nyamekye C., Kwofie S., Ghansah B., Agyapong E., Boamah L.A.",10.1016/j.landusepol.2020.105057,7.63,-0.52
-1,228,4.0,2020,Article,Population spatialization in Beijing city based on machine learning and multisource remote sensing data,"Remote sensing data have been widely used in research on population spatialization. Previous studies have generally divided study areas into several sub-areas with similar features by artificial or clustering algorithms and then developed models for these sub-areas separately using statistical methods. These approaches have drawbacks due to their subjectivity and uncertainty. In this paper, we present a study of population spatialization in Beijing City, China based on multisource remote sensing data and town-level population census data. Six predictive algorithms were compared for estimating population using the spatial variables derived from The National Polar-Orbiting Partnership/ Visible Infrared Imaging Radiometer Suite (NPP/VIIRS) night-time light and other remote sensing data. Random forest achieved the highest accuracy and therefore was employed for population spatialization. Feature selection was performed to determine the optimal variable combinations for population modeling by random forest. Cross-validation results indicated that the developed model achieved a mean absolute error (MAE) of 2129.52 people/km2 and a R2 of 0.63. The gridded population density in Beijing at a spatial resolution of 500 m produced by the random forest model was also adjusted to be consistent with the census population at the town scale. By comparison with Google Earth high-resolution images, the remotely-sensed population was qualitatively validated at the intra-town scale. Validation results indicated that remotely sensed results can effectively depict the spatial distribution of population within town-level districts. This study provides a valuable reference for urban planning, public health and disaster prevention in Beijing, and a reference for population mapping in other cities. © 2020 by the authors.",Beijing; Population spatialization; Random forest; Remote sensing,"He M., Xu Y., Li N.",10.3390/rs12121910,8.4,-0.97
-1,237,4.0,2018,Conference Paper,Satellite image spoofing: Creating remote sensing dataset with generative adversarial networks,"The rise of Artificial Intelligence (AI) has brought up both opportunities and challenges for today's evolving GIScience. Its ability in image classification, object detection and feature extraction has been frequently praised. However, it may also apply for falsifying geospatial data. To demonstrate the thrilling power of AI, this research explored the potentials of deep learning algorithms in capturing geographic features and creating fake satellite images according to the learned 'sense'. Specifically, Generative Adversarial Networks (GANs) is used to capture geographic features of a certain place from a group of web maps and satellite images, and transfer the features to another place. Corvallis is selected as the study area, and fake datasets with 'learned' style from three big cities (i.e. New York City, Seattle and Beijing) are generated through CycleGAN. The empirical results show that GANs can 'remember' a certain 'sense of place' and further apply that 'sense' to another place. With this paper, we would like to raise both public and GIScientists' awareness in the potential occurrence of fake satellite images, and its impacts on various geospatial applications, such as environmental monitoring, urban planning, and land use development. © Chun X. Xu and Bo Zhao.",Deep learning and AI; Fake satellite image; GANs; Geographic feature,"Xu C., Zhao B.",10.4230/LIPIcs.GIScience.2018.67,6.38,2.84
0,238,4.0,2018,Article,Context-Based Filtering of Noisy Labels for Automatic Basemap Updating from UAV Data,"Unmanned aerial vehicles (UAVs) have the potential to obtain high-resolution aerial imagery at frequent intervals, making them a valuable tool for urban planners who require up-to-date basemaps. Supervised classification methods can be exploited to translate the UAV data into such basemaps. However, these methods require labeled training samples, the collection of which may be complex and time consuming. Existing spatial datasets can be exploited to provide the training labels, but these often contain errors due to differences in the date or resolution of the dataset from which these outdated labels were obtained. In this paper, we propose an approach for updating basemaps using global and local contextual cues to automatically remove unreliable samples from the training set, and thereby, improve the classification accuracy. Using UAV datasets over Kigali, Rwanda, and Dar es Salaam, Tanzania, we demonstrate how the amount of mislabeled training samples can be reduced by 44.1% and 35.5%, respectively, leading to a classification accuracy of 92.1% in Kigali and 91.3% in Dar es Salaam. To achieve the same accuracy in Dar es Salaam, between 50000 and 60000 manually labeled image segments would be needed. This demonstrates that the proposed approach of using outdated spatial data to provide labels and iteratively removing unreliable samples is a viable method for obtaining high classification accuracies while reducing the costly step of acquiring labeled training samples. © 2008-2012 IEEE.",Basemap updating; image classification; informal settlements; label noise; random forests; unmanned aerial vehicles (UAVs); urban planning,"Gevaert C.M., Persello C., Elberink S.O., Vosselman G., Sliuzas R.",10.1109/JSTARS.2017.2762905,5.38,2.34
0,242,4.0,2017,Article,Urban areas extraction from multi sensor data based on machine learning and data fusion,"Accurate urban areas information is important for a variety of applications, especially city planning and natural disaster prediction and management. In recent years, extraction of urban structures from remotely sensed images has been extensively explored. The key advantages of this imaging modality are reduction of surveying expense and time. It also elevates restrictions on ground surveys. Thus far, much research typically extracts these structures from very high resolution satellite imagery, which are unfortunately of relatively poor spectral resolution, resulting in good precision yet moderate accuracy. Therefore, this paper investigates extraction of buildings from middle and high resolution satellite images by using spectral indices (Normalized Difference Building Index: NDBI, Normalized Difference Vegetation Index: NDVI, Soil Adjustment Vegetation Index: SAVI, Modified Normalized Difference Index: MNDWI, and Global Environment Monitoring Index: GEMI) by means of various Machine Learning methods (Artificial Neural Network: ANN, K-Nearest Neighbor: KNN, and Support Vector Machine: SVM) and Data Fusion (i.e., Majority Voting). Herein empirical results suggested that suitable learning methods for urban areas extraction are in preferring order Data Fusion, SVM, KNN, and ANN. Their accuracies were 85.46, 84.86, 84.66, and 84.91%, respectively. © 2017, Pleiades Publishing, Ltd.",data fusion; machine learning; spectral indices; urban areas extraction,"Puttinaovarat S., Horkaew P.",10.1134/S1054661816040131,5.95,0.51
-1,245,4.0,2012,Conference Paper,Accuracy comparison of land cover mapping using the object-oriented image classification with machine learning algorithms,"Land cover mapping provides basic information for advanced science such as ecological management, biodiversity conservation, forest planning and so on. In remote sensing research, the process of creating an accurate land cover map is an important subject. Recently, there has been growing research interest in the object-oriented image classification techniques. The object-oriented image classification consists of multidimensional features including object features and thus requires multi-dimensional image classification approaches. For example, a linear model such as the maximum likelihood method of pixel-based classification cannot characterize the patterns or relations of multi-dimensional data. In multi-dimensional image classification, data mining and ensemble learning have been shown to increase accuracy and flexibility. This study examined the use of the object-oriented image classification by the multiple machine learning algorithms for land cover mapping. We applied four classifiers: Classification and regression tree (CART), Decision tree with Boosting, Decision tree with Bagging, and Random Forest. The study area was Sado Island in Niigata Prefecture, Japan. Pan-sharpened SPOT/HRG imagery (June 2007) was used and classified into the following eight classes: broad-leaved deciduous forest, Japanese cedar, Japanese red pine, bamboo forest, paddy field, urban area, road, and bare land. We prepared four data sets with the object based features including textural information. The number of features is increased from data set I through IV. As the result, CART was unsuitable for multi-dimensional classification. Random Forest and Decision tree with Boosting showed high classification accuracies. Furthermore, in the data set with the limited features, Decision tree with Boosting was the accurate classifier. Finally, we propose two machine learning algorithms to every datasets. Random Forest is effective in the case of the multi-dimensional image classification such as data set II, III, and IV. Decision tree with Boosting is effective in the case of the image classification with the limited features such as data set I.",Bagging; Boosting; Classification and regression tree; Ensemble classifier; Random Forest,"Mochizuki S., Murakami T.",,7.52,0.76
0,249,3.0,2021,Article,Deep learning-based multi-feature semantic segmentation in building extraction from images of UAV photogrammetry,"Building information is an essential part of geographic information system (GIS) applications in urban planning and management. However, it changes rapidly with economic growth. Unmanned aerial vehicles (UAV)-based photogrammetry works well in this situation with its advantages of quick and high-resolution data updating. In this paper, in order to improve building extraction accuracy in complex areas where buildings are characterized by various patterns, complex structures, and unique styles, we present a framework which applies deep learning (DL) semantic segmentation to UAV images with digital surface model (DSM) and visible-band difference vegetation index (VDVI). The results show that extraction accuracy improves. The combination of red, green, blue (RGB) and VDVI bands (RGBVI) can effectively distinguish the building area and vegetation. The application of RGB with DSM bands (RGBD) helps separate buildings from ground objects. The combination of RGB, DSM, and VDVI bands (RGBDVI) can identify small buildings which are usually not high and covered partly by tree branches. The proposed method is further applied to an open standard dataset to evaluate its robustness and results indicate an increased overall accuracy from RGB only (93%) to RGBD (97%). © 2020 Informa UK Limited, trading as Taylor & Francis Group.",,"Boonpook W., Tan Y., Xu B.",10.1080/01431161.2020.1788742,5.61,2.22
0,256,3.0,2020,Article,A generalized multi-task learning approach to stereo DSM filtering in urban areas,"City models and height maps of urban areas serve as a valuable data source for numerous applications, such as disaster management or city planning. While this information is not globally available, it can be substituted by digital surface models (DSMs), automatically produced from inexpensive satellite imagery. However, stereo DSMs often suffer from noise and blur. Furthermore, they are heavily distorted by vegetation, which is of lesser relevance for most applications. Such basic models can be filtered by convolutional neural networks (CNNs), trained on labels derived from digital elevation models (DEMs) and 3D city models, in order to obtain a refined DSM. We propose a modular multi-task learning concept that consolidates existing approaches into a generalized framework. Our encoder-decoder models with shared encoders and multiple task-specific decoders leverage roof type classification as a secondary task and multiple objectives including a conditional adversarial term. The contributing single-objective losses are automatically weighted in the final multi-task loss function based on learned uncertainty estimates. We evaluated the performance of specific instances of this family of network architectures. Our method consistently outperforms the state of the art on common data, both quantitatively and qualitatively, and generalizes well to a new dataset of an independent study area. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",3D city models; Deep learning; Multi-task learning; Roof type segmentation; Stereo DSM filtering,"Liebel L., Bittner K., Körner M.",10.1016/j.isprsjprs.2020.03.005,6.0,2.36
0,292,2.0,2020,Article,Precise object detection using adversarially augmented local/global feature fusion,"Object detection, which aims at recognizing or locating the objects of interest in remote sensing imagery with high spatial resolutions (HSR), plays a significant role in many real-world scenarios, e.g., environment monitoring, urban planning, civil infrastructure construction, disaster rescuing, and geographic image retrieval. As a long-lasting challenging problem in both machine learning and geoinformatics communities, many approaches have been proposed to tackle it. However, previous methods always overlook the abundant information embedded in the HSR remote sensing images. The effectiveness of these methods, e.g., accuracy of detection, is therefore limited to some extent. To overcome the mentioned challenge, in this paper, we propose a novel two-phase deep framework, dubbed GLGOD-Net, to effectively detect meaningful objects in HSR images. GLGOD-Net firstly attempts to learn the enhanced deep representations from super-resolution image data. Fully utilizing the augmented image representations, GLGOD-Net then learns the fused representations into which both local and global latent features are implanted. Such fused representations learned by GLGOD-Net can be used to precisely detect different objects in remote sensing images. The proposed framework has been extensively tested on a real-world HSR image dataset for object detection and has been compared with several strong baselines. The remarkable experimental results validate the effectiveness of GLGOD-Net. The success of GLGOD-Net not only advances the cutting-edge of image data analytics, but also promotes the corresponding applicability of deep learning in remote sensing imagery. © 2020",Data augmentation; Geospatial object detection; High spatial resolution (HSR) remote sensing imagery; Local/global feature fusion; Super resolution generative adversarial network,"Han X., He T., Ong Y.-S., Zhong Y.",10.1016/j.engappai.2020.103710,6.43,2.7
1,297,2.0,2020,Article,Sensing Mixed Urban Land-Use Patterns Using Municipal Water Consumption Time Series,"The biased population coverage and short temporal lengths of newly emerged data sets (e.g., data sets of social media, mobile phones, and smart cards) obstruct the effective analysis of long-term dynamics of landuse patterns, particularly in small and developing cities. This study proposed a framework to delineate and analyze mixed land-use patterns and their evolution using municipal water consumption data. A two-step classification strategy was designed based on the rotation forest scheme to differentiate the socioeconomic types of customers (e.g., residence, commerce, public facility, manufacturing, and recreation) using multiple features extracted from the various forms of water consumption time series. The spatial distributions of the socioeconomic functions were then derived, and the mixed land use was measured using a diversity index based on information entropy. Such an approach was applied to Changshu, a typical developing county-level city in China, for the period 2004 to 2013. The results showed that the urbanization of Changshu experienced both spatial expansion and intensification, with a slightly declining rate of growth in recent years. Apart from the city center, two subcenters have emerged for industrial development. The degree of land-use mixture has increased with urban growth, indicating a maturing of urbanization. This study explored the approach of identifying individual socioeconomic functions by the consumption patterns of municipal services and demonstrated that municipal service data sets can reveal land-use patterns and dynamics at a fine spatial resolution to evaluate urban planning and management, with the advantages of large population coverage and long-term temporal lengths. © 2020, © 2020 by American Association of Geographers.",land-use patterns; mixed land use; municipal water consumption; rotation forest; social sensing,"Guan Q., Cheng S., Pan Y., Yao Y., Zeng W.",10.1080/24694452.2020.1769463,8.03,-0.84
1,300,2.0,2019,Article,Spatiotemporal dynamics of urbanization and cropland in the Nile Delta of Egypt using machine learning and satellite big data: implications for sustainable development,"The Nile Delta of Egypt is increasingly facing sustainability threats, due to a combination of nature- and human-induced changes in land cover and land use. In this paper, an analysis of big time series data from remotely sensed satellite images and the random forests classifier was undertaken to assess the spatial and temporal dynamics of urbanization and cropland in the Nile Delta between 2007 and 2017. Out of thirteen variables, five spectral indices were chosen to build 500 decision trees, with a resulting overall accuracy average of 91.9 ± 1.5%. The results revealed that the urban extent in the Nile Delta has increased, between 2007 and 2017, by 592.4 km2 (1.92%). Particularly, the results indicated that the years 2011 and 2012, which coincided the 2011 political uprising in Egypt, so-called the Arab Spring, were associated with significant land-use changes in the Nile Delta, both in rate and scale. As a result, the cropland area in the region decreased between 2010 and 2011 by 1.63% (502.21 km2). Moreover, the results showed that during the period 2012–2017, the mean annual urbanization rate in the region stood at 60 km2/year. In contrast, croplands decreased during the same period at an average annual rate of 2 km2/year. At the governorates’ level, the results suggested that top agricultural producing governorates in the Nile Delta, such as Elmonoufia, Elkalubia, Elbouhyra, and Elghrbia, witnessed the highest rates of decrease in cropland areas during the period 2012–2017. Over the same period, urban areas increased the most in Elkalubia, Domiate, and Elmonoufia by 1.98%, 1.72%, and 1.34%, respectively. The f indings from this analysis are discussed along with their implications for sustainable land-use and urban planning policies. © 2019, Springer Nature Switzerland AG.",Big data; LULC; Nile Delta; Random forests; Sustainable development; Urbanization,"Badreldin N., Abu Hatab A., Lagerkvist C.-J.",10.1007/s10661-019-7934-x,7.38,-0.31
-1,313,2.0,2019,Conference Paper,Multi-scale correlation-based feature selection and random forest classification for LULC mapping from the integration of SAR and optical Sentinel images,"Reliable and accurate land use/land cover (LULC) map is a crucial data source for the understanding of coupled human-environment systems, monitoring changes, timely low-cost planning, and management of natural resources. Improvements in sensor technologies and machine learning capabilities have shifted the attention of remote sensing community to data complementarity through fusion of multi-sensor data for accurate feature extraction and mapping. Amalgamation of optical and synthetic aperture radar (SAR) images has shown promising advantages in enhancing the accuracy of extracting LULC as such method allows exploitation of information in sensors. This study investigated the potential of using freely available multisource Sentinel images to extract LULC maps in semi-arid environments through multi-scale geographic object-based image analysis (GEOBIA). A multi-scale classification framework that integrates GEOBIA, correlation-based feature selection (CFS), and random forest (RF)-supervised classification was adopted to extract LULC from assimilation of Sentinel multi-sensor products. First, Sentinel-1 and-2 images were pre-processed. Second, optimum multi-scale segmentation levels were selected using F-score segmentation quality measures. Third, 70 features of various spectral indices and derivatives and geometrical features from optical data and multiple ratios and textural features from dual-polarization SAR images were computed, and a CFS based on wrapper approach was used to select the most significant features at multi-scale levels. Finally, a single and multi-scale RF classifier was used to extract LULC classes using the most relevant features extracted from Sentinel SAR and optical images. Results of multi-scale image segmentation optimization showed that scale parameter (SP) values of 40, 60, and 150 were optimal for extraction of LULC classes. Results of feature selection showed that 22, 24, and 27 features were selected at scale SP values of 40, 60, and 150, respectively. Half of the features were common among the three scales. Single RF classification yielded overall accuracy (OA) values of 92.10%, 93%, and 91% and kappa coefficients of 0.901, 0.912, and 0.89 at scale values of 150, 60, and 40, respectively. Multiscale RF classification from scale values of 150 and 60 produced better LULC classification with OA 96.06% and kappa coefficient of 0.95 compared with other scale SP values. The integrated approach demonstrated an effective and promising method for high-quality LULC extraction from coupling optical and SAR images. Overall, multi-sensor Sentinel images along with the adopted approach feature a remarkable potential for improving LULC extraction and can effectively be used to update geographic information system layers for various applications. © 2019 SPIE.",data fusion; image segmentation optimization; LULC; object-based classification; Optical sensors; SAR,"Al-Ruzouq R., Shanableh A., Gibril M.B., Kalantar B.",10.1117/12.2533123,7.12,0.85
1,324,1.0,2021,Article,Mapping essential urban land use categories with open big data: Results for five metropolitan areas in the United States of America,"Urban land-use maps outlining the distribution, pattern, and composition of various land use types are critically important for urban planning, environmental management, disaster control, health protection, and biodiversity conservation. Recent advances in remote sensing and social sensing data and methods have shown great potentials in mapping urban land use categories, but they are still constrained by mixed land uses, limited predictors, non-localized models, and often relatively low accuracies. To inform these issues, we proposed a robust and cost-effective framework for mapping urban land use categories using openly available multi-source geospatial “big data”. With street blocks generated from OpenStreetMap (OSM) data as the minimum classification unit, we integrated an expansive set of multi-scale spatially explicit information on land surface, vertical height, socio-economic attributes, social media, demography, and topography. We further proposed to apply the automatic ensemble learning that leverages a bunch of machine learning algorithms in deriving optimal urban land use classification maps. Results of block-level urban land use classification in five metropolitan areas of the United States found the overall accuracies of major-class (Level-I) and minor-class (Level-II) classification could be high as 91% and 86%, respectively. A multi-model comparison revealed that for urban land use classification with high-dimensional features, the multi-layer stacking ensemble models achieved better performance than base models such as random forest, extremely randomized trees, LightGBM, CatBoost, and neural networks. We found without very-high-resolution National Agriculture Imagery Program imagery, the classification results derived from Sentinel-1, Sentinel-2, and other open big data based features could achieve plausible overall accuracies of Level-I and Level-II classification at 88% and 81%, respectively. We also found that model transferability depended highly on the heterogeneity in characteristics of different regions. The methods and findings in this study systematically elucidate the role of data sources, classification methods, and feature transferability in block-level land use classifications, which have important implications for mapping multi-scale essential urban land use categories. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Block-level mapping; Ensemble learning; Geospatial big data; Land use classification; NAIP; Sentinel-1/2,"Chen B., Tu Y., Song Y., Theobald D.M., Zhang T., Ren Z., Li X., Yang J., Wang J., Wang X., Gong P., Bai Y., Xu B.",10.1016/j.isprsjprs.2021.06.010,8.33,-0.15
0,327,1.0,2021,Article,Integration of Texture and Spectral Response with AI Techniques for Buildings Footprint Identification Using High-Resolution Satellite Images,"The rapid growth and advancement in the application of remote sensing (RS) and geographic information systems (GIS) in several application domains helped many researchers to analyze a wide range of information from satellite imagery. Settlement information that includes building foot prints is a very essential parameter for different applications such as urban planning, environmental planning and disaster management. VGG-16 (Visual Geometry Group) conventional neural network (CNN) model is a popular model used to detect and classify the input images. In this study, a new approach was proposed by integration of VGG-16-CNN model with spectral and textural information of satellite images for identification of building foot prints. The model was trained and implemented to identify the building footprints using Worldview-3 high-resolution satellite image over part of Mumbai city of Maharashtra state, India. Classification accuracy in the proposed approach is observed to be nearly 94% as compared to 82% in case of single-shot detector (SSD) algorithm alone. Metric parameters such as F1 score of 0.957, intersection over union (IoU) of 94.86% and total error rate of 8.133% also indicated better performance of the proposed approach. Particularly, the approach is highly beneficial for urban development authorities as they need to monitor the large number of vacant lands spread across urban areas. © 2021, Indian Society of Remote Sensing.",Conventional neural network; High-resolution satellite data; Remote sensing and GIS; Visual geometry group,"Pandey G., Sharma V.K., Chaudhary P., Chowdary V.M., Udayraj",10.1007/s12524-021-01322-9,5.88,1.49
-1,329,1.0,2021,Article,Modeling fine-scale residential land price distribution: An experimental study using open data and machine learning,"Modeling the fine-scale spatiotemporal distribution of residential land prices (RLPs) is the basis for scientifically allocating land resources, managing the residential market and improving urban planning. The accurate mapping of the RLP dynamics require reliable land price prediction models and data with fine spatial and temporal resolution. With the aid of point of interest (POI) data and nighttime light (NTL) images, this paper attempts to explore the ability of machine learning algorithms (MLAs) to model grid-level RLPs using the case of Wuhan in China. Several land price prediction models were built using five MLAs and various geographic variables. The experimental results show that the extra-trees regression algorithm and the radial basis function-based support vector regression algorithm perform best in Period Ⅰ (2010–2014) and Period Ⅱ (2015–2019), respectively; therefore, they were selected to estimate the RLPs of the grids without observations in the corresponding period. Based on the estimated results, we found that the spatial pattern of the RLP in Wuhan transitioned from monocentric to polycentric between the two periods, and RLPs grew rapidly near newly formed urban subcenters and waterscapes. The relative importance of the predictor variables shows that commercial and educational facilities are important determinants of the RLP distribution in Wuhan; moreover, the relative importance of natural amenities and education facilities increased over time, while that of commercial facilities and public transportation decreased slightly. The case of Wuhan confirms the feasibility of MLAs and openly accessible urban data in modeling fine-scale RLP distributions. Our proposed framework provides a new approach to monitor the urban land price dynamics accurately and closely, which is beneficial for improving the infrastructure layout and achieve smart city growth. © 2021 Elsevier Ltd",Determinants; Land price distribution; Machine learning; Open data; Spatiotemporal variation; Wuhan,"Zhang P., Hu S., Li W., Zhang C., Yang S., Qu S.",10.1016/j.apgeog.2021.102442,7.98,-1.75
1,332,1.0,2021,Article,Using satellite image fusion to evaluate the impact of land use changes on ecosystem services and their economic values,"Accelerated land use change is a current challenge for environmental management world-wide. Given the urgent need to incorporate economic and ecological goals in landscape planning, cost-effective conservation strategies are required. In this study, we validated the benefit of fusing imagery from multiple sensors to assess the impact of landscape changes on ecosystem services (ES) and their economic values in the Long County, Shaanxi Province, China. We applied several landscape metrics to assess the local spatial configuration over 15 years (2004–2019) from fused image-ries. Using Landsat-7 Enhanced Thematic Mapper Plus (ETM+), Landsat-8 Operational Land Im-ager (OLI) and Indian Remote Sensing Satellite System Linear Imaging Self Scanning Sensor 3 (IRS LISS 3) imageries fused for 2004, 2009, 2014 and 2019, we reclassified land use/land cover (LULC) changes, through the rotation forest (RF) machine-learning algorithm. We proposed an equivalent monetary metric for estimating the ES values, which also could be used in the whole China. Results showed that agriculture farmland and unused land decreased their spatial distribution over time, with an observed increase on woodland, grassland, water bodies and built-up area. Our findings suggested that the patterns of landscape uniformity and connectivity improved, while the distribution of landscape types stabilized, while the landscape diversity had a slight improvement. The overall ES values increased (4.34%) under a benefit transfer approach, mainly concerning woodland and grassland. A sensitivity analysis showed the selected economic value (EV) was relevant and suitable for the study area associated with our ES for LULC changes. We suggested that changes in landscape patterns affected the ESV trends, while the increases on some LULC classes slightly improved the landscape diversity. Using an interdisciplinary approach, we recommend that local au-thorities and environmental practitioners should balance the economic benefits and ecological gains in different landscapes to achieve a sustainable development from local to regional scales. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Environmental monitoring; Image fusion; Landscape patterns; Remote sens-ing; Urban ecosystem services,"Shuangao W., Padmanaban R., Mbanze A.A., Silva J.M.N., Shamsudeen M., Cabral P., Campos F.S.",10.3390/rs13050851,8.11,0.01
1,347,1.0,2020,Article,Analysing urban development patterns in a conflict zone: A case study of kabul,"A large part of the population in low-income countries (LICs) lives in fragile and conflict-affected states. Many cities in these states show high growth dynamics, but little is known about the relation of conflicts and urban growth. In Afghanistan, the Taliban regime, which lasted from 1996 to 2001, caused large scale displacement of the population. People from Afghanistan migrated to neighboring countries like Iran and Pakistan, and all developments came to a halt. After the US invasion in October 2001, all the major cities in Afghanistan experienced significant population growth, in particular, driven by the influx of internally displaced persons. Maximum pressure of this influx was felt by the capital city, Kabul. This rapid urbanization, combined with very limited capacity of local authorities to deal with this growth, led to unplanned urbanization and challenges for urban planning and management. This study analyses the patterns of growth between 2001 and 2017, and the factors influencing the growth in the city of Kabul with the help of high-resolution Earth Observation-based data (EO) and spatial logistic regression modelling. We analyze settlement patterns by extracting image features from high-resolution images (aerial photographs of 2017) and terrain features as input to a random forest classifier. The urban growth is analyzed using an available built-up map (extracted from IKONOS images for the year 2001). Results indicate that unplanned settlements have grown 4.5 times during this period, whereas planned settlements have grown only 1.25 times. The unplanned settlements expanded mostly towards the west and north west parts of the city, and the growth of planned settlements happened mainly in the central and eastern parts of the city. Population density and the locations of military bases are the most important factors that influence the growth, of both planned and unplanned settlements. The growth of unplanned settlement occurs predominantly in areas of steeper slopes on the hillside, while planned settlements are on gentle slopes and closer to the institutional areas (central and eastern parts of the city). We conclude that security and availability of infrastructure were the main drivers of growth for planned settlements, whereas unplanned growth, mainly on hillsides, was driven by the availability of land with poor infrastructure. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Conflict; GLCM; Informal areas; Machine learning; Random forest classification; Spatial logistic regression; Unplanned areas; Urban growth; Urban growth model,"Chaturvedi V., Kuffer M., Kohli D.",10.3390/rs12213662,7.48,-0.88
-1,361,1.0,2020,Conference Paper,Land cover classification based on machine learning using UAV multi-spectral images,"Land cover classification using UAV multi-spectral images is of great significance in precision agriculture, urban planning, land use and other fields. However, traditional remote sensing image classification methods cannot meet the classification accuracy requirements of UAV multi-spectral images. This paper aims to propose an object-based machine learning classification method to improve the land over classification accuracy of UAV multi-spectral images. The experimental area is a standard test field located in the Jilin Province of China. The experimental data was captured by a UAV equipped with a multi-spectral camera which includes four bands from 550 nm to 790 nm. First, the original images were preprocessed and the spectral curves of land cover were analyzed, thus four kinds of land cover with large differences were selected as categories. Then pixel-based, boosting-based and object-based machine learning methods were used for classification. The object-based classification method could make full use of the spatial and spectral information, and eliminate the noise problem caused by the high resolution of the UAV image to a certain extent. Finally, accuracy analysis using the verification image showed that the RF-O method achieved the highest classification accuracy of 92.2419%, and the kappa coefficient was 0.8904. All results indicate that the object-based machine learning classification method proposed in this paper is more suitable for the research of land cover classification, comparing with the traditional remote sensing image classification methods, and performs well on the land cover classification of UAV multi-spectral images. © 2020 SPIE.",Image classification; Machine learning; UAV remote sensing,"Pan L., Gu L., Ren R., Yang S.",10.1117/12.2566128,7.58,1.02
-1,364,1.0,2020,Article,A Self-Supervised Learning Framework for Road Centerline Extraction from High-Resolution Remote Sensing Images,"Road extraction from the high-resolution remote sensing image is significant for the land planning, vehicle navigation, etc. The existing road extraction methods normally need many preprocessing and subsequent optimization steps. Therefore, an automatic road centerline extraction method based on the self-supervised learning framework for high-resolution remote sensing image is proposed. This proposed method does not need to manually select training samples and other optimization steps, such as the nonroad area removing. First, the positive sample selection method combining the spectral and shape features is proposed to extract the road sample. Then, the one-class classifier framework is introduced and the random forest positive unlabeled learning classifier is constructed to get the posterior probability of the pixel belonging to road. The shape feature and the posterior probability are combined to form the final road network in the object-oriented way. Finally, the road centerline is obtained through the tensor voting algorithm. In order to verify the effectiveness of the proposed algorithm, high-resolution remote sensing images and benchmark datasets are used to do experiments. The indexes of the completeness ratio, the correctness ratio, and the detection quality are used for the quantitative accuracy evaluation. Compared with the supervised, the unsupervised, and the one-class classification road extraction algorithms, this proposed algorithm achieves high accuracy and efficiency. For the deep learning method comparison, the deep learning method performs well in most cases especially in the complex urban area. However, the deep learning method needs a large number of samples and a long training time, and our self-supervised learning framework does not need the training samples. © 2008-2012 IEEE.",High-resolution remote sensing image; one-class classifier; road centerline; road extraction; self-supervised learning,"Guo Q., Wang Z.",10.1109/JSTARS.2020.3014242,5.93,1.13
0,367,1.0,2020,Conference Paper,Application of satellite image segmentation for urban planning optimization,"This article presents research results of a convolution neural network for building detection on high-resolution aerial images of Planet database. Jaccard index was used for analysis of the quality of machine learning algorithm. This index of similarity compares results of algorithms with real masks. The masks were sliced on smaller parts together with images before training of developed model. The convolution neural network was launched on NVIDIA DGX-1 supercomputer, which was provided by AI-center of P.G Demidov Yaroslavl State University. The problem of building detection on satellite images can be put into practice for urban planning, building control, search of the best locations for outlets etc. © WCSE 2019. All rights reserved.",Aerial image segmentation; Building detection; Machine learning,"Khryashchev V., Ivanovsky L., Ostrovskaya A., Semenov A.",,5.85,1.72
0,378,1.0,2019,Conference Paper,A big remote sensing data analysis using deep learning framework,"Spaceborne and airborne sensors deliver a huge number of Earth Observation Data every day. In this context, we can easily observe the whole earth from its different sides. Therefore, this big data is important in remote sensing and could be exploited in several domains requiring image classification, natural hazard monitoring, global climate change, agriculture, urban planning. Over the last five years, Convolutional Neural Networks (CNN) emerged as the most successful technique for the image classification task, as well as a number of other computer vision tasks. However, to train millions of parameters in CNN one requires a huge amount of annotated data. This requirement leads to a significant challenge if the available training data is limited for a target task at hand. To address this challenge, in the recent literature, researchers proposed various ways to apply a technique called Transfer Learning to transfer the knowledge gained by training CNNs parameters on some large annotated dataset to the target task with limited availability of training data. Most of our work in this paper was dedicated to proposing a hybrid classification of remote sensing images. This architecture combines Spark RDD image coding to consider image's local regions, pre-trained VGGNET-16 and UNET for image segmentation and SVM (Support Vector Machines) from spark Machine Learning to achieve labeling task. © Multi Conference on Computer Science and Information Systems, MCCSIS 2019. All rights reserved.",Big Data; Deep Learning; Feature extraction; Multi-label Classification; Remote Sensing; Support Vector Machines,"Balti H., Chebbi I., Mellouli N., Farah I.R., Lamolle M.",10.33965/bigdaci2019_201907l015,6.59,2.52
-1,382,1.0,2018,Conference Paper,Application of machine learning in urban greenery land cover extraction,"Urban greenery is a critical part of the modern city and the greenery coverage information is essential for land resource management, environmental monitoring and urban planning. It is a challenging work to extract the urban greenery information from remote sensing image as the trees and grassland are mixed with city built-ups. In this paper, we propose a new automatic pixel-based greenery extraction method using multispectral remote sensing images. The method includes three main steps. First, a small part of the images is manually interpreted to provide prior knowledge. Secondly, a five-layer neural network is trained and optimised with the manual extraction results, which are divided to serve as training samples, verification samples and testing samples. Lastly, the well-trained neural network will be applied to the unlabelled data to perform the greenery extraction. The GF-2 and GJ-1 high resolution multispectral remote sensing images were used to extract greenery coverage information in the built-up areas of city X. It shows a favourable performance in the 619 square kilometers areas. Also, when comparing with the traditional NDVI method, the proposed method gives a more accurate delineation of the greenery region. Due to the advantage of low computational load and high accuracy, it has a great potential for large area greenery auto extraction, which saves a lot of manpower and resources. © Authors 2018. CC BY 4.0 License.",Auto extraction; Greenery land cover; Machine learning; Multispectral image; Neural network,"Qiao X., Li L.L., Li D., Gan Y.L., Hou A.Y.",10.5194/isprs-archives-XLII-3-1409-2018,6.61,0.62
0,385,1.0,2018,Article,Building detection from orthophotos using binary feature classification,"Building detection in orthophotos is crucial for various applications, such as urban planning and real-estate management. In order to realize accurate and fast building detection, a non-interactive approach based on binary feature classification is brought forward in this paper. The proposed approach includes two major stages, i.e., building area detection and building contours extraction. In the first stage, a sequence of intersections is obtained by superpixel segmentation in the subsampled orthophoto, and then building area is reserved roughly according to the classification of intersections. In the second stage, the sequence of intersections is updated by superpixel segmentation in the building area from original orthophoto, and then building contours is extracted in accordance with the classification of intersections likewise. The local feature of the intersections is descripted employing our extremely compact binary descriptor, and is classified using binary bag-of-features. Experiments show that benefiting from binary description and making full use of texture details and color channels, the proposed descriptor is not only computationally frugal, but also accurate. Experiments are also conducted on orthophotos with different roof colors, textures, shapes, sizes and orientations, and demonstrate that the proposed approach are capable of achieving desirable results. © 2017, Springer Science+Business Media, LLC.",Building detection; Classifier; Descriptor; Local feature; Machine learning,"Hu Y., Hu X., Li P., Ding Y.",10.1007/s11042-017-5093-z,5.42,1.24
0,389,1.0,2018,Conference Paper,Understanding Historical Cityscapes from Aerial Imagery Through Machine Learning,"Understanding cityscapes using remote sensing data has been an active research field for more than two decades. Meanwhile, machine learning provides generalization capabilities compared to hierarchical and rule-based methods. This paper evaluates several machine learning algorithms in order to fuse shadow detection and shadow compensation methods for building detection using high resolution aerial imagery. Three complex and real-life urban study areas were used as test datasets with various: (i) kinds of buildings structures of special architecture, (ii) pixel resolutions and, (iii) types of data. Objective evaluation metrics have been used for assessing the compared algorithms such recall, precision and F1-score as well as rates of completeness, correctness and quality. For both approaches, i.e., shadow detection and building detection, the computational complexity of each machine learning algorithm was examined. The results indicate that deep learning schemes, such a Convolutional Neural Network (CNN), provides the best classification performance in terms of shadow detection and building detection. © 2018, Springer Nature Switzerland AG.",Building detection; Machine learning; Point cloud; Shadow compensation; Shadow detection,"Maltezos E., Protopapadakis E., Doulamis N., Doulamis A., Ioannidis C.",10.1007/978-3-030-01762-0_17,6.1,1.95
-1,401,1.0,2015,Conference Paper,Comparison of different machine learning classifiers for building extraction in LiDAR-derived datasets,"Building extraction in remotely sensed imagery is an important problem that needs solving. It can be used to aid in urban planning, hazard assessments and disaster risk management among others. Light Detection and Ranging or LiDAR, is one of the most powerful remote sensing technologies nowadays. Many studies have used the fusion of LiDAR data and multispectral images in detecting buildings. This study seeks to maximize the power of LiDAR imagery to be able to classify buildings without the aid of multispectral imagery. This work follows the Object Based Image Analysis (OBIA) approach. Instead of the traditional pixel-based classification methods, pixels are segmented into logical groups called objects. From these objects, features for building extraction are calculated. These features are: the number of returns, difference of returns, and the mean and standard deviation of positive surface openness. These objects are then classified using different machine learning classifiers such as Support Vector Machines, K-Nearest Neighbors, Naïve Bayes Classifier, Decision Trees, and Random Forests. A comparative assessment was done on the performance of these different machine learning classifiers. The classifiers performed similarly with the Random Forest Classifier slightly outperforming the others.",Feature extraction; Object based image analysis,"Escamos I.M.H., Roberto A.R.C., Abucay E.R., Inciong G.K.L., Queliste M.D., Hermocilla J.A.C.",,5.25,1.01
1,407,1.0,2007,Conference Paper,"Effects of urbanization on spatiotemporal changes of land cover pattern: A case of Changsha, China","Urbanization is the complex process of converting rural land uses to urban land uses, which has caused significantly land cover changes and associated surface characteristics. Therefore, researches on land cover and its landscape pattern change under urbanization are essential for analyzing the impacts of human activities on environment. This study firstly detected land cover (i.e., forestland, non-forest vegetation, built-up area, and water) changes in Changsha City from 1973 to 2005 by using the multi-temporal Landsat images (TM1973, TM1993, TM1998, ETM+2001) and land use map (2005); and then analyzed the spatiotemporal changes of landscape pattern at landscape-level and class-level by using FRAGSTATS, respectively. At last, the class-level metrics of each land cover class were further regressed to the degree of urbanization. The results indicated that: (1) in the context of urbanization, the built-up area and the non-forest vegetation experienced a significant changes, while the forestland and water remained relatively unchanged, and the non-forest vegetation cover bore the major burden of urbanization; (2) with the advance of urbanization, the change of overall landscape pattern of Changsha represented a complex dynamic process; (3) obvious differences of impacts of urbanization on landscape patterns of various land cover classes existed, i.e., along with the decrease of MPS of non-forest vegetation, the AI of built-up area increased dramatically; (4) some class-level metrics of various land cover classes were strongly correlated to the degree of urbanization, but the correlated extend varied along with the various land cover classes. To sum up, this study demonstrated the differences of impacts of urbanization on various land cover patterns. The results have the potential to assist land-use planning and management.",Changsha; Land cover; Landscape pattern; Urbanization,"Zou B., Zeng Y., Zhang H., Yang K., Dong M.",10.1117/12.760789,7.58,-0.19
0,428,,2021,Article,Comparing three machine learning techniques for building extraction from a digital surface model,"Automatic building extraction from high-resolution remotely sensed data is a major area of interest for an extensive range of fields (e.g., urban planning, environmental risk management) but challenging due to urban morphology complexity. Among the different methods proposed, the approaches based on supervised machine learning (ML) achieve the best results. This paper aims to investigate building footprint extraction using only high-resolution raster digital surface model (DSM) data by comparing the performance of three different popular supervised ML models on a benchmark dataset. The first two methods rely on a histogram of oriented gradients (HOG) feature descriptor and a classical ML (support vector machine (SVM)) or a shallow neural network (extreme learning machine (ELM)) classifier, and the third model is a fully convolutional network (FCN) based on deep learning with transfer learning. Used data were obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) and cover the urban areas of Vaihingen an der Enz, Potsdam, and Toronto. The results indicated that performances of models based on shallow ML (feature extraction and classifier training) are affected by the urban context investigated (F1 scores from 0.49 to 0.81), whereas the FCN-based model proved to be the most robust and best-performing method for building extraction from a high-resolution raster DSM (F1 scores from 0.80 to 0.86). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Automated building extraction; Deep learning (DL); Digital surface model (DSM); Extreme learning machine (ELM); Fully convolutional network (FCN); Histogram of oriented gradients (HOG); Machine learning (ML); Support vector machine (SVM),"Notarangelo N.M., Mazzariello A., Albano R., Sole A.",10.3390/app11136072,5.53,1.66
-1,430,,2021,Article,Building Roof Superstructures Classification from Imbalanced and Low Density Airborne LiDAR Point Cloud,"Light Detection and Ranging (LiDAR), an active remote sensing technology, is becoming an essential tool for geoinformation extraction and urban planning. Airborne Laser Scanning (ALS) point clouds segmentation and accurate classification are challenging and crucial to produce different geo-information products like three-dimensional (3D) city designs. This paper introduces an effective data-driven approach to build roof superstructures classification for airborne LiDAR point clouds with very low density and imbalanced classes, covering an urban area. Notably, it focuses on building roof superstructures (especially dormers and chimneys) and mitigating nonplanar objects' problems. Also, the imbalanced class problem of LiDAR data, to the best of our knowledge, is not yet addressed in the literature; it is considered in this study. The major advantage of the proposed approach is using only raw data without assumptions on the distribution underlying data. The main methodological novelties of this work are summarized in the following key elements. (i) At first, an adapted connected component analysis for 3D points cloud is proposed. (ii) Twelve geometry-based features are extracted for each component. (iii) A Support Vector Machine (SVM)-driven procedure is applied to classify the 3D components. (iv) Furthermore, a new component size-based sampling (CSBS) method is proposed to treat the imbalanced data problem and has been compared with several existing resampling strategies. In this study, components are classified into five classes: shed and gable dormers, chimneys, ground, and others. The results of this investigation show the satisfying classification performance of the proposed approach. Results also showed that the proposed approach outperformed machine learning methods, including SVM, Random Forest, Decision Tree, and Adaboost. © 2001-2012 IEEE.",3D classification; imbalanced data; light detection and ranging (LiDAR); Low-density point cloud; roof superstructures,"Aissou B.E., Aissa A.B., Dairi A., Harrou F., Wichmann A., Kada M.",10.1109/JSEN.2021.3073535,4.93,1.21
-1,431,,2021,Article,"Identifying different types of urban land use dynamics using Point-of-interest (POI) and Random Forest algorithm: The case of Huizhou, China","The significant economic development witnessed in China in recent decades has been accompanied by the increasing expansion of urban areas. Although a growing literature has analyzed the characteristics and driving forces of urban land expansion, less attention has been paid to examining the different expansion determinants driving fine-scale urban land use (residential land, administration and public services land, commercial land, and industrial land) change. This paper aims to identify the differences of multi-mechanisms driving fine-scale urban land use expansion based on big data and machine learning, in the Huizhou downtown area in 2000–2015. The Random Forest (RF) algorithm is used to identify the natural, transportation, location, social, and POI factors driving land expansion by considering different urban land-use categories. Our RF estimations showed that enormous differences existed between various urban land-use types in terms of the role they played in this expansion and their relation to potential determinants, during the different urban development stages studied. Transportation, location, and the distribution of actual land use were found to exert a greater influence on urban land expansion than other factors. All the findings above provide detailed spatiotemporal knowledge and targeted information that can aid in understanding fine-scale urban land use dynamics. In this way, sound planning strategies for different fine-scale land uses can be formulated more scientifically. The strength of association between these factors and urban land expansion differed greatly depending on the different land-use types involved as well as the urban development stage that it occurred within. These results cast a new light on the importance of investigating the potential driving forces in the expansion of different urban land-use types. © 2021 Elsevier Ltd",Big data; Driving forces; Fine-scale; Huizhou; Random Forest; Urban land use,"Wu R., Wang J., Zhang D., Wang S.",10.1016/j.cities.2021.103202,8.02,-1.4
-1,437,,2021,Article,Assessment of deep learning techniques for land use land cover classification in southern new caledonia,"Land use (LU) and land cover (LC) are two complementary pieces of cartographic information used for urban planning and environmental monitoring. In the context of New Caledonia, a biodiversity hotspot, the availability of up-to-date LULC maps is essential to monitor the impact of extreme events such as cyclones and human activities on the environment. With the democratization of satellite data and the development of high-performance deep learning techniques, it is possible to create these data automatically. This work aims at determining the best current deep learning configuration (pixel-wise vs. semantic labelling architectures, data augmentation, image prepos-sessing, … ), to perform LULC mapping in a complex, subtropical environment. For this purpose, a specific data set based on SPOT6 satellite data was created and made available for the scientific community as an LULC benchmark in a tropical, complex environment using five representative areas of New Caledonia labelled by a human operator: four used as training sets, and the fifth as a test set. Several architectures were trained and the resulting classification was compared with a state-of-the-art machine learning technique: XGboost. We also assessed the relevance of popular neo-channels derived from the raw observations in the context of deep learning. The deep learning approach showed comparable results to XGboost for LC detection and over-performed it on the LU detection task (61.45% vs. 51.56% of overall accuracy). Finally, adding LC classification output of the dedicated deep learning architecture to the raw channels input significantly improved the overall accuracy of the deep learning LU classification task (63.61% of overall accuracy). All the data used in this study are available on line for the remote sensing community and for assessing other LULC detection techniques. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning: XGBoost; Land cover; Land use; Neo-channels; Neural network; New Caledonia; Remote sensing,"Rousset G., Despinoy M., Schindler K., Mangeas M.",10.3390/rs13122257,6.94,2.28
-1,439,,2021,Article,Regional population forecast and analysis based on machine learning strategy,"Regional population forecast and analysis is of essence to urban and regional planning, and a well-designed plan can effectively construct a sound national infrastructure and stabilize positive population growth. Traditionally, either urban or regional planning relies on the opinions of demographers in terms of how the population of a city or a region will grow. Multi-regional population forecast is currently possible, carried out mainly on the basis of the Interregional Cohort-Component model. While this model has its unique advantages, several demographic rates are determined based on the decisions made by primary planners. Hence, the only drawback for cohort-component type population forecasting is allowing the analyst to specify the demographic rates of the future, and it goes without saying that this tends to introduce a biased result in forecasting accuracy. To effectively avoid this problem, this work proposes a machine learning-based method to forecast multi-regional population growth objectively. Thus, this work, drawing upon the newly developed machine learning technology, attempts to analyze and forecast the population growth of major cities in Taiwan. By effectively using the advantage of the XGBoost algorithm, the evaluation of feature importance and the forecast of multi-regional population growth between the present and the near future can be observed objectively, and it can further provide an objective reference to the urban planning of regional population. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Boosting regression; Population growth prediction,"Wang C.-Y., Lee S.-J.",10.3390/e23060656,7.98,-1.63
-1,444,,2021,Article,"Machine learning approach to extract building footprint from high-resolution images: The case study of Makkah, Saudi Arabia","Extracting and identifying building boundaries from high-resolution images have been a hot topic in the field of remote sensing for years. Various methods including geometric, radiometric, object based and edge detection were previously deliberated and implemented in different studies in the context of building extraction. Nevertheless, the reliability of extraction process is mainly subject to user intervention. The current study proposes a new automatic morphology-based approach for extracting buildings using high-resolution satellite images of Al-Hudaybiyah region in the city of Makkah as a case study. The proposed technique integrates the support vector machine for extracting buildings that have bright and dark roofs. The appropriateness of this method has been examined by means of various indicators for example completeness, correctness and quality. Preliminary findings will illustrate the precision and accuracy of the used machine learning algorithm. Research results can provide a generic indicator to assist the planning authorities in achieving better urban planning processes taking into account all potential environmental, social and urban demands and requirements. © 2021 The Author(s) 2021. Published by Oxford University Press.",extract building footprint; high-resolution images; machine learning; Makkah,"Faisal K., Imam A., Majrashi A., Hegazy I.",10.1093/ijlct/ctaa099,5.62,0.72
-1,450,,2021,Article,A refined method of high-resolution remote sensing change detection based on machine learning for newly constructed building areas,"Automatic detection of newly constructed building areas (NCBAs) plays an important role in addressing issues of ecological environment monitoring, urban management, and urban planning. Compared with low-and-middle resolution remote sensing images, high-resolution remote sensing images are superior in spatial resolution and display of refined spatial details. Yet its problems of spectral heterogeneity and complexity have impeded research of change detection for high-resolution remote sensing images. As generalized machine learning (including deep learning) technologies proceed, the efficiency and accuracy of recognition for ground-object in remote sensing have been substantially improved, providing a new solution for change detection of high-resolution remote sensing images. To this end, this study proposes a refined NCBAs detection method consisting of four parts based on generalized machine learning: (1) pre-processing; (2) candidate NCBAs are obtained by means of bi-temporal building masks acquired by deep learning semantic segmentation, and then registered one by one; (3) rules and support vector machine (SVM) are jointly adopted for classification of NCBAs with high, medium and low confidence; and (4) the final vectors of NCBAs are obtained by post-processing. In addition, area-based and pixel-based methods are adopted for accuracy assessment. Firstly, the proposed method is applied to three groups of GF1 images covering the urban fringe areas of Jinan, whose experimental results are divided into three categories: high, high-medium, and high-medium-low confidence. The results show that NCBAs of high confidence share the highest F1 score and the best overall effect. Therefore, only NCBAs of high confidence are considered to be the final detection result by this method. Specifically, in NCBAs detection for three groups GF1 images in Jinan, the mean Recall of area-based and pixel-based assessment methods reach around 77% and 91%, respectively, the mean Pixel Accuracy (PA) 88% and 92%, and the mean F1 82% and 91%, confirming the effectiveness of this method on GF1. Similarly, the proposed method is applied to two groups of ZY302 images in Xi’an and Kunming. The scores of F1 for two groups of ZY302 images are also above 90% respectively, confirming the effectiveness of this method on ZY302. It can be concluded that adoption of area registration improves registration efficiency, and the joint use of prior rules and SVM classifier with probability features could avoid over and missing detection for NCBAs. In practical applications, this method is contributive to automatic NCBAs detection from high-resolution remote sensing images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Areas registration; Change detection; Deep learning; High-resolution remote sensing; Newly constructed building areas; SVM,"Wang H., Qi J., Lei Y., Wu J., Li B., Jia Y.",10.3390/rs13081507,6.33,1.5
-1,451,,2021,Conference Paper,Machine Learning Methods for Road Edge Detection on Fused Airborne Hyperspectral and LIDAR Data,"In the last decades, remote sensing sensors, such as hyperspectral systems or LiDAR scanners, have been used for urban mapping. However, an analysis in the urban environment is very complex in applications, e.g., road detection, city management, and urban planning. One of the important urban features is the detection of the road edges. In this study, an approach on multisensory hyperspectral and LiDAR data fusion (HL-Fusion) is introduced for road edge detection using different machine learning algorithms, such as Support Vector Machines, Random Forests, and Convolutional Neural Networks. The first results show that the Random Forest algorithm outperformed in the experiments on the study area at Oslo's surroundings in Norway. This study opens a window for further investigation on machine learning algorithms and a better understanding of HL-Fusion capabilities. © 2021 IEEE.",data fusion; Hyperspectral; LiDAR; machine learning; remote sensing; road edge detection,"Senchuri R., Kuras A., Burud I.",10.1109/WHISPERS52202.2021.9484007,5.57,1.03
-1,454,,2021,Conference Paper,"A study on vehicle detection through aerial images: Various challenges, issues and applications","Nowadays vehicle detection and counting at the border of countries, as well as states/cities, has become popular through aerial images because of security concerns. It will play a vital role to reduce the various crimes i.e. (children kidnapping, drug/alcohol smuggling, traffic misconduct, weapons smuggling, sexual misconduct and mission of country-related crime, etc.) at the border of the cities as well as countries. Vehicle detection and counting have various other applications like traffic management, parking allotment, tracking the rescue vehicle in hill areas, digital watermarking, vehicle tracking at the toll plaza and urban planning, etc. However, vehicle detection and counting task are very challenging and difficult because of the complex background, the small size of the vehicle, other similar visual appearance objects, distance, etc. Till now, traditional methodology introduced several robust algorithms which has limitations while extracting the features from aerial images. Recently, deep learning-based algorithms introduced and the outcomes of these algorithms are robust for such kind of applications in the area of computer vision. But accuracy of these algorithms is not optimized in aerial images because the deep learning algorithm required a huge amount of data to train the machine and the size of the object in aerial images is also too small. All these factors affecting the efficiency of the real-time device. This paper provides a brief description of traditional algorithms as well as machine learning and deep learning concepts to identifying the object through aerial images. The study has shown the comprehensive analysis of benchmark datasets and their parameters and corresponding challenges used by researchers and scientists in the area of object detection/tracking through aerial images. © 2021 IEEE.",Aerial Images; Machine Learning; Security; Vehicle,"Kumar S., Rajan E.G., Rani S.",10.1109/ICCCIS51004.2021.9397116,5.75,2.77
-1,455,,2021,Article,Fusion of airborne lidar point clouds and aerial images for heterogeneous land-use urban mapping,"The World Health Organization has reported that the number of worldwide urban residents is expected to reach 70% of the total world population by 2050. In the face of challenges brought about by the demographic transition, there is an urgent need to improve the accuracy of urban land-use mappings to more efficiently inform about urban planning processes. Decision-makers rely on accurate urban mappings to properly assess current plans and to develop new ones. This study investigates the effects of including conventional spectral signatures acquired by different sensors on the classification of airborne LiDAR (Light Detection and Ranging) point clouds using multiple feature spaces. The proposed method applied three machine learning algorithms—ML (Maximum Likelihood), SVM (Support Vector Machines), and MLP (Multilayer Perceptron Neural Network)—to classify LiDAR point clouds of a residential urban area after being geo-registered to aerial photos. The overall classification accuracy passed 97%, with height as the only geometric feature in the classifying space. Misclassifications occurred among different classes due to independent acquisition of aerial and LiDAR data as well as shadow and orthorectification problems from aerial images. Nevertheless, the outcomes are promising as they surpassed those achieved with large geometric feature spaces and are encouraging since the approach is computationally reasonable and integrates radiometric properties from affordable sensors. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Bootstrap aggregation; K-fold cross-validation; LiDAR classification; LiDAR-aerial geo-registration; LiDAR-aerial integration; Maximum likelihood; Neural networks; Supervised machine learning; Support vector machines; Urban land-use,"Megahed Y., Shaker A., Yan W.Y.",10.3390/rs13040814,5.12,1.23
1,459,,2021,Article,"Using satellite data to analyse raw material consumption in Hanoi, Vietnam","In this work, we provide an innovative route for analysing urban expansion and population growth and their link to the consumption of construction materials by combining satellite data with material consumption analysis within the Hanoi Province (Vietnam). Urban expansion is investigated with the use of landcover maps for the period 1975–2020 derived from satellite. During this period, artificial surfaces and agricultural areas have increased by 11.6% and 15.5%, re-spectively, while forests have decreased by 26.7%. We have used publicly available datasets to calculate and forecast the construction materials consumption and measure its statistical correla-tion with urban expansion between 2007 and 2018. Our results show that official figures for sand consumption are currently underestimated, and that by 2030, steel and sand and gravel consumption will increase even further by three and two times, respectively. Our analysis uses a new method to assess urban development and associated impacts by combining socio-economic and Earth Observation datasets. The analysis can provide evidence, underpin decision-making by au-thorities, policymakers, urban planners and sustainability experts, as well as support the development of informed strategies for resource consumption. It can also provide important information for identifying areas of land conservation and ecological greenways during urban planning. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Cloud computing; Construction materials; Land cover; Machine learning; Material consumption analysis,"Novellino A., Brown T.J., Bide T., Anh N.T.T., Petavratzi E., Kresse C.",10.3390/rs13030334,7.85,-0.81
0,460,,2021,Article,Use of deep learning models in street-level images to classify one-story unreinforced masonry buildings based on roof diaphragms,"In this paper, we explore the potential of convolutional neural networks to classify street-level imagery of one-story unreinforced masonry buildings (MURs) according to the flexibility of the roof diaphragm (rigid or flexible). This information is critical for vulnerability studies, disaster risk assessments, disaster management strategies, etc., and is of great relevance in cities where unreinforced masonry is the most common building typology or where the majority of the population resides in such buildings. Our contribution could be useful for local governments of cities in developing countries seeking to significantly reduce the number of deaths caused by disasters. Our research results indicate that VGG19 is the convolutional neural network architecture with the best performance, with an accuracy of 0.80, a precision of 0.88, and a recall of 0.84. The results are encouraging and could be used to reduce the amount of resources (both human and economic) for the development of detailed exposure models for unreinforced masonry buildings. © 2020 Elsevier Ltd",Convolutional neural networks; Deep learning; Diaphragm; Risk assessment; Seismic risk; Unreinforced masonry; Urban planning,"Rueda-Plata D., González D., Acevedo A.B., Duque J.C., Ramos-Pollán R.",10.1016/j.buildenv.2020.107517,5.59,2.01
0,465,,2021,Article,Using 3D Convolution and Multimodal Architecture For Earthquake Damage Detection Based on Satellite Imagery and Digital Urban Data,"When a large earthquake occurs, it is quite important to quickly figure out the damage distribution of housing structures for disaster prevention measures. Currently, the information is confirmed manually by local public organizations, which takes a lot of time. Therefore, a method is required for gathering the information more swiftly and objectively. In this work, a novel method for detecting damage to single buildings from a set of multi-temporal satellite images is developed by applying a recent machine learning approach. The damage detection system is designed as a deep learning model that uses multimodal data, consisting of optical satellite images and structural attributes. The proposed method achieved over 90% detection accuracy on damaged housing in the affected area of 2016 Kumamoto earthquake, Japan from satellite images taken by Pleiades as well as digital urban data. CCBY",3D convolution; Buildings; earthquake damage detection; Earthquakes; Feature extraction; multimodal learning; Remote sensing; satellite imagery; Satellites; Solid modeling; spatio-temporal data; Three-dimensional displays,"Miyamoto T., Yamamoto Y.",10.1109/JSTARS.2021.3102701,5.88,2.08
0,469,,2021,Article,Satellite derived bathymetry using deep learning,"Coastal development and urban planning are facing different issues including natural disasters and extreme storm events. The ability to track and forecast the evolution of the physical characteristics of coastal areas over time is an important factor in coastal development, risk mitigation and overall coastal zone management. Traditional bathymetry measurements are obtained using echo-sounding techniques which are considered expensive and not always possible due to various complexities. Remote sensing tools such as satellite imagery can be used to estimate bathymetry using incident wave signatures and inversion models such as physical models of waves. In this work, we present two novel approaches to bathymetry estimation using deep learning and we compare the two proposed methods in terms of accuracy, computational costs, and applicability to real data. We show that deep learning is capable of accurately estimating ocean depth in a variety of simulated cases which offers a new approach for bathymetry estimation and a novel application for deep learning. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Deep learning; Earth observation; Machine learning; Regression; Satellite-derived bathymetry,"Al Najar M., Thoumyre G., Bergsma E.W.J., Almar R., Benshila R., Wilson D.G.",10.1007/s10994-021-05977-w,6.71,2.21
1,471,,2021,Book Chapter,"Object-Oriented Approach for Urbanization Growth by Using Remote Sensing and GIS Techniques: A Case Study in Hilla City, Babylon Governorate, Iraq","High rate of urbanization coupled with population growth has led to unexpected land use and land cover changes in Hilla city, which is located in the Babylon governorate of Iraq. Understanding and quantifying the spatiotemporal dynamics of the urban land use and land cover changes, as well as the driving factors behind them, are therefore vital in order to design appropriate policies and monitoring mechanisms to govern urban growth. This study analyzes land use and land cover changes over Hilla city through remote sensing and GIS (Geographical Information System) techniques. IKONOS satellite imagery from years 2000, 2005, and 2011 was collected and pre-processed using ENVI and ArcGIS, which then goes through an object-based supervised image classification stage to generate land use and land cover maps. The classification is performed using the statistical machine learning algorithm, SVM (Support Vector Machine). The confusion matrix and kappa coefficients are used to evaluate the overall accuracy of the results. The statistical results obtained enable assessment of class changes from years 2000 to 2011 and also identify the gain and loss of the built-up areas in relation to other land cover classes. The results also allow assessment of the spatial trend of these built-up areas. Ultimately, forecasts can be made to predict expected future class changes in 2026 and 2036. Generally, the results of this study show increased expansions of built-up areas, i.e., from 8.14% in 2000 to 14.53% in 2005 and up to 18.36% in 2011. All this was at the expense of bare land areas. Simultaneously, there was an increased expansion of vegetation/agricultural land area, specifically from 36.14% in 2000 to 41.71% in 2005 and 45.13% in 2011. The spatial trend also shows that the growth of built-up areas is focused in the southwestern part of Hilla city. In all, we foresee that the findings of this study can provide a good visual resource for decision-makers to perform more efficient urban planning. © 2021, Springer Nature Switzerland AG.",Built-up areas; Land use dynamics; Spatial trend; Support vector machine; Urbanization,"Mahmoud A.S., Kalantar B., Al-Najjar H.A.H., Moayedi H., Halin A.A., Mansor S.",10.1007/978-3-030-71945-6_3,7.23,-0.49
-1,474,,2021,Article,Analysis of built-up areas of small polish cities with the use of deep learning and geographically weighted regression,"Small cities are an important part of the settlement system, a link between rural areas and large cities. Although they perform important functions, research focuses on large cities and metropolises while marginalizing small cities, the study of which is of great importance to progress in social sciences, geography, and urban planning. The main goal of this paper was to verify the impact of selected socio-economic factors on the share of built-up areas in 665 small Polish cities in 2019. Data from the Database of Topographic Objects (BDOT), Sentinel-2 satellite imagery from 2015 and 2019, and Local Data Bank by Statistics Poland form 2019 were used in the research. A machine learning segmentation procedure was used to obtain the data on the occurrence of built-up areas. Hot Spot (Getis-Ord Gi*) analysis and geographically weighted regression (GWR) was applied to explain spatially varying impact of factors related to population, spatial and economic development, and living standards on the share of built-up areas in the area of small cities. Significant association was found between the population density and the share of built-up areas in the area of the cities studied. The influence of the other socio-economic factors examined, related to the spatial and economic development of the cities and the quality of life of the inhabitants, showed great regional variation. The results also indicated that the share of built-up areas in the area of the cities under study is a result of the conditions under which they were established and developed throughout their existence, and not only of the socio-economic factors affecting them at present. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Build-up areas; Deep learning; GWR; Hot Spot (Getis-Ord Gi*); Poland; Small cities,"Adamiak M., Jażdżewska I., Nalej M.",10.3390/geosciences11050223,7.73,-1.3
-1,485,,2021,Article,Analyzing the spatiotemporal uncertainty in urbanization predictions,"With the availability of computational resources, geographical information systems, and remote sensing data, urban growth modeling has become a viable tool for predicting urbanization of cities and towns, regions, and nations around the world. This information allows policy makers, urban planners, environmental and civil organizations to make investments, design infrastructure, extend public utility networks, plan housing solutions, and mitigate adverse environmental impacts. Despite its importance, urban growth models often discard the spatiotemporal uncertainties in their prediction estimates. In this paper, we analyzed the uncertainty in the urban land predictions by comparing the outcomes of two different growth models, one based on a widely applied cellular automata model known as the SLEUTH CA and the other one based on a previously published machine learning framework. We selected these two models because they are complementary, the first is based on human knowledge and pre-defined and understandable policies while the second is more data-driven and might be less influenced by any a priori knowledge or bias. To test our methodology, we chose the cities of Jiaxing and Lishui in China because they are representative of new town planning policies and have different characteristics in terms of land extension, geographical conditions, growth rates, and economic drivers. We focused on the spatiotemporal uncertainty, understood as the inherent doubt in the predictions of where and when will a piece of land become urban, using the concepts of certainty area in space and certainty area in time. The proposed analyses in this paper aim to contribute to better urban planning exercises, and they can be extended to other cities worldwide. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Machine learning; SLEUTH CA; Spatiotemporal uncertainty; Urban growth; Urban planning tools; Urban science; Urbanization processes,"Gómez J.A., Guan C., Tripathy P., Duque J.C., Passos S., Keith M., Liu J.",10.3390/rs13030512,7.74,-1.47
0,486,,2021,Article,UVid-Net: Enhanced Semantic Segmentation of UAV Aerial Videos by Embedding Temporal Information,"Semantic segmentation of aerial videos has been extensively used for decision making in monitoring environmental changes, urban planning, and disaster management. The reliability of these decision support systems is dependent on the accuracy of the video semantic segmentation algorithms. The existing CNN-based video semantic segmentation methods have enhanced the image semantic segmentation methods by incorporating an additional module such as LSTM or optical flow for computing temporal dynamics of the video which is a computational overhead. The proposed research work modifies the CNN architecture by incorporating temporal information to improve the efficiency of video semantic segmentation. In this work, an enhanced encoder-decoder based CNN architecture (UVid-Net) is proposed for unmanned aerial vehicle (UAV) video semantic segmentation. The encoder of the proposed architecture embeds temporal information for temporally consistent labeling. The decoder is enhanced by introducing the feature-refiner module, which aids in accurate localization of the class labels. The proposed UVid-Net architecture for UAV video semantic segmentation is quantitatively evaluated on extended ManipalUAVid dataset. The performance metric mean Intersection over Union of 0.79 has been observed which is significantly greater than the other state-of-the-art algorithms. Further, the proposed work produced promising results even for the pretrained model of UVid-Net on urban street scene by fine tuning the final layer on UAV aerial videos. © 2008-2012 IEEE.",Deep learning; semantic segmentation; transfer learning; U-Net; unmanned aerial vehicle (UAV) video,"Girisha S., Verma U., Manohara Pai M.M., Pai R.M.",10.1109/JSTARS.2021.3069909,6.05,2.75
1,488,,2021,Article,Estimating Socio-Economic Parameters via Machine Learning Methods Using Luojia1-01 Nighttime Light Remotely Sensed Images at Multiple Scales of China in 2018,"Mapping socio-economic indicators with a raster format is still a great challenge. The nighttime light (NTL) datasets have been widely utilized to estimate the socio-economic parameters. However, the precision of the published datasets was too coarse to meet related issues such as flood losses assessment, urban planning, and epidemiological studies. The present study calibrated gross domestic product (GDP), population (POP), electric consumption (EC), and urban build-up area (B-A) at 100 m resolution for 45 cities of China in 2018 using Luojia1-01 NTL datasets via random forest (RF) as well as geographically weighted regression (GWR) model. The linear regression (LR), back propagation neural network (BPNN), and support vector machine (SVM) methods were selected for comparison with GWR and RF models. Besides, the Suomi National Polar-Orbiting Partnership-Visible Infrared Imaging Radiometer Suite (NPP-VIIRS) was chosen for comparison with Luojia1-01. The ten-folded cross-validation (CV) has been used for evaluating accuracy at county and city scales. Finally, the distribution maps of socio-economic parameters were illustrated and some findings were obtained. First, the validation results revealed that the calibration at the city-scale outperformed the county or district scale. Second, the precision of the Luojia1-01 NTL dataset surpassed the NPP-VIIRS NTL dataset on the same administrative scale except for some specific situations. Third, the precision of the simulation for the gross domestic product (GDP) is the highest than the others, followed by electric consumption (EC), build-up area (B-A), and population (POP). Fourth, the optimum model varied according to the socio-economic parameters. Fifth, the distribution of socio-economic parameters exhibited obvious spatial heterogeneity. This paper can supply scientific support for calibrating socio-economic parameters in other regions. © 2013 IEEE.",China; GWR; Luojia1-01; machine learning; multiple scales; NPP/VIIRS; socio-economic parameters,"Guo B., Bian Y., Zhang D., Su Y., Wang X., Zhang B., Wang Y., Chen Q., Wu Y., Luo P.",10.1109/ACCESS.2021.3059865,8.33,-0.59
-1,497,,2020,Article,Urban population distribution mapping with multisource geospatial data based on zonal strategy,"Mapping population distribution at fine resolutions with high accuracy is crucial to urban planning and management. This paper takes Guangzhou city as the study area, illustrates the gridded population distribution map by using machine learning methods based on zoning strategy with multisource geospatial data such as night light remote sensing data, point of interest data, land use data, and so on. The street-level accuracy evaluation results show that the proposed approach achieved good overall accuracy, with determinant coefficient (R2) being 0.713 and root mean square error (RMSE) being 5512.9. Meanwhile, the goodness of fit for single linear regression (LR) model and random forest (RF) regression model are 0.0039 and 0.605, respectively. For dense area, the accuracy of the random forest model is better than the linear regression model, while for sparse area, the accuracy of the linear regression model is better than the random forest model. The results indicated that the proposed method has great potential in fine-scale population mapping. Therefore, it is advised that the zonal modeling strategy should be the primary choice for solving regional differences in the population distribution mapping research. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Guangzhou; Point of interest; Population mapping; Random forest; Zonal model,"Zhao G., Yang M.",10.3390/ijgi9110654,8.29,-1.04
1,503,,2020,Conference Paper,On the development of a novel approach for identifying perennial drainage in Southern Brazil: A study case integrating sentinel-2 and high-resolution digital elevation models with machine learning techniques,"Riparian vegetation plays a key role in maintaining water quality and preserving the ecosystems along riverine systems, as they prevent soil erosion, retain water by increased infiltration, and act as a buffer zone between rivers and their surroundings. Within urban spaces, these areas have also an important role in preventing illegal occupation in areas of hydrologic risk, such as in floodplains. The goal of this research is to propose a framework for identifying areas of permanent protection associated with perennial drainage, utilizing satellite imagery and digital elevation models (DEM) in association with machine learning techniques. The specific objectives include the development of a decision tree to retrieve perennial drainage over high resolution, 1-meter DEM's, and the development of digital image processing workflow to retrieve surface water bodies from Sentinel-2 imagery. In-situ information on perennial and ephemeral conditions of streams and rivers were obtained to validate our results, that happened in the first trimester of 2020. We propose a minimum of 7 days without precipitation prior to in-situ validation, for more accurate assessment of streamflow conditions, in order to minimize impacts of surface water runoff in flow regime. The proposed method will benefit decision makers by providing them with reliable information on drainage network and their buffer zones, as well as yield detailed mapping of the areas of permanent protection that are key to urban planning and management. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.",Digital Elevation Models; Machine Learning; Perennial Drainage; Riparian Vegetation; Sentinel-2,"Montibeller A., Vilela M., Hino F., Mallmann P., Nadas M., Caruso F., Delabary H.",10.5194/isprs-archives-XLIII-B3-2020-161-2020,7.07,0.07
0,504,,2020,Conference Paper,A NOVEL SELF-TAUGHT LEARNING FRAMEWORK USING SPATIAL PYRAMID MATCHING for SCENE CLASSIFICATION,"Remote sensing earth observation images have a wide range of applications in areas like urban planning, agriculture, environment monitoring, etc. While the industrial world benefits from availability of high resolution earth observation images since recent years, interpreting such images has become more challenging than ever. Among many machine learning based methods that have worked out successfully in remote sensing scene classification, spatial pyramid matching using sparse coding (ScSPM) is a classical model that has achieved promising classification accuracy on many benchmark data sets. ScSPM is a three-stage algorithm, composed of dictionary learning, sparse representation and classification. It is generally believed that in the dictionary learning stage, although unsupervised, one should use the same data set as classification stage to get good results. However, recent studies in transfer learning suggest that it might be a better strategy to train the dictionary on a larger data set different from the one to classify. In our work, we propose an algorithm that combines ScSPM with self-taught learning, a transfer learning framework that trains a dictionary on an unlabeled data set and uses it for multiple classification tasks. In the experiments, we learn the dictionary on Caltech-101 data set, and classify two remote sensing scene image data sets: UC Merced LandUse data set and Changping data set. Experimental results show that the classification accuracy of proposed method is compatible to that of ScSPM. Our work thus provides a new way to reduce resource cost in learning a remote sensing scene image classifier. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.",High Resolution Imagery; Remote Sensing; Scene Classification; Self-taught Learning; Spatial Pyramid Matching,"Yang Y., Zhu D., Ren F., Cheng C.",10.5194/isprs-archives-XLIII-B2-2020-725-2020,6.7,2.42
0,505,,2020,Conference Paper,Object detection of aerial image using mask-region convolutional neural network (mask R-CNN),"The most fundamental task in remote sensing data processing and analysis is object detection. It plays an important role in classification and very useful for various applications such as forestry, urban planning, agriculture, land use and land cover mapping, etc. However, it has many challenges to find an appropriate method due to many variations in the appearance of the object in image. The object may have occlusion, illumination, viewpoint variation, shadow, etc. Many object detection method has been researched and developed. Recently, the development of various machine learning-based methods for object detection has been increasing. Among of them are methods based on artificial neural network, deep learning and its derivatives. In this research, object detection method of aerial image by using mask-region convolutional neural network (mask-R CNN) is developed. The result shows that this method gives a significant accuracy by increasing the image training and epoch time. © 2020 IOP Publishing Ltd. All rights reserved.",,"Musyarofah, Schmidt V., Kada M.",10.1088/1755-1315/500/1/012090,6.12,2.88
0,506,,2020,Conference Paper,A big bang-big crunch type-2 fuzzy logic system for explainable semantic segmentation of trees in satellite images using HSV color space,"In recent years, new sensor technologies have increased the accessibility of high-resolution satellite images. The information in these images can help to improve activities like urban planning and growth analysis of cities. Additionally, information extracted from these images can be used for taking decisions related to infrastructure planning, e.g. identifying objects that might interfere with network assets like underground cables. To be able to justify the cost of network planning decisions a high degree of interpretability is required. Convolutional Neural Networks (CNNs) are the state of the art for segmenting these images, but like any black box model they do not offer any explanation for their output. In this paper, we present an approach on how to use a Fuzzy Logic System (FLS) for performing explainable semantic segmentation of trees in satellite images. The FLS uses the HSV (hue, saturation, value) of the pixels as inputs and was optimized by using an evolutionary algorithm called Big Bang Big Crunch. The best configuration for the Interval Type-2 FLS has an Intersection over Union metric measure of 60.6%, which is close to the results obtained from neural network, however the proposed FLS provides interpretable outputs which is highly needed for the real-world operation especially in the telecommunication domain. © 2020 IEEE.",Explainable AI; Fuzzy Logic System; Interpretable models; Neural Networks; Satellite images; Semantic segmentation,"Leon-Garza H., Hagras H., Pena-Rios A., Conway A., Owusu G.",10.1109/FUZZ48607.2020.9177611,6.36,1.78
1,521,,2020,Conference Paper,"Remote sensing and GIS approach for environmental green areas planning using Landsat satellite imagery, Dubai-UAE","Over the last decade, Dubai emirate witnessed a vast, rapidly growing population, that doubled since 2008. Nowadays, Dubai considers as the most populated emirate within the United Arab Emirates (UAE). With such an increasing population and new urban developments, sustainable urban planning procedures play an essential role in Dubai's environmental quality such as air quality, and pollution. Therefore, this study will utilize the Remote Sensing and Geographic Information system (GIS) to investigate Dubai's environmental quality by addressing and locating green areas and pollution percentages within each district. The study methodology is divided into three steps. First, Landsat Satellite medium spatial resolution and multi-spectral imagery will be used as an input for segmentation and object-based analysis. Considering the spectral and spatial signatures for green areas machine learning techniques will be adopted to select the most significant features to classify and extract green areas. Second, using environmental relational indices, green areas percentages will be quantitatively compared to Sentinel air quality data, such as NO2 and SO2, as well as the population density maps. Finally, GIS techniques will be used to create Dubai Environmental Critical Map (DECM), to locate districts with limited green areas and high pollution to improve environmental standards. The study results can be used as a measure for the municipality policymakers to ensure sustainable urban development for a healthy living. © 2020 SPIE",Dubai Environmental Vulnerability Map (DEVM); Geographic Information system (GIS); Remote Sensing,"Aldogom D., Mansoori S.A., AlMaazmi A., Nazzal T.",10.1117/12.2573904,6.92,-0.12
-1,522,,2020,Conference Paper,A Machine Learning-Based Method for Predicting Urban Land Use,"Land use is one of the most basic elements of urban management. In urban planning and design, land use is often determined by experience and case studies. However, the development of urbanization has led to a combinatory trend for land use, and the land use of a plot is always impacted by the surrounding environment. In such a complex situation, it is difficult to find hidden relationships among types of land use by humans alone. Within artificial intelligence, machine learning can help find correlations among data. This paper presents a new method for learning the rules relating the known land use data and predicting the land use of a target plot by constructing an artificial neural network. We take Nanjing as a specific case and study the logic of its land use. The results not only demonstrate associations between the surroundings and the target but also show the feasibility of a combinatory land use index in urban planning and design. © 2020 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.",Artificial neural network; Land use; Machine learning; Urban planning and design,"Xia X., Tong Z.",,7.2,-1.38
-1,531,,2020,Article,Mapping Urban Slum Settlements Using Very High-Resolution Imagery and Land Boundary Data,"Accurate mapping of slums is crucial for urban planning and management. This article proposes a machine learning, hierarchical object-based method to map slum settlements using very high-resolution (VHR) imagery and land boundary data to support slum upgrading. The proposed method is tested in Kingston Metropolitan Area, Jamaica. First, the VHR imagery is classified into major land cover classes (i.e., the initial land cover map). Second, the VHR imagery and land boundary layer are used to obtain homogenous neighborhoods (HNs). Third, the initial land cover map is used to derive multiple context, spectral, and texture image features according to the local physical characteristics of slum settlements. Fourth, a machine-learning classifier, classification and regression trees, is used to classify HNs into slum and nonslum settlements using only the effective image features. Finally, reference data collected manually are used to assess the accuracy of the classification. In the training site, an overall accuracy of 0.935 is achieved. The effective image indicators for slum mapping include the building layout, building density, building roof characteristics, and distance from buildings to gullies. The classifier and those features selected from the training site are further used to map slums in two validating sites to assess the transferability of our approach. Overall accuracy of the two validating sites reached 0.928 and 0.929, respectively, suggesting that the features and classification model obtained from one site has the potential to be transferred to other areas in Jamaica and possibly other developing Caribbean countries with similar situation and data availability. © 2008-2012 IEEE.",Classification and regression trees (CART); Jamaica; object-oriented classification; slum settlements; very high-resolution (VHR) image,"Williams T.K.-A., Wei T., Zhu X.",10.1109/JSTARS.2019.2954407,6.41,0.39
-1,532,,2020,Book Chapter,Comparison of performance of artificial neural network (ANN) and random forest (RF) in the classification of land cover zones of urban slum region,"India is one of the world’s largest economies and economic growth has remained continuous. This has led to accelerating urbanization which requires proper planning and monitoring. As the urban areas are expanding, urban slum areas are also increasing along with it. These growing urban slum areas require proper observation so that existing resources can be employed to provide these regions with the best possible livelihood conditions. For this purpose, urban slum areas as well as surrounding land resources should be well identified and classified so that the existing land resources can be appropriately utilized for future implementation of development activities. Machine learning classification algorithms are found to be very suitable for the identification and classification of remotely sensed images. Their efficiency in feature identification and extraction has established these algorithms as important tools in decision making. In this study, our major objective is to identify and classify different land cover zones in the urban slums areas of Chingrajpara area of Chhattisgarh using remotely-sensed images. For this purpose, high-resolution images, collected using unmanned aerial vehicles (UAVs), are used and these images are classified into different land cover features using two different machine learning algorithms Artificial Neural Network (ANN) and Random Forest (RF). The results obtained show that the overall accuracy achieved by ANN and RF are 72.6% and 84.35% respectively. The study highlights the role and importance of landcover classification for future planning and management. © Springer Nature Switzerland AG 2020.",Artificial neural network (ANN); Random forest (RF); Unmanned aerial vehicles (UAVs),"Tyagi D., Haq M.A., Rahaman G., Baral P., Datta J.",10.1007/978-3-030-37393-1_20,7.44,0.88
0,535,,2019,Conference Paper,Urban Intelligent Navigator for Drone Using Convolutional Neural Network (CNN),"It is still a difficult and challenging task for a drone to maneuver autonomously at low altitude in the urban environments. This is due to the complexity of the urban environment and its unpredictability. Many researches have been carried out in the past decades until recent time, to find a way to solve this problem using powerful sensors such as laser rangefinder sensor, RGB-D camera, stereo vision system, LIDAR and computer vision methods. This paper is aimed to present an urban intelligent navigator for drone using CNN (convolutional neural network). The application of computer vision (object detection) is cheap and has low power consumption compared to other kinds of vision systems. The machine learning allows a drone to detect and recognize all the objects and obstacles on the roads, which can block drone's way. One thousand images were captured of six different street objects (tree, lamp, bump sign, free-smoking sign, no-horn sign, and roof-wall). Those images were used as a dataset to create a machine learning using Faster R-CNN (region convolutional neural network) method. Three machine-learning models were created using different parameters for each model. The controlled parameters are the initial learning rate and the batch-size. Only the third model could successfully detect and recognize all the objects at a specified location showing 98% accuracy. © 2019 IEEE.",Convolution neural networks; Faster R-CNN; Object detection; object recognition,"Moteir I.G.M.I., Ismail K., Zawawi F.M., Azhar M.M.M.",10.1109/SmartNets48225.2019.9069781,5.76,2.72
1,537,,2019,Article,Integrating activity-based geographic information and long-term remote sensing to characterize urban land use change,"The land use structure is a key component to understand the complexity of urban systems because it provides a snapshot of urban dynamics and how people use space. This paper integrates socially sensed activity data with a remotely sensed land cover product in order to infer urban land use and its changes over time. We conducted a case study in theWashington D.C.-Baltimore metropolitan area to identify the pattern of land use change from undeveloped to developed land, including residential and non-residential uses for a period covering 1986-2008. The proposed approach modeled physical and behavioral features of land parcels from a satellite-based impervious surface cover change product and georeferenced Tweets, respectively. A model assessment with random forests classifiers showed that the proposed classification workflow could classify residential and non-residential land uses at an accuracy of 81%, 4% better than modeling the same land uses from physical features alone. Using the timestamps of the impervious surface cover change product, the study also reconstructed the timeline of the identified land uses. The results indicated that the proposed approach was capable of mapping detailed land use and change in an urban region, and represents a new and viable way forward for urban land use surveying that could be especially useful for surveying and tracking changes in cities where traditional approaches and mapping products (i.e., from remote sensing products) may have a limited capacity to capture change. © 2019 by the authors.",Activity patterns; Land use; Machine learning; Social sensing; Twitter,"Fu C., Song X.-P., Stewart K.",10.3390/rs11242965,8.13,-0.42
0,538,,2019,Conference Paper,THE POTENTIAL of BUILDING DETECTION from SAR and LIDAR USING DEEP LEARNING,"The introduction of airborne Synthetic Aperture Radar (SAR) approach has successfully addressed several challenges for mapping and surveying applications Unlike other conventional sensors, airborne SAR mapping approach offers practicality and significant cost savings for the nation minimizing the need for ground control points on the ground in addition to providing high-resolution, day-and-night, cloud coverage and weather independent images, which in turn provides faster turnaround times for creation of large area geospatial data. Up-to-date building map is necessary to guide the decision making in many fields to understand the urban dynamics such as in disaster management, population estimation, planning and many other applications. Whilst mapping and surveying work using airborne SAR have started to capture many interest among surveyors, professionals and practitioners abroad, Malaysia however is still lacking behind in term of the knowledge and the usage of this technology together with Deep Learning, Machine Learning approach especially in building extraction for topographic mapping and urban planning and development. Deep learning is a subset of the machine learning algorithm. Recently, Deep Learning has been proposed to solve traditional artificial intelligent problems. In order to develop a sustainable national geospatial infrastructure for years to come, the integration between airborne SAR and other sensors as such LIDAR is therefore essential in Malaysia and in high demand for urban planning and management. Thus, this paper reviews current techniques and future trends of multi-sources Remote Sensing for building extraction. © 2019 Z. Nordin et al.",building extraction; deep learning; feature extraction; lidar; orthophoto; synthetic aperture radar (SAR),"Nordin Z., Shafri H.Z.M., Abdullah A.F., Hashim S.J.",10.5194/isprs-archives-XLII-4-W16-489-2019,6.12,1.85
1,539,,2019,Conference Paper,EVALUATION of ADVANCED DATA MINING ALGORITHMS in LAND USE/LAND COVER MAPPING,"For environmental monitoring, land-cover mapping, and urban planning, remote sensing is an effective method. In this paper, firstly, for land use land cover mapping, Landsat 8 OLI image classification based on six advanced mathematical algorithms of machine learning including Random Forest, Decision Table, DTNB, Multilayer Perceptron, Non-Nested Generalized Exemplars (NN ge) and Simple Logistic is used. Then, results are compared in the terms of Overall Accuracy (OA), Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) for land use land cover (LULC) mapping. Based on the training and test datasets, Simple Logistic had the best performance in terms of OA, MAE and RMSE values of 99.9293, 0.0006 and 0.016 for training dataset and values of 99.9467, 0.0005 and 0.0153 for the test dataset. © 2019 A. Jamali.",data mining; image classification; land use land cover; lulc; machine learning,"Jamali A., Abdul Rahman A.",10.5194/isprs-archives-XLII-4-W16-283-2019,7.43,0.52
1,540,,2019,Conference Paper,Machine Learning for Strategic Urban Planning,"Data mining is an important part of strategic planning for the development of modern urban settlement with capacities to accommodate population explosion. Developing countries are fast becoming urbanized giving the developments and opportunities that are lacking in rural areas. Data regarding urban development such as satellite image need to be analysed to ascertain the possibilities for further development or opening up of new settlements. This work presents a binary sub-pixel and feature based method of classification to detect water bodies and vegetation in earth observatory images. In this work, the images were subjected data pre-processing, feature extraction, and analysed the data using machine learning classification method to detection regions that support urban expansion or development of new settlement. The proposed method achieved 88.93% accuracy and 0.06% RMSE. © 2019 IEEE.",feature engineering; Haar-cascade; machine learning; object detection; Satellite image,"Odaudu S.N., Umoh I.J., Mu'Azu M.B., Adedokun E.A.",10.1109/NigeriaComputConf45974.2019.8949665,6.7,0.09
1,548,,2019,Conference Paper,Land cover classification and change detection analysis of multispectral satellite images using machine learning,"Land cover classification and change detection analysis based on remote sensing images using machine learning algorithm has become one of the important factors for environmental management and urban planning. We select Yangon as the study area because the government faces many problems in urban planning sectors due to the population growth and urban sprawl. Therefore, the proposed method aims to perform the land cover classification in Yangon using Random Forest (RF) classifier in Google Earth Engine (GEE) and post-classification change detection between 1987 and 2017 with 5 years interval periods are evaluated. Despite land cover classifications using satellite imagery have been executed in the past decades, the classification of remotely sensed data integrating with multiple spectral, temporal and textural features and processing time for classification using time series data still have limitations. To overcome these limitations, features extracted from Sentinel-2, Landsat-8, Landsat-7, Landsat-5 and Open Street Map (OSM) are executed for classification and cloud-based GEE platform is used to reduce the processing time. Some spectral indexes such as NDVI, NDBI and slope from SRTM are calculated to achieve better classification. Land cover classification is performed by using the RF classifier with the different bands' combination. Land cover classification map with 7 classes (Shrub Land, Bare Land, Forest, Vegetation, Urban Area, Lake and River) is obtained with the overall accuracy of 96.73% and kappa statistic of 0.95 for 2017. Finally, change detection analysis over 30 years is performed and the significant changes in build-up, bare land, and agriculture have been resulted. © 2019 SPIE.",Change detection; Classification; Google Earth Engine; Land cover; Machine learning; Random forest,"Soe Thwal N., Ishikawa T., Watanabe H.",10.1117/12.2532988,7.78,0.61
1,564,,2018,Conference Paper,"Urban sprawl modeling of Lahore, Pakistan using machine learning techniques","Population is the fundamental concentration because population is related with all resources and urban sprawl, an effect of socioeconomic improvement in specific conditions, has progressively turned into a noteworthy issue confronting numerous metropolitan zones. This is very essential to understand the significant factors affecting the population. This research analyzed the spatial and temporal characteristics of metropolitan city Lahore, Pakistan. Supervised classification method is applied to examine the urban expansion and to evaluate signatures of Lahore city into four categories (urban, vegetation, bare land and water bodies). For the land cover change analysis and to predict the urban sprawl in future different techniques and methods can be used and out of numerous, geospatial techniques like (MOLUSCE) QGIS plug-in, GIS along with remote sensing is used. In this study, Landsat V and VIII satellite images of 1998, 2008 and 2017 were used to classify the urban expansion. The precision appraisal was completed for characterized maps. Distinctive images Transition probability matrix and region change were acquired by utilizing plug-in created in QGIS and future year 2036 urban expansion was obtained. In this study, an attempt was made to develop a relationship between urban sprawl and population of Lahore. In light of accessible informational index, from 2017 to 2036 the change in urban area is 40% while a 367.02 sq.km loss in vegetation is chronicled. The majority of the urban sprawl occurred along primary roadways. The outcome demonstrates that urban region is relied upon to develop substantially higher in the year 2036 when contrasted with 2017. This analysis gives awareness of urban development and supports in macro and micro level urban planning, policy making in metropolitan cities. © 2018 Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018",GIS; Land Use and Land Cover; Landsat; Population; Remote Sensing,"Ahmed A., Sekimoto Y., Kashiyama T.",,7.67,-0.93
-1,568,,2018,Conference Paper,Automatic semantic segmentation for change detection in remote sensing images,"Change detection (CD) mainly focuses on the extraction of change information from multispectral remote sensing images of the same geographical location for environmental monitoring, natural disaster evaluation, urban studies, and deforestation monitoring. While capturing the Landsat imagery, there may occur data missing issues such as occlusion of cloud, camera sensor, and aperture artifacts. The existing machine learning approaches do not provide significant results. This paper proposes a DeepLab Dilated convolutional neural network (DL-DCNN) for semantic segmentation with the goal to occur the change map for earth observation applications. Experimental results reveal that the accuracy of the proposed change detection results provides improved results as compared with the existing algorithms and maps the semantic objects within the predefined class as change or no change. © Springer Nature Singapore Pte Ltd. 2018.",Change detection; Deep learning; Multispectral; Remote sensing,"Kulkarni T., Venugopal N.",10.1007/978-981-10-8569-7_34,6.46,1.86
-1,575,,2017,Conference Paper,A support vector machine approach on object based image analysis for feature extraction from high resolution images,"Satellite images are the most important available data sources for generation and updating of available maps. They have highly improved in terms of spatial, spectral and temporal resolutions and by the sheer volume of collected images, the necessity of simplification of automation in feature extraction. Road data play a key role in urban planning, traffic management, military applications, and vehicle navigation as well as for decision making in numerous applications. The faster updation of road infrastructure is a need because the technology has brought map in the hands of people in the form of mobile phones and tablets. Road detection is one of the major issues of the road infrastructure extraction. Its accuracy depends on the type of methodology used. An attempt is made here to analyse the first order, the co-occurrence texture features and image transforms useful for discriminating roads from other features specially the buildings. The identified dataset forms high dimension feature space and the Support Vector Machine is a theoretically superior machine learning methodology with great results in classification of high dimensional datasets. In the past, SVMs have been tested and evaluated only as pixel-based image classifiers. Moving from pixel-based techniques towards object-based representation, the dimensions of remote sensing imagery feature space increases significantly. An SVM approach for classification was followed, based on primitive image objects produces by a multi-resolution segmentation algorithm. The SVM procedure produced the final object classification results which were compared to the Nearest Neighbor classifier results and were found to give better results in OBIA domain. © 2017 ACRS. All rights reserved.",Feature Extraction; Grey-Level Co-occurrence textures; Object Based Image Analysis (OBIA); Support Vector Machine (SVM),"Kumar M., Srivastav S.K., Garg P.K.",,5.76,0.75
-1,576,,2017,Article,Urban inefficient industrial land recognition system based on augmented learning model,"From a salient point of view, urban planning has a significant impact on the expansion of the residential, industrial and commercial land. Land planning has a positive impact on the development of residential land but negatively affects the expansion of industrial, commercial and mining land, that is to say, the plot planned for construction land has a lower probability of transforming into construction land, which is not in line with common sense, indicating that the compilation of the land planning is far from the expansion of actual construction land. Therefore, this paper presents the urban inefficient industrial land recognition system based on augmented learning model. We adopt endogenous optimization method to determine the weight of each input factor, do not need to estimate parameters in advance, no correlation requirement to input and output variables, avoiding the input-output relationship of the expression and the index weight to determine the specific functional form of subjectivity. With this model, the urban planning model is then optimized to satisfy the general requirements.",Augmented learning; Inefficient industrial; Land recognition; Machine learning; Urban,"Rao Y., Dai D.",,6.98,-1.31
1,580,,2017,Conference Paper,Algorithm for modeling agricultural land cover classification and land surface temperature,"The rampant and unintended spread of urban areas resulted to the increase artificial component in the land cover types of the countryside bringing forth urban heat island (UHI). This paved the way to wide range of negative influences on the human health and environment which commonly relates to air pollution, drought, higher energy demand, and water shortage. The land cover also plays a relevant role in the process of understanding the interaction between ground surfaces with the local temperature. At the moment, depiction of the land surface temperature (LST) at city/municipality scale particularly in certain areas of Misamis Oriental, Philippines is inadequate as support to efficient mitigations and adaptations of the surface urban heat island (SUHI). Thus, this study purposely attempts to provide application on the Landsat 8 satellite data and low density Light Detection and Ranging (LiDAR) products in mapping out quality semi-Automated LST model and crop-level land cover classification in a local scale through theoretical and algorithm base approach utilizing the principle of data analysis subjected to object based model. The paper also aims to explore the relationship between the derived LST and land cover classification. The results of the presented model showed the ability of comprehensive data analysis, GIS functionalities and object based image analysis (OBIA) approach with the integration of machine learning intelligence on automating complex map production processes with considerable efficiency and high accuracy. The findings may potentially lead to expanded investigation of temporal dynamics of land surface UHI. It is worthwhile to note that the environmental significance of these interactions can provide microclimate perception, awareness and improved decision making for land use planning and characterization at local and neighborhood scale. As a result, it can aid in facilitating problem identification, support mitigations and adaptations more efficiently. © 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Landsat 8 OLI/TIRS; LiDAR; Local scale; Remote sensing,"Villar R.G., Pelayo J.L., Bantugan J., Opiso E.",,7.18,-0.34
