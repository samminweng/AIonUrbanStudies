[{"HDBSCAN_Cluster":-1,"DocId":1,"Cited by":315.0,"Year":2018,"Document Type":"Article","Title":"Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework","Abstract":"In this paper, we designed an end-to-end spectral-spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia. \u00a9 1980-2012 IEEE.","Author Keywords":"3-D deep learning; hyperspectral image classification; spectral-spatial feature extraction; spectral-spatial residual network (SSRN)","Authors":"Zhong Z., Li J., Luo Z., Chapman M.","DOI":"10.1109\/TGRS.2017.2755542","x":-4.1799998283,"y":4.5399999619},{"HDBSCAN_Cluster":-1,"DocId":3,"Cited by":181.0,"Year":2015,"Document Type":"Conference Paper","Title":"Building detection in very high resolution multispectral data with deep learning features","Abstract":"The automated man-made object detection and building extraction from single satellite images is, still, one of the most challenging tasks for various urban planning and monitoring engineering applications. To this end, in this paper we propose an automated building detection framework from very high resolution remote sensing data based on deep convolutional neural networks. The core of the developed method is based on a supervised classification procedure employing a very large training dataset. An MRF model is then responsible for obtaining the optimal labels regarding the detection of scene buildings. The experimental results and the performed quantitative validation indicate the quite promising potentials of the developed approach. \u00a9 2015 IEEE.","Author Keywords":"deep convolutional networks; extraction; ImageNet; Machine learning; man made objects","Authors":"Vakalopoulou M., Karantzalos K., Komodakis N., Paragios N.","DOI":"10.1109\/IGARSS.2015.7326158","x":-4.1700000763,"y":5.6799998283},{"HDBSCAN_Cluster":1,"DocId":12,"Cited by":88.0,"Year":2012,"Document Type":"Article","Title":"Mining urban land-use patterns from volunteered geographic information by means of genetic algorithms and artificial neural networks","Abstract":"In the context of OpenStreetMap (OSM), spatial data quality, in particular completeness, is an essential aspect of its fitness for use in specific applications, such as planning tasks. To mitigate the effect of completeness errors in OSM, this study proposes a methodological framework for predicting by means of OSM urban areas in Europe that are currently not mapped or only partially mapped. For this purpose, a machine learning approach consisting of artificial neural networks and genetic algorithms is applied. Under the premise of existing OSM data, the model estimates missing urban areas with an overall squared correlation coefficient (R 2) of 0.589. Interregional comparisons of European regions confirm spatial heterogeneity in the model performance, whereas the R 2 ranges from 0.129 up to 0.789. These results show that the delineation of urban areas by means of the presented methodology depends strongly on location. \u00a9 2012 Taylor &amp; Francis Group, LLC.","Author Keywords":"Machine learning; OpenStreetMap UK; Spatial data quality; Volunteered geographic information","Authors":"Hagenauer J., Helbich M.","DOI":"10.1080\/13658816.2011.619501","x":-7.9400000572,"y":4.8699998856},{"HDBSCAN_Cluster":-1,"DocId":17,"Cited by":77.0,"Year":2008,"Document Type":"Article","Title":"Land-cover change and environmental impact analysis in the Greater Mankato area of Minnesota using remote sensing and GIS modelling","Abstract":"Land use and land-cover (LULC) data provide essential information for environmental management and planning. This research evaluates the land-cover change dynamics and their effects for the Greater Mankato Area of Minnesota using image classification and Geographic Information Systems (GIS) modelling in high-resolution aerial photography and QuickBird imagery. Results show that from 1971 to 2003, urban impervious surfaces increased from 18.3% to 32.6%, while cropland and grassland decreased from 54.2% to 39.1%. The dramatic urbanization caused evident environmental impacts in terms of runoff and water quality, whereas the annual air pollution removal rate and carbon storage\/sequestration remained consistent since urban forests were steady over the 32-year span. The results also indicate that highly accurate land-cover features can be extracted effectively from high-resolution imagery by incorporating both spectral and spatial information, applying an image-fusion technique, and utilizing the hierarchical machine-learning Feature Analyst classifier. This research fills the high-resolution LULC data gap for the Greater Mankato Area. The findings of the study also provide valuable inputs for local decision-makers and urban planners.","Author Keywords":null,"Authors":"Yuan F.","DOI":"10.1080\/01431160701294703","x":-5.5900001526,"y":3.7699999809},{"HDBSCAN_Cluster":-1,"DocId":20,"Cited by":61.0,"Year":2014,"Document Type":"Article","Title":"Building type classification using spatial and landscape attributes derived from LiDAR remote sensing data","Abstract":"Building information is one of the key elements for a range of urban planning and management practices. In this study, an investigation was performed to classify buildings delineated from light detection and ranging (LiDAR) remote sensing data into three types: single-family houses, multiple-family houses, and non-residential buildings. Four kinds of spatial attributes describing the shape, location, and surrounding environment of buildings were calculated and subsequently employed in the classification. Experiments were performed in suburban and downtown sites in Denver, CO, USA, considering different building components and neighborhood environments. Building type classification results yielded overall accuracy > 70% and Kappa > 0.5 for both sites, demonstrating the feasibility of obtaining building type information from LiDAR data. The shape attributes, such as width, footprint area, and perimeter, were most useful for identifying building types. Environmental landscape attributes surrounding buildings, such as the number of road and parking lot pixels, also contributed to obtaining building type information. Combining shape and environmental landscape attributes was necessary to obtain accurate and consistent classification results. \u00a9 2014 Elsevier B.V.","Author Keywords":"Building classification; Decision trees; LiDAR; Machine learning; Random forest; Support vector machines","Authors":"Lu Z., Im J., Rhee J., Hodgson M.","DOI":"10.1016\/j.landurbplan.2014.07.005","x":-6.6100001335,"y":5.9699997902},{"HDBSCAN_Cluster":-1,"DocId":21,"Cited by":59.0,"Year":2015,"Document Type":"Article","Title":"Urban land use and land cover classification using remotely sensed sar data through deep belief networks","Abstract":"Land use and land cover (LULC) mapping in urban areas is one of the core applications in remote sensing, and it plays an important role in modern urban planning and management. Deep learning is springing up in the field of machine learning recently. By mimicking the hierarchical structure of the human brain, deep learning can gradually extract features from lower level to higher level. The Deep Belief Networks (DBN) model is a widely investigated and deployed deep learning architecture. It combines the advantages of unsupervised and supervised learning and can archive good classification performance. This study proposes a classification approach based on the DBN model for detailed urban mapping using polarimetric synthetic aperture radar (PolSAR) data. Through the DBN model, effective contextual mapping features can be automatically extracted from the PolSAR data to improve the classification performance. Two-date high-resolution RADARSAT-2 PolSAR data over the Great Toronto Area were used for evaluation. Comparisons with the support vector machine (SVM), conventional neural networks (NN), and stochastic Expectation-Maximization (SEM) were conducted to assess the potential of the DBN-based classification approach. Experimental results show that the DBN-based method outperforms three other approaches and produces homogenous mapping results with preserved shape details. \u00a9 2015 Qi Lv et al.","Author Keywords":null,"Authors":"Lv Q., Dou Y., Niu X., Xu J., Xu J., Xia F.","DOI":"10.1155\/2015\/538063","x":-4.2100000381,"y":5.0100002289},{"HDBSCAN_Cluster":-1,"DocId":25,"Cited by":51.0,"Year":2018,"Document Type":"Article","Title":"Exploring the optimal integration levels between SAR and optical data for better urban land cover mapping in the Pearl River Delta","Abstract":"Integrating synthetic aperture radar (SAR) and optical data to improve urban land cover classification has been identified as a promising approach. However, which integration level is the most suitable remains unclear but important to many researchers and engineers. This study aimed to compare different integration levels for providing a scientific reference for a wide range of studies using optical and SAR data. SAR data from TerraSAR-X and ENVISAT ASAR in both WSM and IMP modes were used to be combined with optical data at pixel level, feature level and decision levels using four typical machine learning methods. The experimental results indicated that: 1) feature level that used both the original images and extracted features achieved a significant improvement of up to 10% compared to that using optical data alone; 2) different levels of fusion required different suitable methods depending on the data distribution and data resolution. For instance, support vector machine was the most stable at both the feature and decision levels, while random forest was suitable at the pixel level but not suitable at the decision level. 3) By examining the distribution of SAR features, some features (e.g., homogeneity) exhibited a close-to-normal distribution, explaining the improvement from the maximum likelihood method at the feature and decision levels. This indicated the benefits of using texture features from SAR data when being combined with optical data for land cover classification. Additionally, the research also shown that combining optical and SAR data does not guarantee improvement compared with using single data source for urban land cover classification, depending on the selection of appropriate fusion levels and fusion methods. \u00a9 2017 Elsevier B.V.","Author Keywords":"Fusion level; Fusion strategies; Optical and SAR fusion; Urban land cover","Authors":"Zhang H., Xu R.","DOI":"10.1016\/j.jag.2017.08.013","x":-5.75,"y":4.8000001907},{"HDBSCAN_Cluster":0,"DocId":26,"Cited by":51.0,"Year":2015,"Document Type":"Article","Title":"Combining Pixel-and Object-Based Machine Learning for Identification of Water-Body Types from Urban High-Resolution Remote-Sensing Imagery","Abstract":"Water is one of the vital components for the ecological environment, which plays an important role in human survival and socioeconomic development. Water resources in urban areas are gradually decreasing due to the rapid urbanization, especially in developing countries. Therefore, the precise extraction and automatic identification of water bodies are of great significance and urgently required for urban planning. It should be noted that although some studies have been reported regarding the water-area extraction, to our knowledge, few papers concern the identification of urban water types (e.g., rivers, lakes, canals, and ponds). In this paper, a novel two-level machine-learning framework is proposed for identifying the water types from urban high-resolution remote-sensing images. The framework consists of two interpretation levels: 1) water bodies are extracted at the pixel level, where the water\/shadow\/vegetation indexes are considered and 2) water types are further identified at the object level, where a set of geometrical and textural features are used. Both levels employ machine learning for the image interpretation. The proposed framework is validated using the GeoEye-1 and WorldView-2 images, over two mega cities in China, i.e., Wuhan and Shenzhen, respectively. The experimental results show that the proposed method achieved satisfactory accuracies for both water extraction [95.4% (Shenzhen), 96.2% (Wuhan)], and water type classification [94.1% (Shenzhen), 95.9% (Wuhan)] in complex urban areas. \u00a9 2015 IEEE.","Author Keywords":"High resolution; machine learning; object-oriented; water detection; water extraction; water index","Authors":"Huang X., Xie C., Fang X., Zhang L.","DOI":"10.1109\/JSTARS.2015.2420713","x":-5.3699998856,"y":5.1300001144},{"HDBSCAN_Cluster":-1,"DocId":30,"Cited by":45.0,"Year":2014,"Document Type":"Article","Title":"From land cover-graphs to urban structure types","Abstract":"Urban structure types (UST) are an initial interest and basic instrument for monitoring, controlling and modeling tasks of urban planners and decision makers during ongoing urbanization processes. This study focuses on a method to classify UST from land cover (LC) objects, which were derived from high resolution satellite images. The topology of urban LC objects is analyzed by implementing neighborhood LC-graphs. Various graph measures are examined by their potential to distinguish between different UST, using the machine learning classifier random forest. Additionally the influence of different parameter settings of the random forest model, the reduction of training samples, and the graph measure importance is analyzed. An independent test set is classified and validated, achieving an overall accuracy of 87%. It was found that the height of the building with the highest node degree has a strong impact on the classification result. \u00a9 2014 \u00a9 Taylor & Francis.","Author Keywords":"adjacency-graphs; land cover; land use; urban; urban structure types","Authors":"Walde I., Hese S., Berger C., Schmullius C.","DOI":"10.1080\/13658816.2013.865189","x":-6.9299998283,"y":5.1199998856},{"HDBSCAN_Cluster":0,"DocId":37,"Cited by":39.0,"Year":2015,"Document Type":"Conference Paper","Title":"Improving Spatial Feature Representation from Aerial Scenes by Using Convolutional Networks","Abstract":"The performance of image classification is highly dependent on the quality of extracted features. Concerning high resolution remote image images, encoding the spatial features in an efficient and robust fashion is the key to generating discriminatory models to classify them. Even though many visual descriptors have been proposed or successfully used to encode spatial features of remote sensing images, some applications, using this sort of images, demand more specific description techniques. Deep Learning, an emergent machine learning approach based on neural networks, is capable of learning specific features and classifiers at the same time and adjust at each step, in real time, to better fit the need of each problem. For several task, such image classification, it has achieved very good results, mainly boosted by the feature learning performed which allows the method to extract specific and adaptable visual features depending on the data. In this paper, we propose a novel network capable of learning specific spatial features from remote sensing images, with any pre-processing step or descriptor evaluation, and classify them. Specifically, automatic feature learning task aims at discovering hierarchical structures from the raw data, leading to a more representative information. This task not only poses interesting challenges for existing vision and recognition algorithms, but also brings huge opportunities for urban planning, crop and forest management and climate modelling. The propose convolutional neural network has six layers: three convolutional, two fully-connected and one classifier layer. So, the five first layers are responsible to extract visual features while the last one is responsible to classify the images. We conducted a systematic evaluation of the proposed method using two datasets: (i) the popular aerial image dataset UCMerced Land-use and, (ii) a multispectral high-resolution scenes of the Brazilian Coffee Scenes. The experiments show that the proposed method outperforms state-of-the-art algorithms in terms of overall accuracy. \u00a9 2015 IEEE.","Author Keywords":"Deep Learning; Feature Learning; High-resolution Images; Image Classification; Machine Learning; Remote Sensing","Authors":"Nogueira K., Miranda W.O., Santos J.A.D.","DOI":"10.1109\/SIBGRAPI.2015.39","x":-4.6799998283,"y":4.9899997711},{"HDBSCAN_Cluster":-1,"DocId":41,"Cited by":36.0,"Year":2017,"Document Type":"Article","Title":"Building block level urban land-use information retrieval based on Google Street View images","Abstract":"Land-use maps are important references for urban planning and urban studies. Given the heterogeneity of urban land-use types, it is difficult to differentiate different land-use types based on overhead remotely sensed data. Google Street View (GSV) images, which capture the fa\u00e7ades of building blocks along streets, could be better used to judge the land-use types of different building blocks based on their fa\u00e7ade appearances. Recently developed scene classification algorithms in computer vision community make it possible to categorize different photos semantically based on various image feature descriptors and machine-learning algorithms. Therefore, in this study, we proposed a method to derive detailed land-use information at building block level based on scene classification algorithms and GSV images. Three image feature descriptors (i.e., scale-invariant feature transform-Fisher, histogram of oriented gradients, GIST) were used to represent GSV images of different buildings. Existing land-use maps were used to create training datasets to train support vector machine (SVM) classifiers for categorizing GSV images. The trained SVM classifiers were then applied to case study areas in New York City, Boston, and Houston, to predict the land-use information at building block level. Accuracy assessment results show that the proposed method is suitable for differentiating residential buildings and nonresidential buildings with an accuracy of 85% or so. Since the GSV images are publicly accessible, this proposed method would provide a new way for building block level land-use mapping in future. \u00a9 2017 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"GSV (Google Street View); image features; machine learning; urban land-use mapping","Authors":"Li X., Zhang C., Li W.","DOI":"10.1080\/15481603.2017.1338389","x":-6.4200000763,"y":5.5100002289},{"HDBSCAN_Cluster":-1,"DocId":56,"Cited by":29.0,"Year":2016,"Document Type":"Article","Title":"A supervoxel-based spectro-spatial approach for 3D urban point cloud labelling","Abstract":"ABSTRACT: Three-dimensional (3D) point cloud labelling of airborne lidar (light detection and ranging) data has promising applications in urban city modelling. Automatic and efficient methods for semantic labelling of airborne urban point cloud data with multiple classes still remains a challenge. We propose a novel 3D object-based classification framework for labelling urban lidar point cloud using a computer vision technique, supervoxels. The supervoxel approach is promising for representing dense lidar point cloud in a compact manner for 3D segmentation and for improving the computational efficiency. Initially, supervoxels are generated by over-segmenting the coloured point cloud using the voxel-based cloud connectivity algorithm in the geometric space. The local connectivity established between supervoxels has been used to produce meaningful and realistic objects (segments). The segments are classified by different machine learning techniques based on several spectral and geometric features extracted from the segments. All the points within a labelled segment are assigned the same segment label. Furthermore, the effect of different feature vectors and varying point density on the classification accuracy has been studied. Results indicate an accurate labelling of points in realistic 3D space conforming to the boundaries of objects. An overall classification accuracy of 90% is achieved by the proposed method. The labelled 3D points can be used directly for the reconstruction of buildings and other man-made objects. \u00a9 2016 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Ramiya A.M., Nidamanuri R.R., Ramakrishnan K.","DOI":"10.1080\/01431161.2016.1211348","x":-5.9600000381,"y":6.8299999237},{"HDBSCAN_Cluster":0,"DocId":58,"Cited by":28.0,"Year":2006,"Document Type":"Article","Title":"An adaptive and iterative method of urban area extraction from SAR images","Abstract":"This letter presents a new method for unsupervised urban area extraction from synthetic aperture radar (SAR) images based on the ffmax algorithm proposed by C. Gouinaud specially for acquiring urban areas in SPOT imagery. According to the statistical characteristics of urban areas, an adaptive and iterative method based on the low-level extraction given by the ffmax algorithm using a large window is proposed. Experimental results on real SAR images show that the proposed automatic method works quickly and can preserve the borders of urban areas as well as avoid the disturbance of other classes and the extractions of urban areas are reliable and precise. \u00a9 2006 IEEE.","Author Keywords":"Adaptive and iterative (AI); Ffmax algorithm; Synthetic aperture radar (SAR) image; Urban area extraction","Authors":"He C., Xia G.-S., Sun H.","DOI":"10.1109\/LGRS.2006.878447","x":-5.5999999046,"y":5.1700000763},{"HDBSCAN_Cluster":-1,"DocId":61,"Cited by":27.0,"Year":2007,"Document Type":"Conference Paper","Title":"Conditional random field for 3D point clouds with adaptive data reduction","Abstract":"We proposed using Conditional Random Fields with adaptive data reduction for the classification of 3D point clouds acquired from a Riegl Terrestrial laser scanner. The training and inference of the acquired large outdoor urban data can be time consuming. We approach the problem by computing an adaptive support region for each data point using 3D scale theory. For training and inference of the discriminative Conditional Random Fields, smaller set of data samples that contains relevant information within the support region is selected instead of using all point cloud data. We tested the algorithm on synthetically generated data and urban point clouds data acquired from the laser scanner. The computed support region is also used in feature extraction for urban point clouds data. The results showed improvement in the training and inference rate while maintaining comparable classification accuracy. \u00a9 2007 IEEE.","Author Keywords":"Classifications; Conditional random fields; LIDAR data; Machine learning; Scale theory","Authors":"Lim E.H., Suter D.","DOI":"10.1109\/CW.2007.24","x":-6.2199997902,"y":6.6599998474},{"HDBSCAN_Cluster":0,"DocId":63,"Cited by":26.0,"Year":2019,"Document Type":"Article","Title":"Support Vector Machine accuracy assessment for extracting green urban areas in towns","Abstract":"The most commonly used model for analyzing satellite imagery is the Support Vector Machine (SVM). Since there are a large number of possible variables for use in SVM, this paper will provide a combination of parameters that fit best for extracting green urban areas from Copernicus mission satellite images. This paper aims to provide a combination of parameters to extract green urban areas with the highest degree of accuracy, in order to speed up urban planning and ultimately improve town environments. Two different towns in Croatia were investigated, and the results provide an optimal combination of parameters for green urban areas extraction with an overall kappa index of 0.87 and 0.89, which demonstrates a very high classification accuracy. \u00a9 2019 by the authors.","Author Keywords":"Green urban areas extraction; Kernels; Machine learning; Satellite images; Support vector machine","Authors":"Kranj\u010di\u0107 N., Medak D., \u017dupan R., Rezo M.","DOI":"10.3390\/rs11060655","x":-5.8299999237,"y":5.1700000763},{"HDBSCAN_Cluster":0,"DocId":64,"Cited by":26.0,"Year":2016,"Document Type":"Article","Title":"Land Classification Using Remotely Sensed Data: Going Multilabel","Abstract":"Obtaining an up-to-date high-resolution description of land cover is a challenging task due to the high cost and labor-intensive process of human annotation through field studies. This work introduces a radically novel approach for achieving this goal by exploiting the proliferation of remote sensing satellite imagery, allowing for the up-to-date generation of global-scale land cover maps. We propose the application of multilabel classification, a powerful framework in machine learning, for inferring the complex relationships between the acquired satellite images and the spectral profiles of different types of surface materials. Introducing a drastically different approach compared to unsupervised spectral unmixing, we employ contemporary ground-collected data from the European Environment Agency to generate the label set and multispectral images from the MODIS sensor to generate the spectral features, under a supervised classification framework. To validate the merits of our approach, we present results using several state-of-the-art multilabel learning classifiers and evaluate their predictive performance with respect to the number of annotated training examples, as well as their capability to exploit examples from neighboring regions or different time instances. We also demonstrate the application of our method on hyperspectral data from the Hyperion sensor for the urban land cover estimation of New York City. Experimental results suggest that the proposed framework can achieve excellent prediction accuracy, even from a limited number of diverse training examples, surpassing state-of-the-art spectral unmixing methods. \u00a9 2016 IEEE.","Author Keywords":"CORINE; data processing; land cover; MODIS; pattern classification; remote sensing; satellite applications; time series; unmixing","Authors":"Karalas K., Tsagkatakis G., Zervakis M., Tsakalides P.","DOI":"10.1109\/TGRS.2016.2520203","x":-4.6900000572,"y":4.0799999237},{"HDBSCAN_Cluster":1,"DocId":70,"Cited by":24.0,"Year":2014,"Document Type":"Article","Title":"Driving forces analysis of urban expansion based on boosted regression trees and Logistic regression","Abstract":"The rapid relentless urban area expansion has led to a series of problems in China. Many researches focused on this issue in recent years. Driving forces are the core topic in urban expansion,as well as the basic component of modeling and predicting. It is very useful and meaningful to analyze the driving force of urban expansion, which may provide us with a scientific basis to rationally utilize land resources, determining the law of urban development, researching the evolution process, predicting the urban expansion trends, and also providing guidance for the development of rational control policies. The Shenyang city was chosen as study area. Eight categories of land use types were extracted from remote sensing images (1997 and 2010) with ArcGIS software. Ten driving forces were chosen, including three natural factors, three distance factors, four social and economic factors. which were calculated based on the land use maps, DEM, topographic maps, zoning maps and the statistical yearbooks. The dependent variable was the change of built-up area of Shenyang from 1997 to 2010. Boosted regression trees (BRT) is an ensemble method and is a combination of techniques between statistical and machine learning traditions that has shown to be effective to identify relationships between results and influencing factors. Logistic regression is a method to discover the empirical relationships between a binary dependent and several independent categorical and continuous variables. Boosted Regression Trees and Logistic regression were used to analyze the main driving force of urban expansion synthetically. The result illustrated the relative influence of driving factors was followed by distance from urban area of 1997, distance from river, DEM, distance from highway and railway, land use types, development plan, GDP, population density, aspect, and slope based on BRT analysis. According to Logistic regression analysis, the relative influence of important factors was followed by development zone, distance from urban land of 1997, DEM, distance from highway and railway, population density, distance from river, rural residential areas and slope. The most important driving forces affecting the expansion of Shenyang are distance from urban area of 1997, DEM, distance from highway and railway. Meanwhile, they were all located in the top four of the main factors. The results revealed that the distance factors were the most important factors, and the total contribution rate of relative influence was up to 61.4%. It is demonstrated distance factors are the main driving forces of urban expansion. Natural factorswere less important, but the relative influence of DEM was important, and the contribution rate was 12.5%. Development zones and rural settlements are the only two factors have much influence in the socio-economic factors. On the whole, location factors, which refer to the distance from urban land in this study, were the leading factors of urban expansion. Natural factors, such as DEM, rivers and so on, are the basis of urban development, determining the overall urban spatial form. The construction of infrastructures, such as roads and railways, are the frame of the city. The social and economic factors decided the speed of urban expansion. Urban planning and development zone construction provided the direction of urban expansion.","Author Keywords":"Boosted regression trees; Driving forces; Logistic regression; Shenyang city; Urban expansion","Authors":"Li C.L., Liu M., Hu Y.M., Xu Y.Y., Sun F.Y.","DOI":"10.5846\/stxb201212121790","x":-8.3000001907,"y":4.1500000954},{"HDBSCAN_Cluster":-1,"DocId":71,"Cited by":23.0,"Year":2020,"Document Type":"Review","Title":"Change detection based on artificial intelligence: State-of-the-art and challenges","Abstract":"Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field. \u00a9 2020 by the authors.","Author Keywords":"Artificial intelligence; Change detection; Deep learning; Hyperspectral; Multispectral; Neural network; Remote sensing; SAR; Street view; Unsupervised learning","Authors":"Shi W., Zhang M., Zhang R., Chen S., Zhan Z.","DOI":"10.3390\/rs12101688","x":-4.9299998283,"y":5.6799998283},{"HDBSCAN_Cluster":0,"DocId":72,"Cited by":23.0,"Year":2020,"Document Type":"Article","Title":"Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review","Abstract":"Remote sensing (RS) systems have been collecting massive volumes of datasets for decades, managing and analyzing of which are not practical using common software packages and desktop computing resources. In this regard, Google has developed a cloud computing platform, called Google Earth Engine (GEE), to effectively address the challenges of big data analysis. In particular, this platform facilitates processing big geo data over large areas and monitoring the environment for long periods of time. Although this platform was launched in 2010 and has proved its high potential for different applications, it has not been fully investigated and utilized for RS applications until recent years. Therefore, this study aims to comprehensively explore different aspects of the GEE platform, including its datasets, functions, advantages\/limitations, and various applications. For this purpose, 450 journal articles published in 150 journals between January 2010 and May 2020 were studied. It was observed that Landsat and Sentinel datasets were extensively utilized by GEE users. Moreover, supervised machine learning algorithms, such as Random Forest, were more widely applied to image classification tasks. GEE has also been employed in a broad range of applications, such as Land Cover\/land Use classification, hydrology, urban planning, natural disaster, climate analyses, and image processing. It was generally observed that the number of GEE publications have significantly increased during the past few years, and it is expected that GEE will be utilized by more users from different fields to resolve their big data processing challenges. \u00a9 2008-2012 IEEE.","Author Keywords":"Big data; cloud computing; Google Earth Engine (GEE); remote sensing (RS)","Authors":"Amani M., Ghorbanian A., Ahmadi S.A., Kakooei M., Moghimi A., Mirmazloumi S.M., Moghaddam S.H.A., Mahdavi S., Ghahremanloo M., Parsian S., Wu Q., Brisco B.","DOI":"10.1109\/JSTARS.2020.3021052","x":-6.0799999237,"y":4.0599999428},{"HDBSCAN_Cluster":1,"DocId":74,"Cited by":23.0,"Year":2015,"Document Type":"Article","Title":"Performance analysis of radial basis function networks and multi-layer perceptron networks in modeling urban change: a case study","Abstract":"The majority of cities are rapidly growing. This makes the monitoring and modeling of urban change\u2019s spatial patterns critical to urban planners, decision makers, and environment protection activists. Although a wide range of methods exists for modeling and simulating urban growth, machine learning (ML) techniques have received less attention despite their potential for producing highly accurate predictions of future urban extents. The aim of this study is to investigate two ML techniques, namely radial basis function network (RBFN) and multi-layer perceptron (MLP) networks, for modeling urban change. By predicting urban change for 2010, the models\u2019 performance is evaluated by comparing results with a reference map and by using a set of pertinent statistical measures, such as average spatial distance deviation and figure of merit. The application of these techniques employs the case study area of Mumbai, India. The results show that both models, which were tested using the same explanatory variables, produced promising results in terms of predicting the size and extent of future urban areas. Although a close match between RBFN and MLP is observed, RBFN demonstrates higher spatial accuracy of prediction. Accordingly, RBFN was utilized to simulate urban change for 2020 and 2030. Overall, the study provides evidence that RBFN is a robust and efficient ML technique and can therefore be recommended for land use change modeling. \u00a9 2015, \u00a9 2015 Taylor & Francis.","Author Keywords":"GIS; multi-layer perceptron network; radial basis function network; spatial accuracy assessment; urban change","Authors":"Shafizadeh-Moghadam H., Hagenauer J., Farajzadeh M., Helbich M.","DOI":"10.1080\/13658816.2014.993989","x":-8.1199998856,"y":4.4600000381},{"HDBSCAN_Cluster":-1,"DocId":90,"Cited by":19.0,"Year":2019,"Document Type":"Article","Title":"Spatiotemporal detection of land use\/land cover change in the large basin using integrated approaches of remote sensing and GIS in the Upper Awash basin, Ethiopia","Abstract":"Assessment of the changing environmental conditions is essential for planning the wise use of natural resources. The main objective of this paper is to analyze the historical and future modeled LULC changes using multi-temporal Landsat images in the Upper Awash basin, Ethiopia. The supervised image classification method was used to determine the historical LULC changes based on Landsat 1 MSS 1972, Landsat 5 TM 1984, Landsat 7 ETM + 2000, and Landsat 8 OLI TIRS 2014. The future LULC change was predicted using the machine-learning approaches of Land Change Modeler (LCM). The LULC change detection analysis exhibited significant increment in the areal extent of the cropland and urban areas, and decreasing trends in the pasture, forests and shrubland coverage. Mainly, the LULC change matrices indicated that larger conversion rate was observed from shrubland to cropland area. The urban area found to increase by 606.2% from the year 1972 to 2014 and cropland has also increased by 47.3%. Whereas, a decreasing trend was obtained in the forest by \u2212\u00a025.1%, pasture \u2212 87.4%, shrubland \u2212 28.8% and water \u2212 21.0% in the same period. The modeled future LULC change scenarios of the year 2025 and 2035 have exhibited significant expansion of cropland and urban areas at the expense of forest, pasture and shrubland areas. The study has revealed the extent and the rate of LULC change at larger basin and subbasin level which can be useful for knowledge-based future land management practice in the Upper Awash basin. \u00a9 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Author Keywords":"Agricultural expansion; Classification accuracy; Land change modeler; Land cover change; Upper Awash basin; Urban sprawl","Authors":"Shawul A.A., Chakma S.","DOI":"10.1007\/s12665-019-8154-y","x":-5.7600002289,"y":3.6500000954},{"HDBSCAN_Cluster":1,"DocId":96,"Cited by":17.0,"Year":2018,"Document Type":"Article","Title":"Predicting multiple land use transitions under rapid urbanization and implications for land management and urban planning: The case of Zhanggong District in central China","Abstract":"Numerous machine learning-based land change models have been presented by researchers over the last two decades. To date, however, far less have simulated multiple land use classes and specific land use subclasses at the same time. In some areas of the world, it is important to simulate both of these dynamics to understand fully the drivers and consequences of land change. One important example is the process of urbanization in China, as urban policies have been developed that guide urban expansion, rural protections, and urban subclass development. This paper presents a new model integrating geographic information systems (GIS) with artificial neural networks (ANNs) to predict multiple transitions among land use types and urban subclasses in the Zhanggong District of Ganzhou city in China. We show that the model produces satisfactory goodness of fit values-based on location, quantity and spatial configuration-between simulated and observed land use maps for 2015. Our simulated future maps produced by the model for 2020 and 2025 demonstrate that transitions from farmland and forest to urban will remain the main pathway of urbanization although we predict that the rate will slow after 2025. The goals of urban planning should be aligned with land use planning according to \u201cCombining multiple laws and regulations\u201d in China. Taking into account the current and future land use transitions will enhance the accuracy and timeliness of land use policy making and urban land planning. For the sustainable land use in Zhanggong District, we argue for a strengthened regulation of the land market by government and believe that planning officials should guide the spatial distribution of land supply actively. Furthermore, improving the production, living and ecological functions of land resources are the key points to optimize urban land use functions and the allocation of land resources. We discuss how our model can be adapted to other areas to benefit land use management and urban planning in China. \u00a9 2018 Elsevier Ltd","Author Keywords":"Artificial neural networks; China; Land use management; Multiple land use transitions; Urban planning; Urbanization","Authors":"Wang L., Pijanowski B., Yang W., Zhai R., Omrani H., Li K.","DOI":"10.1016\/j.habitatint.2018.08.007","x":-7.9299998283,"y":3.7899999619},{"HDBSCAN_Cluster":0,"DocId":105,"Cited by":15.0,"Year":2018,"Document Type":"Article","Title":"Progressively Expanded Neural Network (PEN Net) for hyperspectral image classification: A new neural network paradigm for remote sensing image analysis","Abstract":"Hyperspectral image (HSI) has been used for a wide range of applications including forestry, urban planning, and precision agriculture. In recent years, machine learning based algorithms, such as support vector machines, decision trees, ensemble learning, and their variations have shown promising results in HSI analysis. Such methodologies, nevertheless, can lead to insufficient information abstraction in interpreting hyperspectral pixels. In this paper, we propose a novel neural network based classification algorithm, named Progressively Expanded Neural Network (PEN Net), that can effectively interpret hyperspectral pixels in nonlinear feature spaces and then determine their categories. Furthermore, a spectral-spatial HSI classification framework is also introduced to test the generality and robustness of the PEN Net. Experimental results on four standard hyperspectral datasets illustrate that: (1) PEN Net classifier yields better accuracy and competitive processing speed in HSI classification tasks compared to the state-of-the-art methods; (2) Multi-hidden layer based PEN Net generally provides better performance than single hidden layer one; (3) Combination of spectral and spatial features in the PEN Net classifier can significantly improve the classification accuracy by 6\u201315% compared to the spectral only based HSI classification. This study implies that the proposed neural network architecture opens a new window for future research and the potential for remote sensing image analysis. \u00a9 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"Classification; Hyperspectral image (HSI); Machine learning; Neural network; Remote sensing","Authors":"Sidike P., Asari V.K., Sagan V.","DOI":"10.1016\/j.isprsjprs.2018.09.007","x":-4.5399999619,"y":4.4000000954},{"HDBSCAN_Cluster":0,"DocId":109,"Cited by":14.0,"Year":2020,"Document Type":"Article","Title":"Comparative assessment of machine learning methods for urban vegetation mapping using multitemporal Sentinel-1 imagery","Abstract":"Mapping of green vegetation in urban areas using remote sensing techniques can be used as a tool for integrated spatial planning to deal with urban challenges. In this context, multitemporal (MT) synthetic aperture radar (SAR) data have not been equally investigated, as compared to optical satellite data. This research compared various machine learning methods using single-date and MT Sentinel-1 (S1) imagery. The research was focused on vegetation mapping in urban areas across Europe. Urban vegetation was classified using six classifiers-random forests (RF), support vector machine (SVM), extreme gradient boosting (XGB), multi-layer perceptron (MLP), AdaBoost. M1 (AB), and extreme learning machine (ELM). Whereas, SVM showed the best performance in the single-date image analysis, the MLP classifier yielded the highest overall accuracy in the MT classification scenario. Mean overall accuracy (OA) values for all machine learning methods increased from 57% to 77% with speckle filtering. Using MT SAR data, i.e., three and five S1 imagery, an additional increase in the OA of 8.59% and 13.66% occurred, respectively. Additionally, using three and five S1 imagery for classification, the F1 measure for forest and low vegetation land-cover class exceeded 90%. This research allowed us to confirm the possibility of MT C-band SAR imagery for urban vegetation mapping. \u00a9 2020 by the authors.","Author Keywords":"Land-cover classification; Multitemporal; Sentinel-1; Speckle filtering; Synthetic aperture radar (SAR); Urban vegetation","Authors":"Ga\u0161parovi\u0107 M., Dobrini\u0107 D.","DOI":"10.3390\/rs12121952","x":-5.4000000954,"y":4.5},{"HDBSCAN_Cluster":-1,"DocId":110,"Cited by":14.0,"Year":2019,"Document Type":"Article","Title":"Deprivation pockets through the lens of convolutional neural networks","Abstract":"Machine learning techniques have been frequently applied to map urban deprivation (commonly referred to as slums) in very high-resolution satellite images. Among these, Deep Convolutional Neural Networks have shown exceptional efficiency in automated deprivation mapping at the local scale. Yet these networks have never been used to map very small heterogeneous deprivation areas (pockets) at large scale. This study proposes and evaluates a U-Net-Compound model to map deprivation pockets in Bangalore, India. The model only relies on RGB satellite images with a resolution of 2 m as these are more commonly accessible to local urban planning departments. The experiment assumes a practical situation where only limited reference data is available for the model to learn the spatial morphology of deprivation pockets. It tests whether an updated map of deprivation pockets can be obtained with limited information. The model performance to map a large number of deprivation pockets is examined by incrementally changing the model architecture and the amount of training data. Results show that the proposed model is sensitive to the amount of spatial information contained in the training data. Once sufficient spatial information is learnt through a few samples, the city scale mapping accuracy outperforms existing models in mapping small deprivation pockets, achieving a Jaccard Index of 54%. This study demonstrated that a well-designed convolutional neural network can map the existence, extent, as well as distribution patterns of deprivation pockets at the city scale with limited training data, which is essential for upscaling research outputs to provide important information for the formulation of pro-poor policies. \u00a9 2019","Author Keywords":"Bangalore; Convolutional neural networks; Deep learning; Deprivation pockets; Slums","Authors":"Wang J., Kuffer M., Roy D., Pfeffer K.","DOI":"10.1016\/j.rse.2019.111448","x":-6.4099998474,"y":4.8099999428},{"HDBSCAN_Cluster":0,"DocId":111,"Cited by":14.0,"Year":2018,"Document Type":"Article","Title":"Road centerline extraction from very-high-resolution aerial image and LiDAR data based on road connectivity","Abstract":"The road networks provide key information for a broad range of applications such as urban planning, urban management, and navigation. The fast-developing technology of remote sensing that acquires high-resolution observational data of the land surface offers opportunities for automatic extraction of road networks. However, the road networks extracted from remote sensing images are likely affected by shadows and trees, making the road map irregular and inaccurate. This research aims to improve the extraction of road centerlines using both very-high-resolution (VHR) aerial images and light detection and ranging (LiDAR) by accounting for road connectivity. The proposed method first applies the fractal net evolution approach (FNEA) to segment remote sensing images into image objects and then classifies image objects using the machine learning classifier, random forest. A post-processing approach based on the minimum area bounding rectangle (MABR) is proposed and a structure feature index is adopted to obtain the complete road networks. Finally, a multistep approach, that is, morphology thinning, Harris corner detection, and least square fitting (MHL) approach, is designed to accurately extract the road centerlines from the complex road networks. The proposed method is applied to three datasets, including the New York dataset obtained from the object identification dataset, the Vaihingen dataset obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D semantic labelling benchmark and Guangzhou dataset. Compared with two state-of-the-art methods, the proposed method can obtain the highest completeness, correctness, and quality for the three datasets. The experiment results show that the proposed method is an efficient solution for extracting road centerlines in complex scenes from VHR aerial images and light detection and ranging (LiDAR) data. \u00a9 2018 by the authors.","Author Keywords":"LiDAR data; Object recognition; Road centerline; Road connectivity; Very-high-resolution image","Authors":"Zhang Z., Zhang X., Sun Y., Zhang P.","DOI":"10.3390\/rs10081284","x":-5.3499999046,"y":6.1900000572},{"HDBSCAN_Cluster":0,"DocId":126,"Cited by":12.0,"Year":2017,"Document Type":"Article","Title":"Semi-automatic mapping of anthropogenic impervious surfaces in an urban\/suburban area using Landsat 8 satellite data","Abstract":"Impervious surfaces have a significant impact on urban runoff, groundwater, base flow, water quality, and climate. Increase in Anthropogenic Impervious Surfaces (AIS) for a region is a true representation of urban expansion. Monitoring of AIS in an urban region is helpful for better urban planning and resource management. Cost effective and efficient maps of AIS can be obtained for larger areas using remote sensing techniques. In the present study, extraction of AIS has been carried out using Double window Flexible Pace Search (DFPS) from a new index named as Normalized Difference Impervious Surface Index (NDAISI). NDAISI is developed by enhancing Biophysical Composition Index (BCI) in two stages using a new Modified Normalized Difference Soil Index (MNDSI). MNDSI has been developed from Band 7 and Band 8 (PAN) of Landsat 8 data. In comparison to existing impervious surface extraction methods, the new NDAISI approach is able to improve Spectral Discrimination Index (SDI) for bare soil and AIS significantly. Overall accuracy of mapping of AIS, using NDAISI approach has been found to be increased by nearly 23% when compared with existing impervious surface extraction methods. \u00a9 2017 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"BCI; DFPS; HPF resolution merge; MNDSI; NDAISI","Authors":"Piyoosh A.K., Ghosh S.K.","DOI":"10.1080\/15481603.2017.1282414","x":-5.25,"y":4.0599999428},{"HDBSCAN_Cluster":-1,"DocId":137,"Cited by":11.0,"Year":2014,"Document Type":"Article","Title":"Ensemble methods for binary classifications of airborne LIDAR data","Abstract":"This paper presents a framework that is aimed at improving the performance of two existing ensemble methods (namely, AdaBoost and Bagging) for airborne light detection and ranging (LIDAR) classification. LIDAR is one of the fastest growing technologies to support a multitude of civil engineering applications, such as transportation, urban planning, flood control, and city 3D reconstruction. For the above applications, LIDAR data need to be classified into binary classes (i.e., terrain and nonterrain) or multiple classes (e.g., ground, vegetation, and buildings). The proposed framework is designed to enhance the generalization performance of binary classification approach by minimizing type II errors. The authors developed and tested the framework on different LIDAR data sets representing geographic sites in Germany and the United States. The results showed that the proposed ensemble framework performed better compared to the existing methods. In addition, the AdaBoost method outperformed the Bagging method on all the terrain types. However, the framework has some limitations in terms of dealing with rough terrain and discontinuous surfaces. \u00a9 2014 American Society of Civil Engineers.","Author Keywords":"Computing; Ensemble method; LIDAR; Machine learning; Remote sensing","Authors":"Nourzad S.H.H., Pradhan A.","DOI":"10.1061\/(ASCE)CP.1943-5487.0000276","x":-6.3000001907,"y":6.2600002289},{"HDBSCAN_Cluster":0,"DocId":150,"Cited by":9.0,"Year":2018,"Document Type":"Article","Title":"Ultra-Light aircraft-based hyperspectral and colour-infrared imaging to identify deciduous tree species in an urban environment","Abstract":"One may consider the application of remote sensing as a trade-off between the imaging platforms, sensors, and data gathering and processing techniques. This study addresses the potential of hyperspectral imaging using ultra-light aircraft for vegetation species mapping in an urban environment, exploring both the engineering and scientific aspects related to imaging platform design and image classification methods. An imaging system based on simultaneous use of Rikola frame format hyperspectral and Nikon D800E adopted colour infrared cameras installed onboard a Bekas X32 manned ultra-light aircraft is introduced. Two test imaging flight missions were conducted in July of 2015 and September of 2016 over a 4000 ha area in Kaunas City, Lithuania. Sixteen and 64 spectral bands in 2015 and 2016, respectively, in a spectral range of 500-900 nm were recorded with colour infrared images. Three research questions were explored assessing the identification of six deciduous tree species: (1) Pre-treatment of spectral features for classification, (2) testing five conventional machine learning classifiers, and (3) fusion of hyperspectral and colour infrared images. Classification performance was assessed by applying leave-one-out cross-validation at the individual crown level and using as a reference at least 100 field inventoried trees for each species. The best-performing classification algorithm-multilayer perceptron, using all spectral properties extracted from the hyperspectral images-resulted in a moderate classification accuracy. The overall classification accuracy was 63%, Cohen's Kappa was 0.54, and the species-specific classification accuracies were in the range of 51-72%. Hyperspectral images resulted in significantly better tree species classification ability than the colour infrared images and simultaneous use of spectral properties extracted from hyperspectral and colour infrared images improved slightly the accuracy over the 2015 image. Even though classifications using hyperspectral data cubes of 64 bands resulted in relatively larger accuracies than with 16 bands, classification error matrices were not statistically different. Alternative imaging platforms (like an unmanned aerial vehicle and a Cessna 172 aircraft) and settings of the flights were discussed using simulated imaging projects assuming the same study area and field of application. Ultra-light aircraft-based hyperspectral and colour-infrared imaging was considered to be a technically and economically sound solution for urban green space inventories to facilitate tree mapping, characterization, and monitoring. \u00a9 2018 by the authors.","Author Keywords":"Classification; Colour infrared; Hyperspectral; Ultra-light aircraft; Urban trees","Authors":"Mozgeris G., Juodkiene V., Jonikavi\u010dius D., Straigyte L., Gadal S., Ouerghemmi W.","DOI":"10.3390\/rs10101668","x":-4.9099998474,"y":4.3699998856},{"HDBSCAN_Cluster":-1,"DocId":156,"Cited by":8.0,"Year":2020,"Document Type":"Article","Title":"A locally-constrained YOLO framework for detecting small and densely-distributed building footprints","Abstract":"Building footprints are among the most predominant features in urban areas, and provide valuable information for urban planning, solar energy suitability analysis, etc. We aim to automatically and rapidly identify building footprints by leveraging deep learning techniques and the increased availability of remote sensing datasets at high spatial resolution. The task is computationally challenging due to the use of large training datasets and large number of parameters. In related work, You-Only-Look-Once (YOLO) is a state-of-the-art deep learning framework for object detection. However, YOLO is limited in its capacity to identify small objects that appear in groups, which is the case for building footprints. We propose a LOcally-COnstrained (LOCO) You-Only-Look-Once framework to detect small and densely-distributed building footprints. LOCO is a variant of YOLO. Its layer architecture is determined by the spatial characteristics of building footprints and it uses a constrained regression modeling to improve the robustness of building size predictions. We also present an invariant augmentation based voting scheme to further improve the precision in the prediction phase. Experiments show that LOCO can greatly improve the solution quality of building detection compared to related work. \u00a9 2019, \u00a9 2019 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"Building detection; deep learning; locally constrained; remote sensing; YOLO","Authors":"Xie Y., Cai J., Bhojwani R., Shekhar S., Knight J.","DOI":"10.1080\/13658816.2019.1624761","x":-4.4400000572,"y":5.9699997902},{"HDBSCAN_Cluster":-1,"DocId":171,"Cited by":7.0,"Year":2020,"Document Type":"Article","Title":"A robust segmentation framework for closely packed buildings from airborne LiDAR point clouds","Abstract":"Urban villages (UVs) are commonly found in many Asian cities. These villages contain many closely packed buildings constructed decades ago without proper urban planning. There is a need for those buildings to be identified and put into statistics. In this paper, we present a segmentation framework that invokes multiple machine learning techniques and point cloud\/image processing algorithms to segment individual closely packed buildings from large urban scenes. The presented framework consists of two major segmentation processes. The framework first filters out the non-ground objects from the point cloud, then it classified them by using the Random Forest classifier to isolate buildings from the entire scene. After that, the building point clouds will be segmented based on several building attribute analysis methods. This is followed by using the Random Sample Consensus (RANSAC) plane filtering method to expand the space between two closely packed buildings, so that the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering technique can be used to more accurately segment each individual building from the closely packed building areas. Two airborne Light Detection and Ranging (LiDAR) datasets collected in two different cities with some typical closely packed buildings were used to verify the proposed framework. The results show that the framework can effectively identify the closely packed buildings with unified structures from large airborne LiDAR datasets. The overall segmentation accuracy reaches 84% for the two datasets. The proposed framework can serve as a basis for analysis and segmentation of closely packed buildings with a more complicated structure. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Wang X., Chan T.O., Liu K., Pan J., Luo M., Li W., Wei C.","DOI":"10.1080\/01431161.2020.1727053","x":-5.8800001144,"y":6.3600001335},{"HDBSCAN_Cluster":1,"DocId":172,"Cited by":7.0,"Year":2020,"Document Type":"Article","Title":"Analyzing the spatial factors related to the distributions of building heights in urban areas: A comparative case study in Guangzhou and Shenzhen","Abstract":"Rapid urbanization has become an increasingly serious issue worldwide. While most previous studies focused on two-dimensional urban development, the spatial characteristics of building heights are rarely explored. Such information could provide valuable implications for smart urban planning and management. However, previous attempts did not systematically investigate the spatial factors that influence building heights and their associations with urban development. Therefore, this study developed a machine learning-based method to compare the distributions of building heights in Guangzhou and Shenzhen, two cities with different development patterns. First, we collected detailed information on the buildings, such as the location and land values. Second, the height of each building was simulated based on the above information using the well-known random forests, k-nearest neighbor algorithm, and artificial neural network. The random forests algorithm outperformed the other two in both cities. We also found that the commercial land value is the most important factor associated with building heights. Moreover, the building heights in Guangzhou are more sensitive to the distances to administrative centers, while the distances to transportation networks exert stronger influences on the building heights in Shenzhen. Overall, these findings could support urban planning and management. More importantly, the proposed method can be used to predict the heights of new buildings and investigate the distributions of building heights in other regions. \u00a9 2019 Elsevier Ltd","Author Keywords":"Building heights; Machine learning; Spatial factors; Urban modeling","Authors":"Lin J., Wan H., Cui Y.","DOI":"10.1016\/j.scs.2019.101854","x":-7.6999998093,"y":4.6500000954},{"HDBSCAN_Cluster":-1,"DocId":176,"Cited by":7.0,"Year":2019,"Document Type":"Review","Title":"Landscape Transformations in Rapidly Developing Peri-urban Areas of Accra, Ghana: Results of 30 years","Abstract":"Beyond the loss of peri-urban agricultural and forested land as a result of built-up expansion, not much information exists on the changes in the structure of the peri-urban landscape in Ghana. The aim of this paper is to examine the extent to which urban expansion is driving changes in landscape structure of the peri-urban fringes of Accra.We submit that rapid peri-urbanisation will fragment the existing agricultural and forested landscape with consequent ecological, socio-economic and urban governance implications. Using Landsat satellite images for the years 1985, 1991, 2002 and 2015 the study area was classified into four land cover classes. The study adopted the use of Urban Intensity Index (UII) and the Annual Rate of Urbanization (R) as measures of urbanization. Edge density (ED), largest patch index (LPI) and Aggregation index (AI) were used as proxies to measure landscape structural transformations. The study reveals substantial reductions and fragmentation in agricultural lands, riverine and open forests, while there has been over 200 percent increase in built-up areas. Beyond these revelations in spatiotemporal changes in landscape structure, the paper points to the ecological implications of the changes, and three key socio-economic and urban governance implications. \u00a9 2019 G. Ashiagbor et al.","Author Keywords":null,"Authors":"Ashiagbor G., Amoako C., Asabere S.B., Quaye-Ballard J.A.","DOI":"10.1515\/geo-2019-0014","x":-6.0999999046,"y":3.4900000095},{"HDBSCAN_Cluster":1,"DocId":177,"Cited by":7.0,"Year":2019,"Document Type":"Article","Title":"Mapping long-term dynamics of population and dwellings based on a multi-temporal analysis of urban morphologies","Abstract":"Information on the distribution and dynamics of dwellings and their inhabitants is essential to support decision-making in various fields such as energy provision, land use planning, risk assessment and disaster management. However, as various different of approaches to estimate the current distribution of population and dwellings exists, further evidence on past dynamics is needed for a better understanding of urban processes. This article therefore addresses the question of whether and how accurately historical distributions of dwellings and inhabitants can be reconstructed with commonly available geodata from national mapping and cadastral agencies. For this purpose, an approach for the automatic derivation of such information is presented. The data basis is constituted by a current digital landscape model and a 3D building model combined with historical land use information automatically extracted from historical topographic maps. For this purpose, methods of image processing, machine learning, change detection and dasymetric mapping are applied. The results for a study area in Germany show that it is possible to automatically derive decadal historical patterns of population and dwellings from 1950 to 2011 at the level of a 100 m grid with slight underestimations and acceptable standard deviations. By a differentiated analysis we were able to quantify the errors for different urban structure types. \u00a9 2018 by the authors.","Author Keywords":"Dasymetric mapping; Dwelling units; Dynamics; Estimation; Historical demography; Multi-temporal; Population; Topographic maps; Urban morphology; Urban planning","Authors":"Hecht R., Herold H., Behnisch M., Jehling M.","DOI":"10.3390\/ijgi8010002","x":-7.4499998093,"y":3.7599999905},{"HDBSCAN_Cluster":0,"DocId":178,"Cited by":7.0,"Year":2017,"Document Type":"Conference Paper","Title":"Deep highway unit network for land cover type classification with GF-3 SAR imagery","Abstract":"The fully polarized synthetic aperture radar (SAR) is an advanced earth observation system with day and night imaging capability, which can obtain rich information of terrain and has a wide range of applications in environmental protection, urban planning and resource investigation. As the first selfdeveloped C-band multi-polarized SAR image, the acquisition of massive data and operational operation of Chinese SAR remote sensing has entered the era of big data. Under the era of remote sensing large data, however, SAR image interpretation is a great challenge for scientific applications. At present, big data-based intelligent methods such as computer vision technology have achieved great success. Deep learning such as deep highway unit networks has revolutionized the computer vision area. However, due to the characteristics of SAR microwave band imaging and phase coherence processing, SAR images are very different from ordinary optical images in terms of band, projection direction, data composition and so on. Therefore, deep learning can not be directly used for quad-pol SAR image classification. In this paper, deep learning is applied to land cover type classification with GF-3 quad-pol SAR imagery. A deep highway unit network is employed to automatically extract a hierarchic feature representation from the data, based on which the land cover type classification can be conducted. Our classification model is trained on limited training data from forest resource inventory and planning data, and tested on a Radarsat-2 quad-pol images, which is the image of the same area acquired at different times. We also employ the machine learning such as SVM, Random Forest on the same samples for comparison. The deep highway unit network trained by the GF-3 images, which can reduce speckle, fully excavate the regularity of SAR images in time and space. \u00a9 2017 IEEE.","Author Keywords":"Deep highway unit networks; Deep learning; GaoFen-3; Land cover type classification","Authors":"Guo Y., Chen E., Guo Y., Li Z., Li C., Xu K.","DOI":"10.1109\/BIGSARDATA.2017.8124926","x":-4.6599998474,"y":5.25},{"HDBSCAN_Cluster":1,"DocId":197,"Cited by":6.0,"Year":2005,"Document Type":"Conference Paper","Title":"Comparing machine learning classification schemes - A GIS approach","Abstract":"This project examines the effectiveness of two classification schema: Support Vector Machines (SVM), and Artificial Neural Networks (NN) when applied to geographic (i.e. spatial) data. The context for this study is to examine patterns of urbanization in Mahoning County, OH in relation to several independent driving variables of urban development. These independent variables were constructed using Geographic Information Systems (CIS) and were compared to the dependent variable of the spatial locations of urban areas in Mahoning County. The classification techniques were used in conjunction with the GIS-created variables to predict the location of urban areas within Mahoning County. A comparison of the accuracy of the techniques is presented and conclusions drawn concerning which of the variables are the most influential on urban patterns in the region. Lastly, a spatial analysis of the prediction error is performed for each method. \u00a9 2005 IEEE.","Author Keywords":null,"Authors":"Lazar A., Shellito B.A.","DOI":"10.1109\/ICMLA.2005.16","x":-8.0,"y":4.8400001526},{"HDBSCAN_Cluster":1,"DocId":202,"Cited by":5.0,"Year":2020,"Document Type":"Article","Title":"Spatiotemporal modeling of urban growth using machine learning","Abstract":"This paper presents a general framework for modeling the growth of three important variables for cities: population distribution, binary urban footprint, and urban footprint in color. The framework models the population distribution as a spatiotemporal regression problem using machine learning, and it obtains the binary urban footprint from the population distribution through a binary classifier plus a temporal correction for existing urban regions. The framework estimates the urban footprint in color from its previous value, as well as from past and current values of the binary urban footprint using a semantic inpainting algorithm. By combining this framework with free data from the Landsat archive and the Global Human Settlement Layer framework, interested users can get approximate growth predictions of any city in the world. These predictions can be improved with the inclusion in the framework of additional spatially distributed input variables over time subject to availability. Unlike widely used growth models based on cellular automata, there are two main advantages of using the proposed machine learning-based framework. Firstly, it does not require to define rules a priori because the model learns the dynamics of growth directly from the historical data. Secondly, it is very easy to train new machine learning models using different explanatory input variables to assess their impact. As a proof of concept, we tested the framework in Valledupar and Rionegro, two Latin American cities located in Colombia with different geomorphological characteristics, and found that the model predictions were in close agreement with the ground-truth based on performance metrics, such as the root-mean-square error, zero-mean normalized cross-correlation, Pearson's correlation coefficient for continuous variables, and a few others for discrete variables such as the intersection over union, accuracy, and the f1 metric. In summary, our framework for modeling urban growth is flexible, allows sensitivity analyses, and can help policymakers worldwide to assess different what-if scenarios during the planning cycle of sustainable and resilient cities. \u00a9 2019 by the authors.","Author Keywords":"Computer vision; Machine learning; Spatiotemporal modeling; Urban growth; Urban planning tools; Urban science","Authors":"G\u00f3mez J.A., Pati\u00f1o J.E., Duque J.C., Passos S.","DOI":"10.3390\/rs12010109","x":-7.4499998093,"y":3.9900000095},{"HDBSCAN_Cluster":-1,"DocId":204,"Cited by":5.0,"Year":2019,"Document Type":"Article","Title":"Understanding the spatial distribution of urban forests in China using Sentinel-2 images with Google Earth Engine","Abstract":"Urban forests are vitally important for sustainable urban development and the well-being of urban residents. However, there is, as yet, no country-level urban forest spatial dataset of sufficient quality for the scientific management of, and correlative studies on, urban forests in China. At present, China attaches great importance to the construction of urban forests, and it is necessary to map a high-resolution and high-accuracy dataset of urban forests in China. The open-access Sentinel images and the Google Earth Engine platform provide a significant opportunity for the realization of this work. This study used eight bands (B2-B8, B11) and three indices of Sentinel-2 in 2016 to map the urban forests of China using the Random Forest machine learning algorithms at the pixel scale with the support of Google Earth Engine (GEE). The 7317 sample points for training and testing were collected from field visits and very high resolution images from Google Earth. The overall accuracy, producer's accuracy of urban forest, and user's accuracy of urban forest assessed by independent validation samples in this study were 92.30%, 92.27%, and 92.18%, respectively. In 2016, the percentage of urban forest cover was 19.2%. Nearly half of the cities had an urban forest cover between 10% and 20%, and the average percentage of large cities whose urban populations were over 5 million was 24.8%. Cities with less than half of the average were mainly distributed in northern and western parts of China, which should be focused on in urban greening planning. \u00a9 2019 by the authors.","Author Keywords":"China; Google Earth Engine; Sentinel-2; Urban area; Urban greening","Authors":"Duan Q., Tan M., Guo Y., Wang X., Xin L.","DOI":"10.3390\/f10090729","x":-6.5599999428,"y":4.1399998665},{"HDBSCAN_Cluster":-1,"DocId":211,"Cited by":5.0,"Year":2017,"Document Type":"Conference Paper","Title":"3D shape descriptor for objects recognition","Abstract":"3D point cloud classification is an important task in applications for many areas such as robotics, urban planning and augmented reality. 3D sensors measure a high amount of points in the 3D scene objects' surface at a high collect rate, so robust techniques are needed to process all input data and also deal with some imprecision. A common solution for these tasks is the use of robust features extraction techniques to gather representative scene information at the lowest computational cost possible. This paper presents a new approach for object recognition in 3D scenes, using a novel 3D shape descriptor which is used as input for a supervised machine learning method. Proposed robust 3D feature is invariant to translation and scale and provides a very simplified object representation for pattern recognition input. Experiments were performed using an Artificial Neural Network to recognize six different object shapes, and obtained results showed that the proposed method is a promising approach for object recognition in 3D scenes. \u00a9 2017 IEEE.","Author Keywords":"3D Feature Extraction; Object Classification; Pattern Recognition","Authors":"Sales D.O., Amaro J., Os\u00f3rio F.S.","DOI":"10.1109\/SBR-LARS-R.2017.8215285","x":-5.9600000381,"y":6.6900000572},{"HDBSCAN_Cluster":-1,"DocId":223,"Cited by":4.0,"Year":2020,"Document Type":"Article","Title":"Using GIS and machine learning to classify residential status of urban buildings in low and middle income settings","Abstract":"Utilising satellite images for planning and development is becoming a common practice as computational power and machine learning capabilities expand. In this paper, we explore the use of satellite image derived building footprint data to classify the residential status of urban buildings in low and middle income countries. A recently developed ensemble machine learning building classification model is applied for the first time to the Democratic Republic of the Congo, and to Nigeria. The model is informed by building footprint and label data of greater completeness and attribute consistency than have previously been available for these countries. A GIS workflow is described that semiautomates the preparation of data for input to the model. The workflow is designed to be particularly useful to those who apply the model to additional countries and use input data from diverse sources. Results show that the ensemble model correctly classifies between 85% and 93% of structures as residential and nonresidential across both countries. The classification outputs are likely to be valuable in the modelling of human population distributions, as well as in a range of related applications such as urban planning, resource allocation, and service delivery. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Building classification; Building footprint; Machine learning; Residential; Superlearner","Authors":"Lloyd C.T., Sturrock H.J.W., Leasure D.R., Jochem W.C., L\u00e1z\u00e1r A.N., Tatem A.J.","DOI":"10.3390\/rs12233847","x":-6.6900000572,"y":5.2699999809},{"HDBSCAN_Cluster":1,"DocId":228,"Cited by":4.0,"Year":2020,"Document Type":"Article","Title":"Population spatialization in Beijing city based on machine learning and multisource remote sensing data","Abstract":"Remote sensing data have been widely used in research on population spatialization. Previous studies have generally divided study areas into several sub-areas with similar features by artificial or clustering algorithms and then developed models for these sub-areas separately using statistical methods. These approaches have drawbacks due to their subjectivity and uncertainty. In this paper, we present a study of population spatialization in Beijing City, China based on multisource remote sensing data and town-level population census data. Six predictive algorithms were compared for estimating population using the spatial variables derived from The National Polar-Orbiting Partnership\/ Visible Infrared Imaging Radiometer Suite (NPP\/VIIRS) night-time light and other remote sensing data. Random forest achieved the highest accuracy and therefore was employed for population spatialization. Feature selection was performed to determine the optimal variable combinations for population modeling by random forest. Cross-validation results indicated that the developed model achieved a mean absolute error (MAE) of 2129.52 people\/km2 and a R2 of 0.63. The gridded population density in Beijing at a spatial resolution of 500 m produced by the random forest model was also adjusted to be consistent with the census population at the town scale. By comparison with Google Earth high-resolution images, the remotely-sensed population was qualitatively validated at the intra-town scale. Validation results indicated that remotely sensed results can effectively depict the spatial distribution of population within town-level districts. This study provides a valuable reference for urban planning, public health and disaster prevention in Beijing, and a reference for population mapping in other cities. \u00a9 2020 by the authors.","Author Keywords":"Beijing; Population spatialization; Random forest; Remote sensing","Authors":"He M., Xu Y., Li N.","DOI":"10.3390\/rs12121910","x":-7.1100001335,"y":4.3800001144},{"HDBSCAN_Cluster":-1,"DocId":237,"Cited by":4.0,"Year":2018,"Document Type":"Conference Paper","Title":"Satellite image spoofing: Creating remote sensing dataset with generative adversarial networks","Abstract":"The rise of Artificial Intelligence (AI) has brought up both opportunities and challenges for today's evolving GIScience. Its ability in image classification, object detection and feature extraction has been frequently praised. However, it may also apply for falsifying geospatial data. To demonstrate the thrilling power of AI, this research explored the potentials of deep learning algorithms in capturing geographic features and creating fake satellite images according to the learned 'sense'. Specifically, Generative Adversarial Networks (GANs) is used to capture geographic features of a certain place from a group of web maps and satellite images, and transfer the features to another place. Corvallis is selected as the study area, and fake datasets with 'learned' style from three big cities (i.e. New York City, Seattle and Beijing) are generated through CycleGAN. The empirical results show that GANs can 'remember' a certain 'sense of place' and further apply that 'sense' to another place. With this paper, we would like to raise both public and GIScientists' awareness in the potential occurrence of fake satellite images, and its impacts on various geospatial applications, such as environmental monitoring, urban planning, and land use development. \u00a9 Chun X. Xu and Bo Zhao.","Author Keywords":"Deep learning and AI; Fake satellite image; GANs; Geographic feature","Authors":"Xu C., Zhao B.","DOI":"10.4230\/LIPIcs.GIScience.2018.67","x":-4.3299999237,"y":5.1700000763},{"HDBSCAN_Cluster":0,"DocId":245,"Cited by":4.0,"Year":2012,"Document Type":"Conference Paper","Title":"Accuracy comparison of land cover mapping using the object-oriented image classification with machine learning algorithms","Abstract":"Land cover mapping provides basic information for advanced science such as ecological management, biodiversity conservation, forest planning and so on. In remote sensing research, the process of creating an accurate land cover map is an important subject. Recently, there has been growing research interest in the object-oriented image classification techniques. The object-oriented image classification consists of multidimensional features including object features and thus requires multi-dimensional image classification approaches. For example, a linear model such as the maximum likelihood method of pixel-based classification cannot characterize the patterns or relations of multi-dimensional data. In multi-dimensional image classification, data mining and ensemble learning have been shown to increase accuracy and flexibility. This study examined the use of the object-oriented image classification by the multiple machine learning algorithms for land cover mapping. We applied four classifiers: Classification and regression tree (CART), Decision tree with Boosting, Decision tree with Bagging, and Random Forest. The study area was Sado Island in Niigata Prefecture, Japan. Pan-sharpened SPOT\/HRG imagery (June 2007) was used and classified into the following eight classes: broad-leaved deciduous forest, Japanese cedar, Japanese red pine, bamboo forest, paddy field, urban area, road, and bare land. We prepared four data sets with the object based features including textural information. The number of features is increased from data set I through IV. As the result, CART was unsuitable for multi-dimensional classification. Random Forest and Decision tree with Boosting showed high classification accuracies. Furthermore, in the data set with the limited features, Decision tree with Boosting was the accurate classifier. Finally, we propose two machine learning algorithms to every datasets. Random Forest is effective in the case of the multi-dimensional image classification such as data set II, III, and IV. Decision tree with Boosting is effective in the case of the image classification with the limited features such as data set I.","Author Keywords":"Bagging; Boosting; Classification and regression tree; Ensemble classifier; Random Forest","Authors":"Mochizuki S., Murakami T.","DOI":null,"x":-5.7399997711,"y":4.3000001907},{"HDBSCAN_Cluster":0,"DocId":313,"Cited by":2.0,"Year":2019,"Document Type":"Conference Paper","Title":"Multi-scale correlation-based feature selection and random forest classification for LULC mapping from the integration of SAR and optical Sentinel images","Abstract":"Reliable and accurate land use\/land cover (LULC) map is a crucial data source for the understanding of coupled human-environment systems, monitoring changes, timely low-cost planning, and management of natural resources. Improvements in sensor technologies and machine learning capabilities have shifted the attention of remote sensing community to data complementarity through fusion of multi-sensor data for accurate feature extraction and mapping. Amalgamation of optical and synthetic aperture radar (SAR) images has shown promising advantages in enhancing the accuracy of extracting LULC as such method allows exploitation of information in sensors. This study investigated the potential of using freely available multisource Sentinel images to extract LULC maps in semi-arid environments through multi-scale geographic object-based image analysis (GEOBIA). A multi-scale classification framework that integrates GEOBIA, correlation-based feature selection (CFS), and random forest (RF)-supervised classification was adopted to extract LULC from assimilation of Sentinel multi-sensor products. First, Sentinel-1 and-2 images were pre-processed. Second, optimum multi-scale segmentation levels were selected using F-score segmentation quality measures. Third, 70 features of various spectral indices and derivatives and geometrical features from optical data and multiple ratios and textural features from dual-polarization SAR images were computed, and a CFS based on wrapper approach was used to select the most significant features at multi-scale levels. Finally, a single and multi-scale RF classifier was used to extract LULC classes using the most relevant features extracted from Sentinel SAR and optical images. Results of multi-scale image segmentation optimization showed that scale parameter (SP) values of 40, 60, and 150 were optimal for extraction of LULC classes. Results of feature selection showed that 22, 24, and 27 features were selected at scale SP values of 40, 60, and 150, respectively. Half of the features were common among the three scales. Single RF classification yielded overall accuracy (OA) values of 92.10%, 93%, and 91% and kappa coefficients of 0.901, 0.912, and 0.89 at scale values of 150, 60, and 40, respectively. Multiscale RF classification from scale values of 150 and 60 produced better LULC classification with OA 96.06% and kappa coefficient of 0.95 compared with other scale SP values. The integrated approach demonstrated an effective and promising method for high-quality LULC extraction from coupling optical and SAR images. Overall, multi-sensor Sentinel images along with the adopted approach feature a remarkable potential for improving LULC extraction and can effectively be used to update geographic information system layers for various applications. \u00a9 2019 SPIE.","Author Keywords":"data fusion; image segmentation optimization; LULC; object-based classification; Optical sensors; SAR","Authors":"Al-Ruzouq R., Shanableh A., Gibril M.B., Kalantar B.","DOI":"10.1117\/12.2533123","x":-5.4899997711,"y":4.6500000954},{"HDBSCAN_Cluster":1,"DocId":329,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Modeling fine-scale residential land price distribution: An experimental study using open data and machine learning","Abstract":"Modeling the fine-scale spatiotemporal distribution of residential land prices (RLPs) is the basis for scientifically allocating land resources, managing the residential market and improving urban planning. The accurate mapping of the RLP dynamics require reliable land price prediction models and data with fine spatial and temporal resolution. With the aid of point of interest (POI) data and nighttime light (NTL) images, this paper attempts to explore the ability of machine learning algorithms (MLAs) to model grid-level RLPs using the case of Wuhan in China. Several land price prediction models were built using five MLAs and various geographic variables. The experimental results show that the extra-trees regression algorithm and the radial basis function-based support vector regression algorithm perform best in Period \u2160 (2010\u20132014) and Period \u2161 (2015\u20132019), respectively; therefore, they were selected to estimate the RLPs of the grids without observations in the corresponding period. Based on the estimated results, we found that the spatial pattern of the RLP in Wuhan transitioned from monocentric to polycentric between the two periods, and RLPs grew rapidly near newly formed urban subcenters and waterscapes. The relative importance of the predictor variables shows that commercial and educational facilities are important determinants of the RLP distribution in Wuhan; moreover, the relative importance of natural amenities and education facilities increased over time, while that of commercial facilities and public transportation decreased slightly. The case of Wuhan confirms the feasibility of MLAs and openly accessible urban data in modeling fine-scale RLP distributions. Our proposed framework provides a new approach to monitor the urban land price dynamics accurately and closely, which is beneficial for improving the infrastructure layout and achieve smart city growth. \u00a9 2021 Elsevier Ltd","Author Keywords":"Determinants; Land price distribution; Machine learning; Open data; Spatiotemporal variation; Wuhan","Authors":"Zhang P., Hu S., Li W., Zhang C., Yang S., Qu S.","DOI":"10.1016\/j.apgeog.2021.102442","x":-7.5300002098,"y":4.4200000763},{"HDBSCAN_Cluster":0,"DocId":361,"Cited by":1.0,"Year":2020,"Document Type":"Conference Paper","Title":"Land cover classification based on machine learning using UAV multi-spectral images","Abstract":"Land cover classification using UAV multi-spectral images is of great significance in precision agriculture, urban planning, land use and other fields. However, traditional remote sensing image classification methods cannot meet the classification accuracy requirements of UAV multi-spectral images. This paper aims to propose an object-based machine learning classification method to improve the land over classification accuracy of UAV multi-spectral images. The experimental area is a standard test field located in the Jilin Province of China. The experimental data was captured by a UAV equipped with a multi-spectral camera which includes four bands from 550 nm to 790 nm. First, the original images were preprocessed and the spectral curves of land cover were analyzed, thus four kinds of land cover with large differences were selected as categories. Then pixel-based, boosting-based and object-based machine learning methods were used for classification. The object-based classification method could make full use of the spatial and spectral information, and eliminate the noise problem caused by the high resolution of the UAV image to a certain extent. Finally, accuracy analysis using the verification image showed that the RF-O method achieved the highest classification accuracy of 92.2419%, and the kappa coefficient was 0.8904. All results indicate that the object-based machine learning classification method proposed in this paper is more suitable for the research of land cover classification, comparing with the traditional remote sensing image classification methods, and performs well on the land cover classification of UAV multi-spectral images. \u00a9 2020 SPIE.","Author Keywords":"Image classification; Machine learning; UAV remote sensing","Authors":"Pan L., Gu L., Ren R., Yang S.","DOI":"10.1117\/12.2566128","x":-5.2699999809,"y":4.1900000572},{"HDBSCAN_Cluster":0,"DocId":364,"Cited by":1.0,"Year":2020,"Document Type":"Article","Title":"A Self-Supervised Learning Framework for Road Centerline Extraction from High-Resolution Remote Sensing Images","Abstract":"Road extraction from the high-resolution remote sensing image is significant for the land planning, vehicle navigation, etc. The existing road extraction methods normally need many preprocessing and subsequent optimization steps. Therefore, an automatic road centerline extraction method based on the self-supervised learning framework for high-resolution remote sensing image is proposed. This proposed method does not need to manually select training samples and other optimization steps, such as the nonroad area removing. First, the positive sample selection method combining the spectral and shape features is proposed to extract the road sample. Then, the one-class classifier framework is introduced and the random forest positive unlabeled learning classifier is constructed to get the posterior probability of the pixel belonging to road. The shape feature and the posterior probability are combined to form the final road network in the object-oriented way. Finally, the road centerline is obtained through the tensor voting algorithm. In order to verify the effectiveness of the proposed algorithm, high-resolution remote sensing images and benchmark datasets are used to do experiments. The indexes of the completeness ratio, the correctness ratio, and the detection quality are used for the quantitative accuracy evaluation. Compared with the supervised, the unsupervised, and the one-class classification road extraction algorithms, this proposed algorithm achieves high accuracy and efficiency. For the deep learning method comparison, the deep learning method performs well in most cases especially in the complex urban area. However, the deep learning method needs a large number of samples and a long training time, and our self-supervised learning framework does not need the training samples. \u00a9 2008-2012 IEEE.","Author Keywords":"High-resolution remote sensing image; one-class classifier; road centerline; road extraction; self-supervised learning","Authors":"Guo Q., Wang Z.","DOI":"10.1109\/JSTARS.2020.3014242","x":-5.1999998093,"y":6.0500001907},{"HDBSCAN_Cluster":0,"DocId":382,"Cited by":1.0,"Year":2018,"Document Type":"Conference Paper","Title":"Application of machine learning in urban greenery land cover extraction","Abstract":"Urban greenery is a critical part of the modern city and the greenery coverage information is essential for land resource management, environmental monitoring and urban planning. It is a challenging work to extract the urban greenery information from remote sensing image as the trees and grassland are mixed with city built-ups. In this paper, we propose a new automatic pixel-based greenery extraction method using multispectral remote sensing images. The method includes three main steps. First, a small part of the images is manually interpreted to provide prior knowledge. Secondly, a five-layer neural network is trained and optimised with the manual extraction results, which are divided to serve as training samples, verification samples and testing samples. Lastly, the well-trained neural network will be applied to the unlabelled data to perform the greenery extraction. The GF-2 and GJ-1 high resolution multispectral remote sensing images were used to extract greenery coverage information in the built-up areas of city X. It shows a favourable performance in the 619 square kilometers areas. Also, when comparing with the traditional NDVI method, the proposed method gives a more accurate delineation of the greenery region. Due to the advantage of low computational load and high accuracy, it has a great potential for large area greenery auto extraction, which saves a lot of manpower and resources. \u00a9 Authors 2018. CC BY 4.0 License.","Author Keywords":"Auto extraction; Greenery land cover; Machine learning; Multispectral image; Neural network","Authors":"Qiao X., Li L.L., Li D., Gan Y.L., Hou A.Y.","DOI":"10.5194\/isprs-archives-XLII-3-1409-2018","x":-5.1300001144,"y":4.6999998093},{"HDBSCAN_Cluster":0,"DocId":401,"Cited by":1.0,"Year":2015,"Document Type":"Conference Paper","Title":"Comparison of different machine learning classifiers for building extraction in LiDAR-derived datasets","Abstract":"Building extraction in remotely sensed imagery is an important problem that needs solving. It can be used to aid in urban planning, hazard assessments and disaster risk management among others. Light Detection and Ranging or LiDAR, is one of the most powerful remote sensing technologies nowadays. Many studies have used the fusion of LiDAR data and multispectral images in detecting buildings. This study seeks to maximize the power of LiDAR imagery to be able to classify buildings without the aid of multispectral imagery. This work follows the Object Based Image Analysis (OBIA) approach. Instead of the traditional pixel-based classification methods, pixels are segmented into logical groups called objects. From these objects, features for building extraction are calculated. These features are: the number of returns, difference of returns, and the mean and standard deviation of positive surface openness. These objects are then classified using different machine learning classifiers such as Support Vector Machines, K-Nearest Neighbors, Na\u00efve Bayes Classifier, Decision Trees, and Random Forests. A comparative assessment was done on the performance of these different machine learning classifiers. The classifiers performed similarly with the Random Forest Classifier slightly outperforming the others.","Author Keywords":"Feature extraction; Object based image analysis","Authors":"Escamos I.M.H., Roberto A.R.C., Abucay E.R., Inciong G.K.L., Queliste M.D., Hermocilla J.A.C.","DOI":null,"x":-6.2399997711,"y":6.0399999619},{"HDBSCAN_Cluster":-1,"DocId":430,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Building Roof Superstructures Classification from Imbalanced and Low Density Airborne LiDAR Point Cloud","Abstract":"Light Detection and Ranging (LiDAR), an active remote sensing technology, is becoming an essential tool for geoinformation extraction and urban planning. Airborne Laser Scanning (ALS) point clouds segmentation and accurate classification are challenging and crucial to produce different geo-information products like three-dimensional (3D) city designs. This paper introduces an effective data-driven approach to build roof superstructures classification for airborne LiDAR point clouds with very low density and imbalanced classes, covering an urban area. Notably, it focuses on building roof superstructures (especially dormers and chimneys) and mitigating nonplanar objects' problems. Also, the imbalanced class problem of LiDAR data, to the best of our knowledge, is not yet addressed in the literature; it is considered in this study. The major advantage of the proposed approach is using only raw data without assumptions on the distribution underlying data. The main methodological novelties of this work are summarized in the following key elements. (i) At first, an adapted connected component analysis for 3D points cloud is proposed. (ii) Twelve geometry-based features are extracted for each component. (iii) A Support Vector Machine (SVM)-driven procedure is applied to classify the 3D components. (iv) Furthermore, a new component size-based sampling (CSBS) method is proposed to treat the imbalanced data problem and has been compared with several existing resampling strategies. In this study, components are classified into five classes: shed and gable dormers, chimneys, ground, and others. The results of this investigation show the satisfying classification performance of the proposed approach. Results also showed that the proposed approach outperformed machine learning methods, including SVM, Random Forest, Decision Tree, and Adaboost. \u00a9 2001-2012 IEEE.","Author Keywords":"3D classification; imbalanced data; light detection and ranging (LiDAR); Low-density point cloud; roof superstructures","Authors":"Aissou B.E., Aissa A.B., Dairi A., Harrou F., Wichmann A., Kada M.","DOI":"10.1109\/JSEN.2021.3073535","x":-6.3499999046,"y":6.4600000381},{"HDBSCAN_Cluster":1,"DocId":431,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Identifying different types of urban land use dynamics using Point-of-interest (POI) and Random Forest algorithm: The case of Huizhou, China","Abstract":"The significant economic development witnessed in China in recent decades has been accompanied by the increasing expansion of urban areas. Although a growing literature has analyzed the characteristics and driving forces of urban land expansion, less attention has been paid to examining the different expansion determinants driving fine-scale urban land use (residential land, administration and public services land, commercial land, and industrial land) change. This paper aims to identify the differences of multi-mechanisms driving fine-scale urban land use expansion based on big data and machine learning, in the Huizhou downtown area in 2000\u20132015. The Random Forest (RF) algorithm is used to identify the natural, transportation, location, social, and POI factors driving land expansion by considering different urban land-use categories. Our RF estimations showed that enormous differences existed between various urban land-use types in terms of the role they played in this expansion and their relation to potential determinants, during the different urban development stages studied. Transportation, location, and the distribution of actual land use were found to exert a greater influence on urban land expansion than other factors. All the findings above provide detailed spatiotemporal knowledge and targeted information that can aid in understanding fine-scale urban land use dynamics. In this way, sound planning strategies for different fine-scale land uses can be formulated more scientifically. The strength of association between these factors and urban land expansion differed greatly depending on the different land-use types involved as well as the urban development stage that it occurred within. These results cast a new light on the importance of investigating the potential driving forces in the expansion of different urban land-use types. \u00a9 2021 Elsevier Ltd","Author Keywords":"Big data; Driving forces; Fine-scale; Huizhou; Random Forest; Urban land use","Authors":"Wu R., Wang J., Zhang D., Wang S.","DOI":"10.1016\/j.cities.2021.103202","x":-7.7100000381,"y":4.1399998665},{"HDBSCAN_Cluster":0,"DocId":437,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Assessment of deep learning techniques for land use land cover classification in southern new caledonia","Abstract":"Land use (LU) and land cover (LC) are two complementary pieces of cartographic information used for urban planning and environmental monitoring. In the context of New Caledonia, a biodiversity hotspot, the availability of up-to-date LULC maps is essential to monitor the impact of extreme events such as cyclones and human activities on the environment. With the democratization of satellite data and the development of high-performance deep learning techniques, it is possible to create these data automatically. This work aims at determining the best current deep learning configuration (pixel-wise vs. semantic labelling architectures, data augmentation, image prepos-sessing, \u2026 ), to perform LULC mapping in a complex, subtropical environment. For this purpose, a specific data set based on SPOT6 satellite data was created and made available for the scientific community as an LULC benchmark in a tropical, complex environment using five representative areas of New Caledonia labelled by a human operator: four used as training sets, and the fifth as a test set. Several architectures were trained and the resulting classification was compared with a state-of-the-art machine learning technique: XGboost. We also assessed the relevance of popular neo-channels derived from the raw observations in the context of deep learning. The deep learning approach showed comparable results to XGboost for LC detection and over-performed it on the LU detection task (61.45% vs. 51.56% of overall accuracy). Finally, adding LC classification output of the dedicated deep learning architecture to the raw channels input significantly improved the overall accuracy of the deep learning LU classification task (63.61% of overall accuracy). All the data used in this study are available on line for the remote sensing community and for assessing other LULC detection techniques. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Deep learning: XGBoost; Land cover; Land use; Neo-channels; Neural network; New Caledonia; Remote sensing","Authors":"Rousset G., Despinoy M., Schindler K., Mangeas M.","DOI":"10.3390\/rs13122257","x":-4.4899997711,"y":4.7600002289},{"HDBSCAN_Cluster":1,"DocId":439,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Regional population forecast and analysis based on machine learning strategy","Abstract":"Regional population forecast and analysis is of essence to urban and regional planning, and a well-designed plan can effectively construct a sound national infrastructure and stabilize positive population growth. Traditionally, either urban or regional planning relies on the opinions of demographers in terms of how the population of a city or a region will grow. Multi-regional population forecast is currently possible, carried out mainly on the basis of the Interregional Cohort-Component model. While this model has its unique advantages, several demographic rates are determined based on the decisions made by primary planners. Hence, the only drawback for cohort-component type population forecasting is allowing the analyst to specify the demographic rates of the future, and it goes without saying that this tends to introduce a biased result in forecasting accuracy. To effectively avoid this problem, this work proposes a machine learning-based method to forecast multi-regional population growth objectively. Thus, this work, drawing upon the newly developed machine learning technology, attempts to analyze and forecast the population growth of major cities in Taiwan. By effectively using the advantage of the XGBoost algorithm, the evaluation of feature importance and the forecast of multi-regional population growth between the present and the near future can be observed objectively, and it can further provide an objective reference to the urban planning of regional population. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Boosting regression; Population growth prediction","Authors":"Wang C.-Y., Lee S.-J.","DOI":"10.3390\/e23060656","x":-8.0,"y":4.2800002098},{"HDBSCAN_Cluster":0,"DocId":444,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Machine learning approach to extract building footprint from high-resolution images: The case study of Makkah, Saudi Arabia","Abstract":"Extracting and identifying building boundaries from high-resolution images have been a hot topic in the field of remote sensing for years. Various methods including geometric, radiometric, object based and edge detection were previously deliberated and implemented in different studies in the context of building extraction. Nevertheless, the reliability of extraction process is mainly subject to user intervention. The current study proposes a new automatic morphology-based approach for extracting buildings using high-resolution satellite images of Al-Hudaybiyah region in the city of Makkah as a case study. The proposed technique integrates the support vector machine for extracting buildings that have bright and dark roofs. The appropriateness of this method has been examined by means of various indicators for example completeness, correctness and quality. Preliminary findings will illustrate the precision and accuracy of the used machine learning algorithm. Research results can provide a generic indicator to assist the planning authorities in achieving better urban planning processes taking into account all potential environmental, social and urban demands and requirements. \u00a9 2021 The Author(s) 2021. Published by Oxford University Press.","Author Keywords":"extract building footprint; high-resolution images; machine learning; Makkah","Authors":"Faisal K., Imam A., Majrashi A., Hegazy I.","DOI":"10.1093\/ijlct\/ctaa099","x":-6.0300002098,"y":5.5900001526},{"HDBSCAN_Cluster":0,"DocId":450,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"A refined method of high-resolution remote sensing change detection based on machine learning for newly constructed building areas","Abstract":"Automatic detection of newly constructed building areas (NCBAs) plays an important role in addressing issues of ecological environment monitoring, urban management, and urban planning. Compared with low-and-middle resolution remote sensing images, high-resolution remote sensing images are superior in spatial resolution and display of refined spatial details. Yet its problems of spectral heterogeneity and complexity have impeded research of change detection for high-resolution remote sensing images. As generalized machine learning (including deep learning) technologies proceed, the efficiency and accuracy of recognition for ground-object in remote sensing have been substantially improved, providing a new solution for change detection of high-resolution remote sensing images. To this end, this study proposes a refined NCBAs detection method consisting of four parts based on generalized machine learning: (1) pre-processing; (2) candidate NCBAs are obtained by means of bi-temporal building masks acquired by deep learning semantic segmentation, and then registered one by one; (3) rules and support vector machine (SVM) are jointly adopted for classification of NCBAs with high, medium and low confidence; and (4) the final vectors of NCBAs are obtained by post-processing. In addition, area-based and pixel-based methods are adopted for accuracy assessment. Firstly, the proposed method is applied to three groups of GF1 images covering the urban fringe areas of Jinan, whose experimental results are divided into three categories: high, high-medium, and high-medium-low confidence. The results show that NCBAs of high confidence share the highest F1 score and the best overall effect. Therefore, only NCBAs of high confidence are considered to be the final detection result by this method. Specifically, in NCBAs detection for three groups GF1 images in Jinan, the mean Recall of area-based and pixel-based assessment methods reach around 77% and 91%, respectively, the mean Pixel Accuracy (PA) 88% and 92%, and the mean F1 82% and 91%, confirming the effectiveness of this method on GF1. Similarly, the proposed method is applied to two groups of ZY302 images in Xi\u2019an and Kunming. The scores of F1 for two groups of ZY302 images are also above 90% respectively, confirming the effectiveness of this method on ZY302. It can be concluded that adoption of area registration improves registration efficiency, and the joint use of prior rules and SVM classifier with probability features could avoid over and missing detection for NCBAs. In practical applications, this method is contributive to automatic NCBAs detection from high-resolution remote sensing images. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Areas registration; Change detection; Deep learning; High-resolution remote sensing; Newly constructed building areas; SVM","Authors":"Wang H., Qi J., Lei Y., Wu J., Li B., Jia Y.","DOI":"10.3390\/rs13081507","x":-5.0,"y":5.6999998093},{"HDBSCAN_Cluster":0,"DocId":451,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"Machine Learning Methods for Road Edge Detection on Fused Airborne Hyperspectral and LIDAR Data","Abstract":"In the last decades, remote sensing sensors, such as hyperspectral systems or LiDAR scanners, have been used for urban mapping. However, an analysis in the urban environment is very complex in applications, e.g., road detection, city management, and urban planning. One of the important urban features is the detection of the road edges. In this study, an approach on multisensory hyperspectral and LiDAR data fusion (HL-Fusion) is introduced for road edge detection using different machine learning algorithms, such as Support Vector Machines, Random Forests, and Convolutional Neural Networks. The first results show that the Random Forest algorithm outperformed in the experiments on the study area at Oslo's surroundings in Norway. This study opens a window for further investigation on machine learning algorithms and a better understanding of HL-Fusion capabilities. \u00a9 2021 IEEE.","Author Keywords":"data fusion; Hyperspectral; LiDAR; machine learning; remote sensing; road edge detection","Authors":"Senchuri R., Kuras A., Burud I.","DOI":"10.1109\/WHISPERS52202.2021.9484007","x":-5.5,"y":6.0100002289},{"HDBSCAN_Cluster":0,"DocId":454,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"A study on vehicle detection through aerial images: Various challenges, issues and applications","Abstract":"Nowadays vehicle detection and counting at the border of countries, as well as states\/cities, has become popular through aerial images because of security concerns. It will play a vital role to reduce the various crimes i.e. (children kidnapping, drug\/alcohol smuggling, traffic misconduct, weapons smuggling, sexual misconduct and mission of country-related crime, etc.) at the border of the cities as well as countries. Vehicle detection and counting have various other applications like traffic management, parking allotment, tracking the rescue vehicle in hill areas, digital watermarking, vehicle tracking at the toll plaza and urban planning, etc. However, vehicle detection and counting task are very challenging and difficult because of the complex background, the small size of the vehicle, other similar visual appearance objects, distance, etc. Till now, traditional methodology introduced several robust algorithms which has limitations while extracting the features from aerial images. Recently, deep learning-based algorithms introduced and the outcomes of these algorithms are robust for such kind of applications in the area of computer vision. But accuracy of these algorithms is not optimized in aerial images because the deep learning algorithm required a huge amount of data to train the machine and the size of the object in aerial images is also too small. All these factors affecting the efficiency of the real-time device. This paper provides a brief description of traditional algorithms as well as machine learning and deep learning concepts to identifying the object through aerial images. The study has shown the comprehensive analysis of benchmark datasets and their parameters and corresponding challenges used by researchers and scientists in the area of object detection\/tracking through aerial images. \u00a9 2021 IEEE.","Author Keywords":"Aerial Images; Machine Learning; Security; Vehicle","Authors":"Kumar S., Rajan E.G., Rani S.","DOI":"10.1109\/ICCCIS51004.2021.9397116","x":-4.5799999237,"y":5.5300002098},{"HDBSCAN_Cluster":0,"DocId":455,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Fusion of airborne lidar point clouds and aerial images for heterogeneous land-use urban mapping","Abstract":"The World Health Organization has reported that the number of worldwide urban residents is expected to reach 70% of the total world population by 2050. In the face of challenges brought about by the demographic transition, there is an urgent need to improve the accuracy of urban land-use mappings to more efficiently inform about urban planning processes. Decision-makers rely on accurate urban mappings to properly assess current plans and to develop new ones. This study investigates the effects of including conventional spectral signatures acquired by different sensors on the classification of airborne LiDAR (Light Detection and Ranging) point clouds using multiple feature spaces. The proposed method applied three machine learning algorithms\u2014ML (Maximum Likelihood), SVM (Support Vector Machines), and MLP (Multilayer Perceptron Neural Network)\u2014to classify LiDAR point clouds of a residential urban area after being geo-registered to aerial photos. The overall classification accuracy passed 97%, with height as the only geometric feature in the classifying space. Misclassifications occurred among different classes due to independent acquisition of aerial and LiDAR data as well as shadow and orthorectification problems from aerial images. Nevertheless, the outcomes are promising as they surpassed those achieved with large geometric feature spaces and are encouraging since the approach is computationally reasonable and integrates radiometric properties from affordable sensors. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Bootstrap aggregation; K-fold cross-validation; LiDAR classification; LiDAR-aerial geo-registration; LiDAR-aerial integration; Maximum likelihood; Neural networks; Supervised machine learning; Support vector machines; Urban land-use","Authors":"Megahed Y., Shaker A., Yan W.Y.","DOI":"10.3390\/rs13040814","x":-6.0599999428,"y":6.1999998093},{"HDBSCAN_Cluster":1,"DocId":474,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Analysis of built-up areas of small polish cities with the use of deep learning and geographically weighted regression","Abstract":"Small cities are an important part of the settlement system, a link between rural areas and large cities. Although they perform important functions, research focuses on large cities and metropolises while marginalizing small cities, the study of which is of great importance to progress in social sciences, geography, and urban planning. The main goal of this paper was to verify the impact of selected socio-economic factors on the share of built-up areas in 665 small Polish cities in 2019. Data from the Database of Topographic Objects (BDOT), Sentinel-2 satellite imagery from 2015 and 2019, and Local Data Bank by Statistics Poland form 2019 were used in the research. A machine learning segmentation procedure was used to obtain the data on the occurrence of built-up areas. Hot Spot (Getis-Ord Gi*) analysis and geographically weighted regression (GWR) was applied to explain spatially varying impact of factors related to population, spatial and economic development, and living standards on the share of built-up areas in the area of small cities. Significant association was found between the population density and the share of built-up areas in the area of the cities studied. The influence of the other socio-economic factors examined, related to the spatial and economic development of the cities and the quality of life of the inhabitants, showed great regional variation. The results also indicated that the share of built-up areas in the area of the cities under study is a result of the conditions under which they were established and developed throughout their existence, and not only of the socio-economic factors affecting them at present. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Build-up areas; Deep learning; GWR; Hot Spot (Getis-Ord Gi*); Poland; Small cities","Authors":"Adamiak M., Ja\u017cd\u017cewska I., Nalej M.","DOI":"10.3390\/geosciences11050223","x":-8.1599998474,"y":4.6199998856},{"HDBSCAN_Cluster":1,"DocId":485,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Analyzing the spatiotemporal uncertainty in urbanization predictions","Abstract":"With the availability of computational resources, geographical information systems, and remote sensing data, urban growth modeling has become a viable tool for predicting urbanization of cities and towns, regions, and nations around the world. This information allows policy makers, urban planners, environmental and civil organizations to make investments, design infrastructure, extend public utility networks, plan housing solutions, and mitigate adverse environmental impacts. Despite its importance, urban growth models often discard the spatiotemporal uncertainties in their prediction estimates. In this paper, we analyzed the uncertainty in the urban land predictions by comparing the outcomes of two different growth models, one based on a widely applied cellular automata model known as the SLEUTH CA and the other one based on a previously published machine learning framework. We selected these two models because they are complementary, the first is based on human knowledge and pre-defined and understandable policies while the second is more data-driven and might be less influenced by any a priori knowledge or bias. To test our methodology, we chose the cities of Jiaxing and Lishui in China because they are representative of new town planning policies and have different characteristics in terms of land extension, geographical conditions, growth rates, and economic drivers. We focused on the spatiotemporal uncertainty, understood as the inherent doubt in the predictions of where and when will a piece of land become urban, using the concepts of certainty area in space and certainty area in time. The proposed analyses in this paper aim to contribute to better urban planning exercises, and they can be extended to other cities worldwide. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Machine learning; SLEUTH CA; Spatiotemporal uncertainty; Urban growth; Urban planning tools; Urban science; Urbanization processes","Authors":"G\u00f3mez J.A., Guan C., Tripathy P., Duque J.C., Passos S., Keith M., Liu J.","DOI":"10.3390\/rs13030512","x":-7.8200001717,"y":4.1999998093},{"HDBSCAN_Cluster":1,"DocId":497,"Cited by":null,"Year":2020,"Document Type":"Article","Title":"Urban population distribution mapping with multisource geospatial data based on zonal strategy","Abstract":"Mapping population distribution at fine resolutions with high accuracy is crucial to urban planning and management. This paper takes Guangzhou city as the study area, illustrates the gridded population distribution map by using machine learning methods based on zoning strategy with multisource geospatial data such as night light remote sensing data, point of interest data, land use data, and so on. The street-level accuracy evaluation results show that the proposed approach achieved good overall accuracy, with determinant coefficient (R2) being 0.713 and root mean square error (RMSE) being 5512.9. Meanwhile, the goodness of fit for single linear regression (LR) model and random forest (RF) regression model are 0.0039 and 0.605, respectively. For dense area, the accuracy of the random forest model is better than the linear regression model, while for sparse area, the accuracy of the linear regression model is better than the random forest model. The results indicated that the proposed method has great potential in fine-scale population mapping. Therefore, it is advised that the zonal modeling strategy should be the primary choice for solving regional differences in the population distribution mapping research. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Guangzhou; Point of interest; Population mapping; Random forest; Zonal model","Authors":"Zhao G., Yang M.","DOI":"10.3390\/ijgi9110654","x":-7.1799998283,"y":4.3000001907},{"HDBSCAN_Cluster":1,"DocId":522,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"A Machine Learning-Based Method for Predicting Urban Land Use","Abstract":"Land use is one of the most basic elements of urban management. In urban planning and design, land use is often determined by experience and case studies. However, the development of urbanization has led to a combinatory trend for land use, and the land use of a plot is always impacted by the surrounding environment. In such a complex situation, it is difficult to find hidden relationships among types of land use by humans alone. Within artificial intelligence, machine learning can help find correlations among data. This paper presents a new method for learning the rules relating the known land use data and predicting the land use of a target plot by constructing an artificial neural network. We take Nanjing as a specific case and study the logic of its land use. The results not only demonstrate associations between the surroundings and the target but also show the feasibility of a combinatory land use index in urban planning and design. \u00a9 2020 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.","Author Keywords":"Artificial neural network; Land use; Machine learning; Urban planning and design","Authors":"Xia X., Tong Z.","DOI":null,"x":-7.5799999237,"y":4.8000001907},{"HDBSCAN_Cluster":0,"DocId":531,"Cited by":null,"Year":2020,"Document Type":"Article","Title":"Mapping Urban Slum Settlements Using Very High-Resolution Imagery and Land Boundary Data","Abstract":"Accurate mapping of slums is crucial for urban planning and management. This article proposes a machine learning, hierarchical object-based method to map slum settlements using very high-resolution (VHR) imagery and land boundary data to support slum upgrading. The proposed method is tested in Kingston Metropolitan Area, Jamaica. First, the VHR imagery is classified into major land cover classes (i.e., the initial land cover map). Second, the VHR imagery and land boundary layer are used to obtain homogenous neighborhoods (HNs). Third, the initial land cover map is used to derive multiple context, spectral, and texture image features according to the local physical characteristics of slum settlements. Fourth, a machine-learning classifier, classification and regression trees, is used to classify HNs into slum and nonslum settlements using only the effective image features. Finally, reference data collected manually are used to assess the accuracy of the classification. In the training site, an overall accuracy of 0.935 is achieved. The effective image indicators for slum mapping include the building layout, building density, building roof characteristics, and distance from buildings to gullies. The classifier and those features selected from the training site are further used to map slums in two validating sites to assess the transferability of our approach. Overall accuracy of the two validating sites reached 0.928 and 0.929, respectively, suggesting that the features and classification model obtained from one site has the potential to be transferred to other areas in Jamaica and possibly other developing Caribbean countries with similar situation and data availability. \u00a9 2008-2012 IEEE.","Author Keywords":"Classification and regression trees (CART); Jamaica; object-oriented classification; slum settlements; very high-resolution (VHR) image","Authors":"Williams T.K.-A., Wei T., Zhu X.","DOI":"10.1109\/JSTARS.2019.2954407","x":-6.2899999619,"y":4.9400000572},{"HDBSCAN_Cluster":0,"DocId":532,"Cited by":null,"Year":2020,"Document Type":"Book Chapter","Title":"Comparison of performance of artificial neural network (ANN) and random forest (RF) in the classification of land cover zones of urban slum region","Abstract":"India is one of the world\u2019s largest economies and economic growth has remained continuous. This has led to accelerating urbanization which requires proper planning and monitoring. As the urban areas are expanding, urban slum areas are also increasing along with it. These growing urban slum areas require proper observation so that existing resources can be employed to provide these regions with the best possible livelihood conditions. For this purpose, urban slum areas as well as surrounding land resources should be well identified and classified so that the existing land resources can be appropriately utilized for future implementation of development activities. Machine learning classification algorithms are found to be very suitable for the identification and classification of remotely sensed images. Their efficiency in feature identification and extraction has established these algorithms as important tools in decision making. In this study, our major objective is to identify and classify different land cover zones in the urban slums areas of Chingrajpara area of Chhattisgarh using remotely-sensed images. For this purpose, high-resolution images, collected using unmanned aerial vehicles (UAVs), are used and these images are classified into different land cover features using two different machine learning algorithms Artificial Neural Network (ANN) and Random Forest (RF). The results obtained show that the overall accuracy achieved by ANN and RF are 72.6% and 84.35% respectively. The study highlights the role and importance of landcover classification for future planning and management. \u00a9 Springer Nature Switzerland AG 2020.","Author Keywords":"Artificial neural network (ANN); Random forest (RF); Unmanned aerial vehicles (UAVs)","Authors":"Tyagi D., Haq M.A., Rahaman G., Baral P., Datta J.","DOI":"10.1007\/978-3-030-37393-1_20","x":-5.9000000954,"y":4.5100002289},{"HDBSCAN_Cluster":0,"DocId":568,"Cited by":null,"Year":2018,"Document Type":"Conference Paper","Title":"Automatic semantic segmentation for change detection in remote sensing images","Abstract":"Change detection (CD) mainly focuses on the extraction of change information from multispectral remote sensing images of the same geographical location for environmental monitoring, natural disaster evaluation, urban studies, and deforestation monitoring. While capturing the Landsat imagery, there may occur data missing issues such as occlusion of cloud, camera sensor, and aperture artifacts. The existing machine learning approaches do not provide significant results. This paper proposes a DeepLab Dilated convolutional neural network (DL-DCNN) for semantic segmentation with the goal to occur the change map for earth observation applications. Experimental results reveal that the accuracy of the proposed change detection results provides improved results as compared with the existing algorithms and maps the semantic objects within the predefined class as change or no change. \u00a9 Springer Nature Singapore Pte Ltd. 2018.","Author Keywords":"Change detection; Deep learning; Multispectral; Remote sensing","Authors":"Kulkarni T., Venugopal N.","DOI":"10.1007\/978-981-10-8569-7_34","x":-4.9899997711,"y":5.5},{"HDBSCAN_Cluster":0,"DocId":575,"Cited by":null,"Year":2017,"Document Type":"Conference Paper","Title":"A support vector machine approach on object based image analysis for feature extraction from high resolution images","Abstract":"Satellite images are the most important available data sources for generation and updating of available maps. They have highly improved in terms of spatial, spectral and temporal resolutions and by the sheer volume of collected images, the necessity of simplification of automation in feature extraction. Road data play a key role in urban planning, traffic management, military applications, and vehicle navigation as well as for decision making in numerous applications. The faster updation of road infrastructure is a need because the technology has brought map in the hands of people in the form of mobile phones and tablets. Road detection is one of the major issues of the road infrastructure extraction. Its accuracy depends on the type of methodology used. An attempt is made here to analyse the first order, the co-occurrence texture features and image transforms useful for discriminating roads from other features specially the buildings. The identified dataset forms high dimension feature space and the Support Vector Machine is a theoretically superior machine learning methodology with great results in classification of high dimensional datasets. In the past, SVMs have been tested and evaluated only as pixel-based image classifiers. Moving from pixel-based techniques towards object-based representation, the dimensions of remote sensing imagery feature space increases significantly. An SVM approach for classification was followed, based on primitive image objects produces by a multi-resolution segmentation algorithm. The SVM procedure produced the final object classification results which were compared to the Nearest Neighbor classifier results and were found to give better results in OBIA domain. \u00a9 2017 ACRS. All rights reserved.","Author Keywords":"Feature Extraction; Grey-Level Co-occurrence textures; Object Based Image Analysis (OBIA); Support Vector Machine (SVM)","Authors":"Kumar M., Srivastav S.K., Garg P.K.","DOI":null,"x":-5.7300000191,"y":5.6199998856},{"HDBSCAN_Cluster":1,"DocId":576,"Cited by":null,"Year":2017,"Document Type":"Article","Title":"Urban inefficient industrial land recognition system based on augmented learning model","Abstract":"From a salient point of view, urban planning has a significant impact on the expansion of the residential, industrial and commercial land. Land planning has a positive impact on the development of residential land but negatively affects the expansion of industrial, commercial and mining land, that is to say, the plot planned for construction land has a lower probability of transforming into construction land, which is not in line with common sense, indicating that the compilation of the land planning is far from the expansion of actual construction land. Therefore, this paper presents the urban inefficient industrial land recognition system based on augmented learning model. We adopt endogenous optimization method to determine the weight of each input factor, do not need to estimate parameters in advance, no correlation requirement to input and output variables, avoiding the input-output relationship of the expression and the index weight to determine the specific functional form of subjectivity. With this model, the urban planning model is then optimized to satisfy the general requirements.","Author Keywords":"Augmented learning; Inefficient industrial; Land recognition; Machine learning; Urban","Authors":"Rao Y., Dai D.","DOI":null,"x":-7.3499999046,"y":4.8099999428}]