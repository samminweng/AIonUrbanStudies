[{"Group":0,"score":0.7902706604,"NumPhrases":70,"Key-phrases":["high resolution DEM data","image SR method","traditional interpolation method","terrain character","urban planning","Building change detection","urban planning and development","imagery and Digital Elevation Model","new GeoAI research method","building and road","impervious surface","Landsat and Sentinel series","Automatic building extraction","Photogrammetry and Remote Sensing","hyperspectral and LiDAR data fusion","urban mapping","aerial image","UAV image","urban planning and management","building extraction accuracy","visible band difference vegetation index","Building footprint information","earth observation field","scene and roofing material","digital urban data","multitemporal satellite image","bathymetry estimation","satellite imagery","Coastal development","UAV video","urban planning and disaster management","aerial building dataset","geoinformatics community","real world HSR image dataset","high resolution earth observation image","specific decoder leverage roof type classification","3D city model","inexpensive satellite imagery","land cover mapping","urban climate","multispectral data","building size prediction","urban intelligent navigator","drone","LIDAR and computer vision method","airborne SAR mapping approach","such LIDAR","date building map","Overhead imagery","Earth Observation Data","Spark RDD image","lidar","complex urban study area","urban data","accurate and fast building detection","subsampled orthophoto","urban study area","aerial imagery","building detection","Landsat imagery","urban study and deforestation monitoring","change map","Urban Atlas land classification dataset","land use","automatic building detection","intelligent unmanned aerial vehicle navigation","building detection framework","single satellite image","popular aerial image dataset UCMerced Land use","multispectral high resolution scene"],"NumDocs":35,"DocIds":[9,16,23,46,66,73,87,118,128,141,161,165,169,183,188,226,231,234,237,254,259,314,330,389,398,418,460,462,463,469,473,490,525,547,548],"dimension":28,"min_samples":5,"min_cluster_size":30,"x":[3.2599999905,3.4200000763,3.2999999523,3.0399999619,2.4000000954,2.3800001144,2.3699998856,3.2300000191,2.6400001049,2.5,2.8099999428,3.3199999332,2.4400000572,3.2000000477,3.1600000858,2.5199999809,3.2000000477,3.3399999142,2.4200000763,2.4200000763,3.1400001049,2.3900001049,3.2300000191,2.6800000668,2.6099998951,3.2999999523,2.9300000668,3.1500000954,2.5399999619,3.3399999142,2.4800000191,2.5999999046,2.7100000381,3.2300000191,3.2699999809,2.5799999237,2.5499999523,3.1099998951,2.7599999905,2.4700000286,3.2200000286,2.3800001144,2.7100000381,3.2699999809,3.0399999619,3.0699999332,3.1199998856,2.5299999714,3.1600000858,3.0999999046,3.4700000286,3.0699999332,2.4700000286,2.7200000286,2.5,3.3199999332,2.5099999905,3.0499999523,2.5099999905,3.25,2.5299999714,2.6500000954,2.7699999809,2.5599999428,2.5599999428,3.1300001144,2.4900000095,3.2699999809,2.9100000858,3.25],"y":[4.9899997711,4.9600000381,4.9200000763,5.0900001526,5.6100001335,5.8200001717,5.6500000954,5.0100002289,5.3400001526,5.5199999809,5.2800002098,5.0999999046,5.7699999809,5.1300001144,5.1399998665,5.5999999046,5.1199998856,5.0300002098,5.5599999428,5.7600002289,5.1300001144,5.7699999809,5.0999999046,5.4699997902,5.5199999809,5.1300001144,5.1999998093,5.2399997711,5.4299998283,5.0399999619,5.5799999237,5.6399998665,5.3699998856,5.0700001717,5.1500000954,5.6599998474,5.6100001335,5.2300000191,5.3699998856,5.5599999428,5.1100001335,5.7399997711,5.4499998093,5.0999999046,5.2199997902,5.1700000763,5.1900000572,5.5500001907,5.1399998665,5.1799998283,4.9099998474,5.2699999809,5.6100001335,5.4200000763,5.8000001907,5.0300002098,5.5599999428,5.2399997711,5.7399997711,5.1199998856,5.5,5.4600000381,5.4699997902,5.4299998283,5.7100000381,5.1599998474,5.75,5.1900000572,5.3499999046,5.0999999046]},{"Group":1,"score":0.5889723253,"NumPhrases":65,"Key-phrases":["neural network","many powerful general semantic segmentation model","multiscale prediction","deep supervision","new deep supervision module","deep learning","novel semisupervised scene classification method","generator loss","generative adversarial net","semantic representation","source deep learning","natural feature detection","class semantic segmentation task","extreme learning machine","convolutional network","change detection","deep neural network","Kernel Point Convolution","Random Forest algorithm","Convolutional Neural Networks","vehicle detection","deep learning algorithm","semantic segmentation","deep supervision and scale attention","damage detection system","deep learning model","incident wave signature","semantic segmentation method","CNN architecture","single receptive field","deep representation","GLGOD Net","sparse representation and classification","transfer learning framework","scene image classifier","single objective loss","mask R CNN","object detection method","deep convolutional neural network","scene classification task","deep learning framework","invariant augmentation","R CNN","adversarial training scheme","unsupervised feature","Transfer Learning","CNNs parameter","Deep learning paradigm","raw input data","multiple sensor input","candidate identification","spectral spatial residual network","other deep learning model","binary feature classification","superpixel segmentation","shadow detection","deep learning scheme","change detection result","deep architecture","matrix covariance descriptor","pair segmentation algorithm region descriptor","MRF","optimal label","classifier layer","spatial feature"],"NumDocs":37,"DocIds":[9,16,23,37,46,66,73,87,93,118,128,141,161,165,169,183,188,226,231,234,237,254,259,314,330,389,398,418,460,462,463,469,473,490,525,547,548],"dimension":28,"min_samples":5,"min_cluster_size":30,"x":[3.3900001049,2.9000000954,3.1199998856,3.3800001144,3.3399999142,3.5399999619,2.8099999428,3.25,3.6600000858,3.0299999714,3.6099998951,2.75,2.9300000668,3.2699999809,3.6700000763,2.7300000191,3.6300001144,3.4900000095,2.9800000191,3.7200000286,2.75,3.4600000381,2.9600000381,3.3199999332,2.7599999905,3.5799999237,2.8900001049,2.8800001144,3.6099998951,3.25,3.3099999428,3.6600000858,3.0399999619,3.0999999046,2.9300000668,3.1400001049,3.3900001049,2.7799999714,3.6300001144,2.9400000572,3.5399999619,3.3599998951,3.5599999428,3.3399999142,2.8299999237,3.1600000858,3.5899999142,3.4300000668,3.5799999237,2.9500000477,2.8699998856,3.3900001049,3.4700000286,2.8699998856,2.9600000381,2.75,3.3599998951,2.8599998951,3.5199999809,3.0999999046,2.9300000668,3.4200000763,3.0,3.0499999523,2.8099999428],"y":[5.2399997711,5.2100000381,5.2300000191,5.0900001526,5.1100001335,5.1100001335,5.5199999809,5.1100001335,5.0199999809,5.2600002289,5.0999999046,5.6799998283,5.2600002289,5.2100000381,5.1799998283,5.6599998474,5.0700001717,5.2699999809,5.4400000572,5.0999999046,5.5300002098,5.2300000191,5.2199997902,5.1199998856,5.4800000191,5.1799998283,5.3699998856,5.2699999809,5.0999999046,5.3000001907,5.2800002098,5.0300002098,5.4099998474,5.1300001144,5.5,5.2300000191,5.1999998093,5.5900001526,5.0900001526,5.4699997902,5.1300001144,5.1100001335,5.0900001526,5.0500001907,5.5799999237,5.1700000763,5.1399998665,5.1300001144,5.0999999046,5.3499999046,5.5100002289,5.2699999809,5.2100000381,5.5199999809,5.3000001907,5.6300001144,5.1599998474,5.5,5.1100001335,5.3899998665,5.3400001526,5.0799999237,5.3200001717,5.4000000954,5.5700001717]},{"Group":-1,"score":-0.1732221112,"NumPhrases":33,"Key-phrases":["selective nonlocal operation","atrous spatial pyramid","natural disaster detection","new data fusion strategy","open access Sentinel","same pixel","U net_adam_bands","raw 3D point cloud","earth population","road edges","huge amount","security concern","extra lightweight encoder","large earthquake","temporal dynamic","ResNet50 encoder","human productive activity","geographic image retrieval","spatial pyramid matching","secondary task","important role","lczs","small object","predominant feature","different street object","large scale dataset","large annotated dataset","physical interpretation","single vehicle extraction","hyperspectral image classification","D cube","standard benchmark","huge opportunity"],"NumDocs":27,"DocIds":[16,23,37,46,66,73,93,118,128,161,165,183,188,226,231,234,237,254,259,314,389,398,418,460,462,490,548],"dimension":28,"min_samples":5,"min_cluster_size":30,"x":[2.7699999809,3.2100000381,2.5699999332,3.0499999523,3.25,3.5899999142,3.5899999142,3.1099998951,2.9800000191,2.7000000477,2.8599998951,3.2100000381,3.4100000858,2.6500000954,2.9900000095,3.4900000095,2.7699999809,2.9600000381,3.0599999428,2.9300000668,2.8699998856,3.4200000763,2.9700000286,2.7599999905,2.6600000858,3.0099999905,3.0199999809,2.9400000572,2.8199999332,3.1800000668,3.3199999332,2.9500000477,2.9000000954],"y":[5.4699997902,5.3299999237,5.5599999428,5.1999998093,5.1599998474,5.0799999237,5.0500001907,5.1900000572,5.1999998093,5.25,5.2399997711,5.2100000381,4.9699997902,5.4000000954,5.3200001717,4.9800000191,5.3699998856,5.3800001144,5.4499998093,5.3000001907,5.3299999237,5.0900001526,5.3699998856,5.5999999046,5.4099998474,5.1700000763,5.1799998283,5.3099999428,5.4400000572,5.1900000572,5.2199997902,5.2600002289,5.2699999809]}]