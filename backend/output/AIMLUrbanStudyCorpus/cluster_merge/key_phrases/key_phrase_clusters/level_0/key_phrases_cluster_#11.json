[{"Group":0,"score":0.7430636148,"NumPhrases":70,"Key-phrases":["high resolution DEM data","image SR method","traditional interpolation method","terrain character","urban planning","Building change detection","urban planning and development","natural disaster detection","imagery and Digital Elevation Model","new GeoAI research method","building and road","impervious surface","Landsat and Sentinel series","Automatic building extraction","Photogrammetry and Remote Sensing","raw 3D point cloud","hyperspectral and LiDAR data fusion","urban mapping","aerial image","huge amount","UAV image","urban planning and management","building extraction accuracy","visible band difference vegetation index","Building footprint information","earth observation field","scene and roofing material","large earthquake","digital urban data","multitemporal satellite image","satellite imagery","Coastal development","UAV video","urban planning and disaster management","aerial building dataset","human productive activity","geoinformatics community","real world HSR image dataset","high resolution earth observation image","specific decoder leverage roof type classification","3D city model","inexpensive satellite imagery","land cover mapping","urban climate","multispectral data","building size prediction","urban intelligent navigator","drone","airborne SAR mapping approach","date building map","Overhead imagery","Earth Observation Data","lidar","complex urban study area","urban data","accurate and fast building detection","subsampled orthophoto","urban study area","aerial imagery","building detection","Landsat imagery","urban study and deforestation monitoring","change map","Urban Atlas land classification dataset","land use","automatic building detection","building detection framework","single satellite image","popular aerial image dataset UCMerced Land use","multispectral high resolution scene"],"NumDocs":37,"DocIds":[9,16,23,37,46,66,73,87,93,118,128,141,161,165,169,183,188,226,231,234,237,254,259,314,330,389,398,418,460,462,463,469,473,490,525,547,548],"dimension":70,"min_samples":5,"min_cluster_size":30,"x":[5.7300000191,5.7399997711,5.75,5.6500000954,5.4899997711,5.6700000763,5.4699997902,5.6300001144,5.6999998093,5.4899997711,5.5999999046,5.6500000954,5.6700000763,5.6700000763,5.6300001144,5.7899999619,5.7399997711,5.5700001717,5.6999998093,5.5599999428,5.7800002098,5.5100002289,5.6500000954,5.6300001144,5.6300001144,5.5799999237,5.6399998665,5.5399999619,5.5700001717,5.6599998474,5.6399998665,5.4899997711,5.75,5.5199999809,5.6300001144,5.5599999428,5.5199999809,5.7100000381,5.6399998665,5.6500000954,5.5999999046,5.6700000763,5.5700001717,5.4800000191,5.6799998283,5.6199998856,5.6799998283,5.7600002289,5.6799998283,5.5599999428,5.7199997902,5.5700001717,5.7600002289,5.5399999619,5.5300002098,5.7100000381,5.6999998093,5.5100002289,5.6599998474,5.6399998665,5.6700000763,5.5,5.5700001717,5.5799999237,5.5,5.7100000381,5.6700000763,5.6599998474,5.5999999046,5.7100000381],"y":[4.3000001907,4.3099999428,4.2600002289,4.4400000572,4.6700000763,4.4800000191,4.6399998665,4.4000000954,4.3299999237,4.6300001144,4.5900001526,4.4499998093,4.3499999046,4.4800000191,4.3400001526,4.3699998856,4.3200001717,4.5700001717,4.4000000954,4.4899997711,4.3299999237,4.6700000763,4.5199999809,4.3299999237,4.5300002098,4.3600001335,4.4800000191,4.4699997902,4.5599999428,4.25,4.3800001144,4.6199998856,4.3400001526,4.5799999237,4.4899997711,4.5799999237,4.5599999428,4.3400001526,4.3499999046,4.4800000191,4.5700001717,4.3699998856,4.5100002289,4.6799998283,4.3200001717,4.5700001717,4.5,4.3600001335,4.3499999046,4.5199999809,4.3400001526,4.4099998474,4.3499999046,4.6599998474,4.5700001717,4.5,4.3400001526,4.6700000763,4.4000000954,4.5100002289,4.3400001526,4.6399998665,4.5199999809,4.5300002098,4.6399998665,4.4899997711,4.4899997711,4.3200001717,4.4800000191,4.3099999428]},{"Group":1,"score":0.5363726702,"NumPhrases":70,"Key-phrases":["neural network","many powerful general semantic segmentation model","multiscale prediction","deep supervision","new deep supervision module","deep learning","novel semisupervised scene classification method","generator loss","generative adversarial net","semantic representation","source deep learning","natural feature detection","class semantic segmentation task","extreme learning machine","convolutional network","change detection","deep neural network","Kernel Point Convolution","Random Forest algorithm","Convolutional Neural Networks","vehicle detection","deep learning algorithm","semantic segmentation","deep supervision and scale attention","damage detection system","deep learning model","incident wave signature","semantic segmentation method","CNN architecture","single receptive field","deep representation","GLGOD Net","sparse representation and classification","spatial pyramid matching","transfer learning framework","scene image classifier","single objective loss","mask R CNN","object detection method","deep convolutional neural network","scene classification task","deep learning framework","small object","predominant feature","invariant augmentation","R CNN","LIDAR and computer vision method","adversarial training scheme","unsupervised feature","Transfer Learning","CNNs parameter","Deep learning paradigm","raw input data","single vehicle extraction","multiple sensor input","candidate identification","spectral spatial residual network","other deep learning model","binary feature classification","superpixel segmentation","shadow detection","deep learning scheme","change detection result","deep architecture","matrix covariance descriptor","pair segmentation algorithm region descriptor","MRF","optimal label","classifier layer","spatial feature"],"NumDocs":37,"DocIds":[9,16,23,37,46,66,73,87,93,118,128,141,161,165,169,183,188,226,231,234,237,254,259,314,330,389,398,418,460,462,463,469,473,490,525,547,548],"dimension":70,"min_samples":5,"min_cluster_size":30,"x":[5.7699999809,5.8400001526,5.7600002289,5.7899999619,5.7800002098,5.75,5.7399997711,5.7800002098,5.8299999237,5.7600002289,5.8000001907,5.7300000191,5.8099999428,5.7699999809,5.8299999237,5.7600002289,5.8099999428,5.8499999046,5.7199997902,5.7600002289,5.7600002289,5.8000001907,5.8400001526,5.7699999809,5.75,5.7800002098,5.7199997902,5.8299999237,5.8200001717,5.8200001717,5.7899999619,5.8099999428,5.75,5.7699999809,5.7199997902,5.75,5.7800002098,5.8299999237,5.75,5.8000001907,5.7699999809,5.7899999619,5.7399997711,5.6799998283,5.8099999428,5.8000001907,5.8000001907,5.8099999428,5.7199997902,5.7600002289,5.8299999237,5.7899999619,5.7600002289,5.7399997711,5.7699999809,5.7100000381,5.8099999428,5.7899999619,5.6999998093,5.8299999237,5.7600002289,5.7699999809,5.7399997711,5.7699999809,5.7800002098,5.8000001907,5.7699999809,5.7600002289,5.75,5.6900000572],"y":[4.3899998665,4.3200001717,4.4099998474,4.3400001526,4.3200001717,4.3699998856,4.4899997711,4.4699997902,4.3400001526,4.2699999809,4.3400001526,4.5,4.3800001144,4.3800001144,4.3499999046,4.3699998856,4.3400001526,4.3800001144,4.5100002289,4.3600001335,4.4899997711,4.3400001526,4.3299999237,4.4000000954,4.3899998665,4.3299999237,4.2899999619,4.3600001335,4.3600001335,4.4200000763,4.3600001335,4.3600001335,4.4499998093,4.4600000381,4.3400001526,4.4899997711,4.4600000381,4.3899998665,4.4899997711,4.3299999237,4.4600000381,4.3400001526,4.5,4.5500001907,4.3800001144,4.3800001144,4.3499999046,4.3800001144,4.5300002098,4.3899998665,4.3600001335,4.3600001335,4.3400001526,4.5199999809,4.3600001335,4.5300002098,4.3800001144,4.3600001335,4.5100002289,4.3699998856,4.4800000191,4.3699998856,4.3600001335,4.3600001335,4.4200000763,4.4099998474,4.3899998665,4.4600000381,4.4699997902,4.5199999809]},{"Group":-1,"score":-0.3270680726,"NumPhrases":28,"Key-phrases":["selective nonlocal operation","atrous spatial pyramid","new data fusion strategy","open access Sentinel","same pixel","U net_adam_bands","earth population","road edges","security concern","extra lightweight encoder","bathymetry estimation","temporal dynamic","ResNet50 encoder","geographic image retrieval","secondary task","important role","lczs","different street object","such LIDAR","large scale dataset","Spark RDD image","large annotated dataset","physical interpretation","hyperspectral image classification","D cube","standard benchmark","intelligent unmanned aerial vehicle navigation","huge opportunity"],"NumDocs":25,"DocIds":[16,23,46,66,73,93,118,128,161,169,183,188,226,234,237,254,314,330,389,398,418,462,490,525,548],"dimension":70,"min_samples":5,"min_cluster_size":30,"x":[5.6300001144,5.75,5.7300000191,5.6900000572,5.8000001907,5.8000001907,5.5300002098,5.6700000763,5.6999998093,5.7800002098,5.5999999046,5.7199997902,5.7800002098,5.6199998856,5.6199998856,5.5999999046,5.7800002098,5.6700000763,5.7699999809,5.5900001526,5.7699999809,5.6500000954,5.7100000381,5.7300000191,5.7699999809,5.5999999046,5.7699999809,5.5999999046],"y":[4.5500001907,4.4499998093,4.3499999046,4.4099998474,4.3499999046,4.3600001335,4.4400000572,4.5300002098,4.4299998283,4.3200001717,4.4200000763,4.2699999809,4.3400001526,4.4800000191,4.5399999619,4.5100002289,4.4000000954,4.5799999237,4.3600001335,4.4000000954,4.3200001717,4.4000000954,4.2800002098,4.3699998856,4.4400000572,4.4000000954,4.4000000954,4.4800000191]}]