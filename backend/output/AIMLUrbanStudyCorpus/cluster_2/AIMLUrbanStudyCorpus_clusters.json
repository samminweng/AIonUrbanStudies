[{"HDBSCAN_Cluster":0,"DocId":6,"Cited by":null,"Year":2022,"Document Type":"Article","Title":"Generative Adversarial Network Approach to Future Sermonizing of Housing Dispersal in Emerging Cities","Abstract":"This study aims to visualize the future housing dispersal of expatriates, based on the predicted urban growth in emerging cities. Generalized adversarial networks (GANs) will be utilized to predict the future urban growth of Doha Metropolitan emerging city. The housing dispersal of expatriates will be visualized on the predicted urban growth map to investigate housing preferences, which will be based on Gordon's theory. This study will prove the feasibility of a process approach when practicing the management of urban growth in emerging cities worldwide. It could be a robust solution for the worsening imbalance in the urban morphology of metropolitan cities. The findings of the broad-spectrum housing dispersal guidelines could benefit the policymakers and planners for the realities of spatial patterns and future urban growth. \u00a9 2021 American Society of Civil Engineers.","Author Keywords":"Emerging cities; Generative adversarial network; Housing dispersal; Machine learning; Urban growth","Authors":"Ibrahim H., Khattab Z., Khattab T., Abraham R.","DOI":"10.1061\/(ASCE)UP.1943-5444.0000783","x":11.78,"y":3.44},{"HDBSCAN_Cluster":-1,"DocId":8,"Cited by":null,"Year":2022,"Document Type":"Article","Title":"Automatic Target Detection from Satellite Imagery Using Machine Learning","Abstract":"Object detection is a vital step in satellite imagery-based computer vision applications such as precision agriculture, urban planning and defense applications. In satellite imagery, object detection is a very complicated task due to various reasons including low pixel resolution of objects and detection of small objects in the large scale (a single satellite image taken by Digital Globe com-prises over 240 million pixels) satellite images. Object detection in satellite images has many challenges such as class variations, multiple objects pose, high variance in object size, illumination and a dense background. This study aims to compare the performance of existing deep learning algorithms for object detection in satellite imagery. We created the dataset of satellite imagery to perform object detection using convolutional neural network-based frameworks such as faster RCNN (faster region-based convolutional neural network), YOLO (you only look once), SSD (single-shot detector) and SIMRDWN (satellite imagery multiscale rapid detection with windowed networks). In addition to that, we also performed an analysis of these approaches in terms of accuracy and speed using the developed dataset of satellite imagery. The results showed that SIMRDWN has an accuracy of 97% on high-resolution images, while Faster RCNN has an accuracy of 95.31% on the standard resolution (1000 \u00d7 600). YOLOv3 has an accuracy of 94.20% on standard resolution (416 416) while on the other hand SSD has an accuracy of 84.61% on standard resolution (300 \u00d7 300). When it comes to speed and efficiency, YOLO is the obvious leader. In real-time surveillance, SIMRDWN fails. When YOLO takes 170 to 190 milliseconds to perform a task, SIMRDWN takes 5 to 103 milliseconds. \u00a9 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Deep learning; Faster RCNN; Satellite images; SIMRDWN; SSD; YOLO","Authors":"Tahir A., Munawar H.S., Akram J., Adil M., Ali S., Kouzani A.Z., Pervez Mahmud M.A.","DOI":"10.3390\/s22031147","x":16.08,"y":5.23},{"HDBSCAN_Cluster":1,"DocId":9,"Cited by":null,"Year":2022,"Document Type":"Article","Title":"Comparison of DEM Super-Resolution Methods Based on Interpolation and Neural Networks","Abstract":"High-resolution digital elevation models (DEMs) play a critical role in geospatial databases, which can be applied to many terrain-related studies such as facility siting, hydrological analysis, and urban design. However, due to the limitation of precision of equipment, there are big gaps to collect high-resolution DEM data. A practical idea is to recover high-resolution DEMs from easily obtained low-resolution DEMs, and this process is termed DEM super-resolution (SR). However, traditional DEM SR methods (e.g., bicubic interpolation) tend to over-smooth high-frequency regions on account of the operation of averaging local variations. With the recent development of machine learning, image SR methods have made great progress. Nevertheless, due to the complexity of terrain characters (e.g., peak and valley) and the huge difference between elevation field and image RGB (Red, Green, and Blue) value field, there are few works that apply image SR methods to the task of DEM SR. Therefore, this paper investigates the question of whether the state-of-the-art image SR methods are appropriate for DEM SR. More specifically, the traditional interpolation method and three excellent SR methods based on neural networks are chosen for comparison. Experimental results suggest that SRGAN (Super-Resolution with Generative Adversarial Network) presents the best performance on accuracy evaluation over a series of DEM SR experiments. \u00a9 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"DEM; Neural network; Super-resolution process; Terrain features","Authors":"Zhang Y., Yu W.","DOI":"10.3390\/s22030745","x":16.33,"y":5.51},{"HDBSCAN_Cluster":1,"DocId":11,"Cited by":null,"Year":2022,"Document Type":"Article","Title":"Urban Catchment-Scale Blue-Green-Gray Infrastructure Classification with Unmanned Aerial Vehicle Images and Machine Learning Algorithms","Abstract":"Green infrastructure (GI), such as green roofs, is now widely used in sustainable urban development. An accurate mapping of GI is important to provide surface parameterization for model development. However, the accuracy and precision of mapping GI is still a challenge in identifying GI at the small catchment scale. We proposed a framework for blue-green-gray infrastructure classification using machine learning algorithms and unmanned aerial vehicle (UAV) images that contained digital surface model (DSM) information. We used the campus of the Southern University of Science and Technology in Shenzhen, China, as a study case for our classification method. The UAV was a DJI Phantom 4 Multispectral, which measures the blue, green, red, red-edge, and near-infrared bands and DSM information. Six machine learning algorithms, i.e., fuzzy classifier, k-nearest neighbor classifier, Bayes classifier, classification and regression tree, support vector machine (SVM), and random forest (RF), were used to classify blue (including water), green (including green roofs, grass, trees (shrubs), bare land), and gray (including buildings, roads) infrastructure. The highest kappa coefficient was observed for RF and the lowest was observed for SVM, with coefficients of 0.807 and 0.381, respectively. We optimized the sampling method based on a chessboard grid and got the optimal sampling interval of 11.6\u00a0m to increase the classification efficiency. We also analyzed the effects of weather conditions, seasons, and different image layers, and found that images in overcast days or winter days could improve the classification accuracy. In particular, the DSM layer was crucial for distinguishing green roofs and grass, and buildings and roads. Our study demonstrates the feasibility of using UAV images in urban blue-green-gray infrastructure classification, and our infrastructure classification framework based on machine learning algorithms is effective. Our results could provide the basis for the future urban stormwater management model development and aid sustainable urban planning. Copyright \u00a9 2022 Jia, Cui and Liu.","Author Keywords":"blue infrastructure; classification; green infrastructure; machine learning; unmanned aerial vehicle images","Authors":"Jia J., Cui W., Liu J.","DOI":"10.3389\/fenvs.2021.778598","x":14.29,"y":4.62},{"HDBSCAN_Cluster":1,"DocId":16,"Cited by":null,"Year":2022,"Document Type":"Article","Title":"SNLRUX++ for Building Extraction from High-Resolution Remote Sensing Images","Abstract":"Building extraction plays an important role in high-resolution remote sensing image processing, which can be used as the basis for urban planning and demographic analysis. In recent years, many powerful general semantic segmentation models have emerged, but these models often perform poorly when transferred to remote sensing images because of the characteristics of remote sensing images. To this end, we propose a new deep learning network called Selective Nonlocal ResUNeXt++ (SNLRUX++) for building extraction. First, the cascaded multiscale feature fusion is proposed to transform the high-performance image classification network ResNeXt into the segmentation network ResUNeXt++. Second, selective nonlocal operation is designed to establish long-range dependencies while avoiding introducing excessive noise and computational effort. Finally, multiscale prediction is applied as deep supervision to accelerate training and convergence, and improves prediction performance of objects at different scales. The experimental results on two different remote sensing image datasets show the effectiveness and generalization ability of the proposed method. \u00a9 2008-2012 IEEE.","Author Keywords":"Building extraction; convolution neural network; deep learning; high-resolution image; remote sensing","Authors":"Lei Y., Yu J., Chan S., Wu W., Liu X.","DOI":"10.1109\/JSTARS.2021.3135705","x":15.93,"y":6.11},{"HDBSCAN_Cluster":1,"DocId":23,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"DSA-Net: A novel deeply supervised attention-guided network for building change detection in high-resolution remote sensing images","Abstract":"Building change detection (BCD) plays a crucial role in urban planning and development and has received extensive attention. However, existing deep learning-based change detection methods suffer from limited accuracy, mainly due to the information loss and inadequate capability in feature extraction. To overcome these shortcomings, we propose a novel deeply supervised attention-guided network (DSA-Net) for BCD tasks in high-resolution images. In the DSA-Net, we innovatively introduce a spatial attention mechanism-guided cross-layer addition and skip-connection (CLA-Con-SAM) module to aggregate multi-level contextual information, weaken the heterogeneity between raw image features and difference features, and direct the network's attention to changed regions. We also introduce an atrous spatial pyramid pooling (ASPP) module to extract multi-scale features. To further improve detection performance, we implement a new deep supervision module to enhance the ability of middle layers to extract more distinctive features. We conduct quantitative and qualitative experiments on the two publicly available datasets, i.e., the LEVIR-CD and the WHU Building datasets. Compared with the competing methods, the proposed DSA-Net achieves the best performance in all evaluation metrics. The efficiency analysis reveals that the proposed DSA-Net achieves a great balance between BCD performance and complexity\/efficiency, with faster convergence and higher robustness. \u00a9 2021 The Authors","Author Keywords":"Building change detection; CLA-Con-SAM; Deep learning; Deep supervision; DSA-Net","Authors":"Ding Q., Shao Z., Huang X., Altan O.","DOI":"10.1016\/j.jag.2021.102591","x":16.41,"y":5.9},{"HDBSCAN_Cluster":1,"DocId":37,"Cited by":2.0,"Year":2021,"Document Type":"Article","Title":"GAN-Based Semisupervised Scene Classification of Remote Sensing Image","Abstract":"With the advent of a large number of remote sensing images (RSIs), scene classification of RSI is widely applied to many fields such as urban planning, natural disaster detection, and environmental monitoring. Compared with the natural image field, the lack of labeled RSI is a bottleneck of supervised scene classification methods based on deep learning. Meanwhile, unsupervised scene classification is difficult to meet actual needs. To this end, we propose a novel semisupervised scene classification method for RSI using generative adversarial nets (GANs), in which a gating unit, a self-attention gating (SAG) module, and a pretrained Inception V3 branch are introduced into discriminative network to enhance the feature representation capability for facilitating semisupervised classification. To be specific, the gating unit aims to learn the weights of each feature map and capture the dependence relationship between features. The SAG module aims to capture a long-range dependence for adaptively focusing on important scene regions. The Inception V3 branch aims to extract the high-level semantic representation of input images and further enhance the discriminant ability by gating unit and SAG module. Furthermore, a new optimization term is incorporated into the generator loss to indirectly drive discriminator to correctly classify scene images. To verify the effectiveness of the proposed method, extensive experimental results on UC Merced and EuroSAT data sets demonstrate that the method surpasses most of the state-of-the-art semisupervised image classification methods significantly, especially when only few samples are tagged. \u00a9 2004-2012 IEEE.","Author Keywords":"Gating unit; generative adversarial nets (GANs); remote sensing image (RSI); self-attention gating (SAG) module; semisupervised image classification","Authors":"Guo D., Xia Y., Luo X.","DOI":"10.1109\/LGRS.2020.3014108","x":16.3,"y":5.08},{"HDBSCAN_Cluster":0,"DocId":42,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"SPATIAL CLASSIFICATION of URBAN LAND by SPECULATIVE LAND VALUE and MSI SATELLITE IMAGERY USING K-MEANS, in HUANCAYO, PERU [CLASIFICACI\u00d3N ESPACIAL DEL SUELO URBANO POR EL VALOR ESPECULATIVO DEL SUELO E IM\u00c1GENES MSI SATELITALES USANDO K-MEANS, HUANCAYO, PER\u00da]","Abstract":"The city of Huancayo, like other intermediate cities in Latin America, faces problems of poorly planned land-use changes and a rapid dynamic of the urban land market. The scarce and outdated information on the urban territory impedes the adequate classification of urban areas, limiting the form of its intervention. The purpose of this research was the adoption of unassisted and mixed methods for the spatial classification of urban areas, considering the speculative land value, the proportion of urbanized land, and other geospatial variables. Among the data collection media, Multi-Spectral Imagery (MSI) from the Sentinel-2 satellite, the primary road system, and a sample of direct observation points, were used. The processed data were incorporated into georeferenced maps, to which urban limits and official slopes were added. During data processing, the K-Means algorithm was used, together with other machine learning and assisted judgment methods. As a result, an objective classification of urban areas was obtained, which differs from the existing planning. \u00a9 2021 The authors. All right reserved.","Author Keywords":"Artificial intelligence; Real estate market; Urban periphery; Urban planning","Authors":"Zamalloa G.R.P.","DOI":"10.22320\/07183607.2021.24.44.06","x":13.41,"y":4.03},{"HDBSCAN_Cluster":1,"DocId":46,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"GeoAI in terrain analysis: Enabling multi-source deep learning and data fusion for natural feature detection","Abstract":"In this paper we report on a new GeoAI research method which enables deep machine learning from multi-source geospatial data for natural feature detection. In particular, a multi-source, deep learning-based object detection pipeline was developed. This pipeline introduces three new features: First, strategies of both data-level fusion (i.e., channel expansion on convolutional neural networks) and feature-level fusion were integrated into the object detection model to allow simultaneous machine learning from multi-source data, including remote sensing imagery and Digital Elevation Model (DEM) data. Second, a new data fusion strategy was developed to blend DEM data and its derivatives to create a new, fused data source with enriched information content and image features. The model has also enabled deep learning by combining both the proposed data fusion and feature-level fusion strategies to yield a much-improved detection result. Third, two different sets of data augmentation techniques were applied to the multi-source training data to further improve the model performance. A series of experiments were conducted to verify the effectiveness of the proposed strategies in multi-source deep learning. \u00a9 2021 Elsevier Ltd","Author Keywords":"Data enrichment; Deep Learning; GeoAI; Multi-source data fusion; Object detection","Authors":"Wang S., Li W.","DOI":"10.1016\/j.compenvurbsys.2021.101715","x":16.34,"y":5.27},{"HDBSCAN_Cluster":0,"DocId":59,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Evaluating the ability to use contextual features derived from multi-scale satellite imagery to map spatial patterns of urban attributes and population distributions","Abstract":"With an increasing global population, accurate and timely population counts are essential for urban planning and disaster management. Previous research using contextual features, using mainly very-high-spatial-resolution imagery (&lt;2 m spatial resolution) at subnational to city scales, has found strong correlations with population and poverty. Contextual features can be defined as the statistical quantification of edge patterns, pixel groups, gaps, textures, and the raw spectral sig-natures calculated over groups of pixels or neighborhoods. While they correlated with population and poverty, which components of the human-modified landscape were captured by the contextual features have not been investigated. Additionally, previous research has focused on more costly, less frequently acquired very-high-spatial-resolution imagery. Therefore, contextual features from both very-high-spatial-resolution imagery and lower-spatial-resolution Sentinel-2 (10 m pixels) imagery in Sri Lanka, Belize, and Accra, Ghana were calculated, and those outputs were correlated with OpenStreetMap building and road metrics. These relationships were compared to determine what components of the human-modified landscape the features capture, and how spatial resolution and location impact the predictive power of these relationships. The results suggest that contextual features can map urban attributes well, with out-of-sample R2 values up to 93%. Moreover, the degradation of spatial resolution did not significantly reduce the results, and for some urban attributes, the results actually improved. Based on these results, the ability of the lower resolution Sentinel-2 data to predict the population density of the smallest census units available was then assessed. The findings indicate that Sentinel-2 contextual features explained up to 84% of the out-of-sample variation for population density. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Contextual features; Machine learning; Modeling; Population; Spatial resolution; Urban attributes","Authors":"Chao S., Engstrom R., Mann M., Bedada A.","DOI":"10.3390\/rs13193962","x":13.16,"y":4.23},{"HDBSCAN_Cluster":1,"DocId":66,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Multi-class strategies for joint building footprint and road detection in remote sensing","Abstract":"Building footprints and road networks are important inputs for a great deal of services. For instance, building maps are useful for urban planning, whereas road maps are essential for disaster response services. Traditionally, building and road maps are manually generated by remote sensing experts or land surveying, occasionally assisted by semi-automatic tools. In the last decade, deep learning-based approaches have demonstrated their capabilities to extract these elements automatically and accurately from remote sensing imagery. The building footprint and road network detection problem can be considered a multi-class semantic segmentation task, that is, a single model performs a pixel-wise classification on multiple classes, optimizing the overall performance. However, depending on the spatial resolution of the imagery used, both classes may coexist within the same pixel, drastically reducing their separability. In this regard, binary decomposition techniques, which have been widely studied in the machine learning literature, are proved useful for addressing multiclass problems. Accordingly, the multi-class problem can be split into multiple binary semantic segmentation sub-problems, specializing different models for each class. Nevertheless, in these cases, an aggregation step is required to obtain the final output labels. Additionally, other novel approaches, such as multi-task learning, may come in handy to further increase the performance of the binary semantic segmentation models. Since there is no certainty as to which strategy should be carried out to accurately tackle a multi-class remote sensing semantic segmentation problem, this paper performs an in-depth study to shed light on the issue. For this purpose, open-access Sentinel-1 and Sentinel-2 imagery (at 10 m) are considered for extracting buildings and roads, making use of the well-known U-Net convolutional neural network. It is worth stressing that building and road classes may coexist within the same pixel when working at such a low spatial resolution, setting a challenging problem scheme. Accordingly, a robust experimental study is developed to assess the benefits of the decomposition strategies and their combination with a multi-task learning scheme. The obtained results demonstrate that decomposing the considered multi-class remote sensing semantic segmentation problem into multiple binary ones using a One-vs-All binary decomposition technique leads to better results than the standard direct multi-class approach. Additionally, the benefits of using a multi-task learning scheme for pushing the performance of binary segmentation models are also shown. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Binary semantic segmentation; Building detection; Convolutional neural networks; Deep learning; Multi-class semantic segmentation; Multi-task semantic segmentation; Remote sensing; Road detection; Sentinel-1; Sentinel-2","Authors":"Ayala C., Aranda C., Galar M.","DOI":"10.3390\/app11188340","x":15.93,"y":5.97},{"HDBSCAN_Cluster":0,"DocId":72,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"A novel approach for change detection analysis of land cover from multispectral FCC optical image using machine learning","Abstract":"Land covers refers to the physical land types such as vegetation, water, urban area, roads, and many more according to the geographical region. With the rapid change in land-use patterns, the land covers are varying drastically which requires immediate attention to have an eye at the impact of the land use planning and environmental changes is on the right track, or it needs to be modified. Hence utilizing the advancements in remote sensing technology for analyzing Land Use Land Cover (L ULC) classification maps using satellite images of the geographical region plays an important role in analyzing the present scenario of land covers. This paper proposes a novel approach for change detection analysis using the classification maps generated using Machine Learning (ML) classification techniques on a particular geographical region surrounding Nirma University, Ahmedabad, India. The highest classification accuracy of 98.48% was achieved using Support Vector Machine (SVM) for Near Infrared (NIR) band False Colour Composite (FCC) image obtained from Sentinel 2. \u00a9 2021 IEEE.","Author Keywords":"Change Detection; Land Use Land Classification; Machine Learning; Multispectral; Remote Sensing","Authors":"Patel K., Jain M., Patel M.I., Gajjar R.","DOI":"10.1109\/ICORT52730.2021.9582057","x":14.39,"y":3.61},{"HDBSCAN_Cluster":1,"DocId":73,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Automatic detection of impervious surfaces from remotely sensed data using deep learning","Abstract":"The large scale quantification of impervious surfaces provides valuable information for urban planning and socioeconomic development. Remote sensing and GIS techniques provide spatial and temporal information of land surfaces and are widely used for modeling impervious surfaces. Traditionally, these surfaces are predicted by computing statistical indices derived from different bands available in remotely sensed data, such as the Landsat and Sentinel series. More recently, researchers have explored classification and regression techniques to model impervious surfaces. However, these modeling efforts are limited due to lack of labeled data for training and evaluation. This in turn requires significant effort for manual labeling of data and visual interpretation of results. In this paper, we train deep learning neural networks using TensorFlow to predict impervious surfaces from Landsat 8 images. We used OpenStreetMap (OSM), a crowd-sourced map of the world with manually interpreted impervious surfaces such as roads and buildings, to programmatically generate large amounts of training and evaluation data, thus overcoming the need for manual labeling. We conducted extensive experimentation to compare the performance of different deep learning neural network architectures, optimization methods, and the set of features used to train the networks. The four model configurations labeled U-Net_SGD_Bands, U-Net_Adam_Bands, U-Net_Adam_Bands+SI, and VGG-19_Adam_Bands+SI resulted in a root mean squared error (RMSE) of 0.1582, 0.1358, 0.1375, and 0.1582 and an accuracy of 90.87%, 92.28%, 92.46%, and 90.11%, respectively, on the test set. The U-Net_Adam_Bands+SI Model, similar to the others mentioned above, is a deep learning neural network that combines Landsat 8 bands with statistical indices. This model performs the best among all four on statistical accuracy and produces qualitatively sharper and brighter predictions of impervious surfaces as compared to the other models. \u00a9 2021 by the authors.","Author Keywords":"Deep learning; Google Earth Engine; Impervious surfaces; Machine learning; Remote sensing","Authors":"Parekh J.R., Poortinga A., Bhandari B., Mayer T., Saah D., Chishtie F.","DOI":"10.3390\/rs13163166","x":15.91,"y":5.05},{"HDBSCAN_Cluster":-1,"DocId":74,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Cloud detection using an ensemble of pixel-based machine learning models incorporating unsupervised classification","Abstract":"Remote sensing imagery, such as that provided by the United States Geological Survey (USGS) Landsat satellites, has been widely used to study environmental protection, hazard analysis, and urban planning for decades. Clouds are a constant challenge for such imagery and, if not handled correctly, can cause a variety of issues for a wide range of remote sensing analyses. Typically, cloud mask algorithms use the entire image; in this study we present an ensemble of different pixel-based approaches to cloud pixel modeling. Based on four training subsets with a selection of different input features, 12 machine learning models were created. We evaluated these models using the cropped LC8-Biome cloud validation dataset. As a comparison, Fmask was also applied to the cropped scene Biome dataset. One goal of this research is to explore a machine learning modeling approach that uses as small a training data sample as possible but still provides an accurate model. Overall, the model trained on the sample subset (1.3% of the total training samples) that includes unsupervised Self-Organizing Map classification results as an input feature has the best performance. The approach achieves 98.57% overall accuracy, 1.18% cloud omission error, and 0.93% cloud commission error on the 88 cropped test images. By comparison to Fmask 4.0, this model improves the accuracy by 10.12% and reduces the cloud omission error by 6.39%. Furthermore, using an additional eight independent validation images that were not sampled in model training, the model trained on the second largest subset with an additional five features has the highest overall accuracy at 86.35%, with 12.48% cloud omission error and 7.96% cloud commission error. This model\u2019s overall correctness increased by 3.26%, and the cloud omission error decreased by 1.28% compared to Fmask 4.0. The machine learning cloud classification models discussed in this paper could achieve very good performance utilizing only a small portion of the total training pixels available. We showed that a pixel-based cloud classification model, and that as each scene obviously has unique spectral characteristics, and having a small portion of example pixels from each of the sub-regions in a scene can improve the model accuracy significantly. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Cloud detection; Ensemble approaches; HOT; Landsat 8; Machine learning; NDSI; NDVI; Self organizing maps (SOM); Whitness","Authors":"Yu X., Lary D.J.","DOI":"10.3390\/rs13163289","x":15.19,"y":3.86},{"HDBSCAN_Cluster":0,"DocId":78,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Mapping essential urban land use categories with open big data: Results for five metropolitan areas in the United States of America","Abstract":"Urban land-use maps outlining the distribution, pattern, and composition of various land use types are critically important for urban planning, environmental management, disaster control, health protection, and biodiversity conservation. Recent advances in remote sensing and social sensing data and methods have shown great potentials in mapping urban land use categories, but they are still constrained by mixed land uses, limited predictors, non-localized models, and often relatively low accuracies. To inform these issues, we proposed a robust and cost-effective framework for mapping urban land use categories using openly available multi-source geospatial \u201cbig data\u201d. With street blocks generated from OpenStreetMap (OSM) data as the minimum classification unit, we integrated an expansive set of multi-scale spatially explicit information on land surface, vertical height, socio-economic attributes, social media, demography, and topography. We further proposed to apply the automatic ensemble learning that leverages a bunch of machine learning algorithms in deriving optimal urban land use classification maps. Results of block-level urban land use classification in five metropolitan areas of the United States found the overall accuracies of major-class (Level-I) and minor-class (Level-II) classification could be high as 91% and 86%, respectively. A multi-model comparison revealed that for urban land use classification with high-dimensional features, the multi-layer stacking ensemble models achieved better performance than base models such as random forest, extremely randomized trees, LightGBM, CatBoost, and neural networks. We found without very-high-resolution National Agriculture Imagery Program imagery, the classification results derived from Sentinel-1, Sentinel-2, and other open big data based features could achieve plausible overall accuracies of Level-I and Level-II classification at 88% and 81%, respectively. We also found that model transferability depended highly on the heterogeneity in characteristics of different regions. The methods and findings in this study systematically elucidate the role of data sources, classification methods, and feature transferability in block-level land use classifications, which have important implications for mapping multi-scale essential urban land use categories. \u00a9 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"Block-level mapping; Ensemble learning; Geospatial big data; Land use classification; NAIP; Sentinel-1\/2","Authors":"Chen B., Tu Y., Song Y., Theobald D.M., Zhang T., Ren Z., Li X., Yang J., Wang J., Wang X., Gong P., Bai Y., Xu B.","DOI":"10.1016\/j.isprsjprs.2021.06.010","x":13.77,"y":2.87},{"HDBSCAN_Cluster":-1,"DocId":87,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Comparing three machine learning techniques for building extraction from a digital surface model","Abstract":"Automatic building extraction from high-resolution remotely sensed data is a major area of interest for an extensive range of fields (e.g., urban planning, environmental risk management) but challenging due to urban morphology complexity. Among the different methods proposed, the approaches based on supervised machine learning (ML) achieve the best results. This paper aims to investigate building footprint extraction using only high-resolution raster digital surface model (DSM) data by comparing the performance of three different popular supervised ML models on a benchmark dataset. The first two methods rely on a histogram of oriented gradients (HOG) feature descriptor and a classical ML (support vector machine (SVM)) or a shallow neural network (extreme learning machine (ELM)) classifier, and the third model is a fully convolutional network (FCN) based on deep learning with transfer learning. Used data were obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) and cover the urban areas of Vaihingen an der Enz, Potsdam, and Toronto. The results indicated that performances of models based on shallow ML (feature extraction and classifier training) are affected by the urban context investigated (F1 scores from 0.49 to 0.81), whereas the FCN-based model proved to be the most robust and best-performing method for building extraction from a high-resolution raster DSM (F1 scores from 0.80 to 0.86). \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Automated building extraction; Deep learning (DL); Digital surface model (DSM); Extreme learning machine (ELM); Fully convolutional network (FCN); Histogram of oriented gradients (HOG); Machine learning (ML); Support vector machine (SVM)","Authors":"Notarangelo N.M., Mazzariello A., Albano R., Sole A.","DOI":"10.3390\/app11136072","x":15.32,"y":6.39},{"HDBSCAN_Cluster":-1,"DocId":89,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Building Roof Superstructures Classification from Imbalanced and Low Density Airborne LiDAR Point Cloud","Abstract":"Light Detection and Ranging (LiDAR), an active remote sensing technology, is becoming an essential tool for geoinformation extraction and urban planning. Airborne Laser Scanning (ALS) point clouds segmentation and accurate classification are challenging and crucial to produce different geo-information products like three-dimensional (3D) city designs. This paper introduces an effective data-driven approach to build roof superstructures classification for airborne LiDAR point clouds with very low density and imbalanced classes, covering an urban area. Notably, it focuses on building roof superstructures (especially dormers and chimneys) and mitigating nonplanar objects' problems. Also, the imbalanced class problem of LiDAR data, to the best of our knowledge, is not yet addressed in the literature; it is considered in this study. The major advantage of the proposed approach is using only raw data without assumptions on the distribution underlying data. The main methodological novelties of this work are summarized in the following key elements. (i) At first, an adapted connected component analysis for 3D points cloud is proposed. (ii) Twelve geometry-based features are extracted for each component. (iii) A Support Vector Machine (SVM)-driven procedure is applied to classify the 3D components. (iv) Furthermore, a new component size-based sampling (CSBS) method is proposed to treat the imbalanced data problem and has been compared with several existing resampling strategies. In this study, components are classified into five classes: shed and gable dormers, chimneys, ground, and others. The results of this investigation show the satisfying classification performance of the proposed approach. Results also showed that the proposed approach outperformed machine learning methods, including SVM, Random Forest, Decision Tree, and Adaboost. \u00a9 2001-2012 IEEE.","Author Keywords":"3D classification; imbalanced data; light detection and ranging (LiDAR); Low-density point cloud; roof superstructures","Authors":"Aissou B.E., Aissa A.B., Dairi A., Harrou F., Wichmann A., Kada M.","DOI":"10.1109\/JSEN.2021.3073535","x":14.25,"y":6.02},{"HDBSCAN_Cluster":0,"DocId":90,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Identifying different types of urban land use dynamics using Point-of-interest (POI) and Random Forest algorithm: The case of Huizhou, China","Abstract":"The significant economic development witnessed in China in recent decades has been accompanied by the increasing expansion of urban areas. Although a growing literature has analyzed the characteristics and driving forces of urban land expansion, less attention has been paid to examining the different expansion determinants driving fine-scale urban land use (residential land, administration and public services land, commercial land, and industrial land) change. This paper aims to identify the differences of multi-mechanisms driving fine-scale urban land use expansion based on big data and machine learning, in the Huizhou downtown area in 2000\u20132015. The Random Forest (RF) algorithm is used to identify the natural, transportation, location, social, and POI factors driving land expansion by considering different urban land-use categories. Our RF estimations showed that enormous differences existed between various urban land-use types in terms of the role they played in this expansion and their relation to potential determinants, during the different urban development stages studied. Transportation, location, and the distribution of actual land use were found to exert a greater influence on urban land expansion than other factors. All the findings above provide detailed spatiotemporal knowledge and targeted information that can aid in understanding fine-scale urban land use dynamics. In this way, sound planning strategies for different fine-scale land uses can be formulated more scientifically. The strength of association between these factors and urban land expansion differed greatly depending on the different land-use types involved as well as the urban development stage that it occurred within. These results cast a new light on the importance of investigating the potential driving forces in the expansion of different urban land-use types. \u00a9 2021 Elsevier Ltd","Author Keywords":"Big data; Driving forces; Fine-scale; Huizhou; Random Forest; Urban land use","Authors":"Wu R., Wang J., Zhang D., Wang S.","DOI":"10.1016\/j.cities.2021.103202","x":12.2,"y":3.59},{"HDBSCAN_Cluster":-1,"DocId":92,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"Assessment of combining convolutional neural networks and object based image analysis to land cover classification using sentinel 2 satellite imagery (Tenes Region, Algeria)","Abstract":"Land cover maps can provide valuable information for various applications, such as territorial monitoring, environmental protection, urban planning and climate change prevention. In this purpose, remote sensing based on image classification approaches undergoing a high revolution can be dedicated to land cover mapping tasks. Similarly, deep learning models are considerably applied in remote sensing applications; which can automatically learn features from large amounts of data. Prevalently, the Convolutional Neural Network (CNN), have been increasingly performed in image classification. The aim of this study is to apply a new approach to analyse land cover, and extract its features. Experiments carried out on a coastal town located in north-western Algeria (T\u00e9n\u00e8s region). The study area is chosen because of its importance as a part of the national strategy to combat natural hazards, specifically floods. As well as, a simple CNN model with two hidden layers was constructed, combined with an Object-Based Image Analysis (OBIA). In this regard, a Sentinel-2 image was used, to perform the classification, using spectral index combinations. Furthermore, to compare the performance of the proposed approach, an OBIA based on machines learning algorithms mainly Random Forest (RF) and Support Vector Machine (SVM), was provided. Results of accuracy assessment of classification showed good values in terms of Overall accuracy and Kappa Index, which reach to 93.1% and 0.91, respectively. As a comparison, CNN-OBIA approach outperformed OBIA based on RF algorithm. Therefore, Final land cover maps can be used as a support tool in regional and national decisions. \u00a9 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved.","Author Keywords":"Convolutional neural networks (CNN); Land cover; Machine learning; Object based image analysis (OBIA); Sentinel-2; T\u00e9n\u00e8s","Authors":"Zaabar N., Niculescu S., Mihoubi M.K.","DOI":"10.5194\/isprs-archives-XLIII-B3-2021-383-2021","x":15.35,"y":4.15},{"HDBSCAN_Cluster":1,"DocId":93,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"3D urban change detection with point cloud siamese networks","Abstract":"As the majority of the earth population is living in urban environments, cities are continuously evolving and efficient monitoring tools are needed to retrieve and classify their evolution. In this context, analysing changes between two dates is a crucial point. In urban environments, most changes occur along the vertical axis (with new construction or demolition of buildings) and the use of 3D data is therefore mandatory. Among them, LiDAR constitutes a valuable source of information. However, With the difficulty of processing sparse and unordered 3D point clouds, most of existing methods start by rasterizing point clouds (for example to Digital Surface Models) before using more conventional image processing tools. This implies a significant loss of information. Among existing studies dealing directly with point clouds, and to the best of our knowledge, no deep neural network-based method has been explored yet. Thus, in order to fill this gap and to test the ability of deep methods to deal with change detection and characterization of 3D point clouds, we propose a Siamese network with Kernel Point Convolution inspired by Siamese architectures that have already shown their performances on change detection in 2D images and on KPConv network which achieves high-quality results for semantic segmentation of raw 3D point clouds. We show quantitatively and qualitatively that our method outperforms by more than 25% (in terms of average Intersection over Union for classes of change) existing machine learning methods based on hand-crafted features. \u00a9 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved.","Author Keywords":"3D Change Detection; Deep Learning; Kernel Point Convolution; Point Clouds; Siamese Network; Urban Monitoring","Authors":"De G\u00e9lis I., Lef\u00e8vre S., Corpetti T.","DOI":"10.5194\/isprs-archives-XLIII-B3-2021-879-2021","x":16.28,"y":6.21},{"HDBSCAN_Cluster":-1,"DocId":96,"Cited by":2.0,"Year":2021,"Document Type":"Article","Title":"Assessment of deep learning techniques for land use land cover classification in southern new caledonia","Abstract":"Land use (LU) and land cover (LC) are two complementary pieces of cartographic information used for urban planning and environmental monitoring. In the context of New Caledonia, a biodiversity hotspot, the availability of up-to-date LULC maps is essential to monitor the impact of extreme events such as cyclones and human activities on the environment. With the democratization of satellite data and the development of high-performance deep learning techniques, it is possible to create these data automatically. This work aims at determining the best current deep learning configuration (pixel-wise vs. semantic labelling architectures, data augmentation, image prepos-sessing, \u2026 ), to perform LULC mapping in a complex, subtropical environment. For this purpose, a specific data set based on SPOT6 satellite data was created and made available for the scientific community as an LULC benchmark in a tropical, complex environment using five representative areas of New Caledonia labelled by a human operator: four used as training sets, and the fifth as a test set. Several architectures were trained and the resulting classification was compared with a state-of-the-art machine learning technique: XGboost. We also assessed the relevance of popular neo-channels derived from the raw observations in the context of deep learning. The deep learning approach showed comparable results to XGboost for LC detection and over-performed it on the LU detection task (61.45% vs. 51.56% of overall accuracy). Finally, adding LC classification output of the dedicated deep learning architecture to the raw channels input significantly improved the overall accuracy of the deep learning LU classification task (63.61% of overall accuracy). All the data used in this study are available on line for the remote sensing community and for assessing other LULC detection techniques. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Deep learning: XGBoost; Land cover; Land use; Neo-channels; Neural network; New Caledonia; Remote sensing","Authors":"Rousset G., Despinoy M., Schindler K., Mangeas M.","DOI":"10.3390\/rs13122257","x":15.66,"y":4.31},{"HDBSCAN_Cluster":0,"DocId":100,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Regional population forecast and analysis based on machine learning strategy","Abstract":"Regional population forecast and analysis is of essence to urban and regional planning, and a well-designed plan can effectively construct a sound national infrastructure and stabilize positive population growth. Traditionally, either urban or regional planning relies on the opinions of demographers in terms of how the population of a city or a region will grow. Multi-regional population forecast is currently possible, carried out mainly on the basis of the Interregional Cohort-Component model. While this model has its unique advantages, several demographic rates are determined based on the decisions made by primary planners. Hence, the only drawback for cohort-component type population forecasting is allowing the analyst to specify the demographic rates of the future, and it goes without saying that this tends to introduce a biased result in forecasting accuracy. To effectively avoid this problem, this work proposes a machine learning-based method to forecast multi-regional population growth objectively. Thus, this work, drawing upon the newly developed machine learning technology, attempts to analyze and forecast the population growth of major cities in Taiwan. By effectively using the advantage of the XGBoost algorithm, the evaluation of feature importance and the forecast of multi-regional population growth between the present and the near future can be observed objectively, and it can further provide an objective reference to the urban planning of regional population. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Boosting regression; Population growth prediction","Authors":"Wang C.-Y., Lee S.-J.","DOI":"10.3390\/e23060656","x":11.98,"y":3.37},{"HDBSCAN_Cluster":-1,"DocId":106,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Machine learning approach to extract building footprint from high-resolution images: The case study of Makkah, Saudi Arabia","Abstract":"Extracting and identifying building boundaries from high-resolution images have been a hot topic in the field of remote sensing for years. Various methods including geometric, radiometric, object based and edge detection were previously deliberated and implemented in different studies in the context of building extraction. Nevertheless, the reliability of extraction process is mainly subject to user intervention. The current study proposes a new automatic morphology-based approach for extracting buildings using high-resolution satellite images of Al-Hudaybiyah region in the city of Makkah as a case study. The proposed technique integrates the support vector machine for extracting buildings that have bright and dark roofs. The appropriateness of this method has been examined by means of various indicators for example completeness, correctness and quality. Preliminary findings will illustrate the precision and accuracy of the used machine learning algorithm. Research results can provide a generic indicator to assist the planning authorities in achieving better urban planning processes taking into account all potential environmental, social and urban demands and requirements. \u00a9 2021 The Author(s) 2021. Published by Oxford University Press.","Author Keywords":"extract building footprint; high-resolution images; machine learning; Makkah","Authors":"Faisal K., Imam A., Majrashi A., Hegazy I.","DOI":"10.1093\/ijlct\/ctaa099","x":14.27,"y":5.43},{"HDBSCAN_Cluster":-1,"DocId":113,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"A refined method of high-resolution remote sensing change detection based on machine learning for newly constructed building areas","Abstract":"Automatic detection of newly constructed building areas (NCBAs) plays an important role in addressing issues of ecological environment monitoring, urban management, and urban planning. Compared with low-and-middle resolution remote sensing images, high-resolution remote sensing images are superior in spatial resolution and display of refined spatial details. Yet its problems of spectral heterogeneity and complexity have impeded research of change detection for high-resolution remote sensing images. As generalized machine learning (including deep learning) technologies proceed, the efficiency and accuracy of recognition for ground-object in remote sensing have been substantially improved, providing a new solution for change detection of high-resolution remote sensing images. To this end, this study proposes a refined NCBAs detection method consisting of four parts based on generalized machine learning: (1) pre-processing; (2) candidate NCBAs are obtained by means of bi-temporal building masks acquired by deep learning semantic segmentation, and then registered one by one; (3) rules and support vector machine (SVM) are jointly adopted for classification of NCBAs with high, medium and low confidence; and (4) the final vectors of NCBAs are obtained by post-processing. In addition, area-based and pixel-based methods are adopted for accuracy assessment. Firstly, the proposed method is applied to three groups of GF1 images covering the urban fringe areas of Jinan, whose experimental results are divided into three categories: high, high-medium, and high-medium-low confidence. The results show that NCBAs of high confidence share the highest F1 score and the best overall effect. Therefore, only NCBAs of high confidence are considered to be the final detection result by this method. Specifically, in NCBAs detection for three groups GF1 images in Jinan, the mean Recall of area-based and pixel-based assessment methods reach around 77% and 91%, respectively, the mean Pixel Accuracy (PA) 88% and 92%, and the mean F1 82% and 91%, confirming the effectiveness of this method on GF1. Similarly, the proposed method is applied to two groups of ZY302 images in Xi\u2019an and Kunming. The scores of F1 for two groups of ZY302 images are also above 90% respectively, confirming the effectiveness of this method on ZY302. It can be concluded that adoption of area registration improves registration efficiency, and the joint use of prior rules and SVM classifier with probability features could avoid over and missing detection for NCBAs. In practical applications, this method is contributive to automatic NCBAs detection from high-resolution remote sensing images. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Areas registration; Change detection; Deep learning; High-resolution remote sensing; Newly constructed building areas; SVM","Authors":"Wang H., Qi J., Lei Y., Wu J., Li B., Jia Y.","DOI":"10.3390\/rs13081507","x":16.59,"y":5.72},{"HDBSCAN_Cluster":0,"DocId":114,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Modeling fine-scale residential land price distribution: An experimental study using open data and machine learning","Abstract":"Modeling the fine-scale spatiotemporal distribution of residential land prices (RLPs) is the basis for scientifically allocating land resources, managing the residential market and improving urban planning. The accurate mapping of the RLP dynamics require reliable land price prediction models and data with fine spatial and temporal resolution. With the aid of point of interest (POI) data and nighttime light (NTL) images, this paper attempts to explore the ability of machine learning algorithms (MLAs) to model grid-level RLPs using the case of Wuhan in China. Several land price prediction models were built using five MLAs and various geographic variables. The experimental results show that the extra-trees regression algorithm and the radial basis function-based support vector regression algorithm perform best in Period \u2160 (2010\u20132014) and Period \u2161 (2015\u20132019), respectively; therefore, they were selected to estimate the RLPs of the grids without observations in the corresponding period. Based on the estimated results, we found that the spatial pattern of the RLP in Wuhan transitioned from monocentric to polycentric between the two periods, and RLPs grew rapidly near newly formed urban subcenters and waterscapes. The relative importance of the predictor variables shows that commercial and educational facilities are important determinants of the RLP distribution in Wuhan; moreover, the relative importance of natural amenities and education facilities increased over time, while that of commercial facilities and public transportation decreased slightly. The case of Wuhan confirms the feasibility of MLAs and openly accessible urban data in modeling fine-scale RLP distributions. Our proposed framework provides a new approach to monitor the urban land price dynamics accurately and closely, which is beneficial for improving the infrastructure layout and achieve smart city growth. \u00a9 2021 Elsevier Ltd","Author Keywords":"Determinants; Land price distribution; Machine learning; Open data; Spatiotemporal variation; Wuhan","Authors":"Zhang P., Hu S., Li W., Zhang C., Yang S., Qu S.","DOI":"10.1016\/j.apgeog.2021.102442","x":11.87,"y":3.53},{"HDBSCAN_Cluster":1,"DocId":118,"Cited by":1.0,"Year":2021,"Document Type":"Conference Paper","Title":"Machine Learning Methods for Road Edge Detection on Fused Airborne Hyperspectral and LIDAR Data","Abstract":"In the last decades, remote sensing sensors, such as hyperspectral systems or LiDAR scanners, have been used for urban mapping. However, an analysis in the urban environment is very complex in applications, e.g., road detection, city management, and urban planning. One of the important urban features is the detection of the road edges. In this study, an approach on multisensory hyperspectral and LiDAR data fusion (HL-Fusion) is introduced for road edge detection using different machine learning algorithms, such as Support Vector Machines, Random Forests, and Convolutional Neural Networks. The first results show that the Random Forest algorithm outperformed in the experiments on the study area at Oslo's surroundings in Norway. This study opens a window for further investigation on machine learning algorithms and a better understanding of HL-Fusion capabilities. \u00a9 2021 IEEE.","Author Keywords":"data fusion; Hyperspectral; LiDAR; machine learning; remote sensing; road edge detection","Authors":"Senchuri R., Kuras A., Burud I.","DOI":"10.1109\/WHISPERS52202.2021.9484007","x":14.64,"y":5.31},{"HDBSCAN_Cluster":0,"DocId":119,"Cited by":13.0,"Year":2021,"Document Type":"Article","Title":"Predicting stream water quality under different urban development pattern scenarios with an interpretable machine learning approach","Abstract":"Urban development pattern significantly impacts stream water quality by influencing pollutant generation, build-up, and wash-off processes. It is thus necessary to understand and predict stream water quality in accordance with different urban development patterns to effectively advise urban growth planning and policies. To do so, we collected pollutant concentration data on nitrate (NO3\u2212-N), total phosphate (TP), and Escherichia coli (E. coli) from 1047 sampling stations in the Texas Gulf Region. We utilized a Random Forest (RF) machine learning model to predict stream water quality under four planning scenarios with different urban densities and configurations. SHapley Additive exPlanations (SHAP) was used to prove the importance of urban development pattern in influencing stream water quality. The spatial variations of the impact of these patterns were explored with Geographically Weighted Regression (GWR). SHAP results indicated that Largest Patch Index (LPI), Patch Cohesion Index (COHESION), Splitting Index (SPLIT), and Landscape Division Index (DIVISION) were the most important urban development pattern metrics affecting stream water quality. The spatial variations of such patterns were shown to impact stream water quality depending on pollutants, seasonality, climate, and urbanization level. RF prediction results suggested that high density aggregated development was more effective in reducing TP and NO3\u2212-N concentrations than the current sprawl development, but had the potential risk of increasing E. coli pollution in the wet season. The results of this study provide empirical evidence and a potential mechanistic explanation that stream water quality degradation is a consequence of urban sprawl. Lastly, machine learning is a powerful tool for scenario prediction in land use planning to forecast environmental impacts under different urban development pattern scenarios. \u00a9 2020 Elsevier B.V.","Author Keywords":"Landscape metrics; Machine learning; Scenario planning; Urban form; Urban sprawl; Water quality","Authors":"Wang R., Kim J.-H., Li M.-H.","DOI":"10.1016\/j.scitotenv.2020.144057","x":12.7,"y":2.62},{"HDBSCAN_Cluster":0,"DocId":120,"Cited by":4.0,"Year":2021,"Document Type":"Article","Title":"Using satellite image fusion to evaluate the impact of land use changes on ecosystem services and their economic values","Abstract":"Accelerated land use change is a current challenge for environmental management world-wide. Given the urgent need to incorporate economic and ecological goals in landscape planning, cost-effective conservation strategies are required. In this study, we validated the benefit of fusing imagery from multiple sensors to assess the impact of landscape changes on ecosystem services (ES) and their economic values in the Long County, Shaanxi Province, China. We applied several landscape metrics to assess the local spatial configuration over 15 years (2004\u20132019) from fused image-ries. Using Landsat-7 Enhanced Thematic Mapper Plus (ETM+), Landsat-8 Operational Land Im-ager (OLI) and Indian Remote Sensing Satellite System Linear Imaging Self Scanning Sensor 3 (IRS LISS 3) imageries fused for 2004, 2009, 2014 and 2019, we reclassified land use\/land cover (LULC) changes, through the rotation forest (RF) machine-learning algorithm. We proposed an equivalent monetary metric for estimating the ES values, which also could be used in the whole China. Results showed that agriculture farmland and unused land decreased their spatial distribution over time, with an observed increase on woodland, grassland, water bodies and built-up area. Our findings suggested that the patterns of landscape uniformity and connectivity improved, while the distribution of landscape types stabilized, while the landscape diversity had a slight improvement. The overall ES values increased (4.34%) under a benefit transfer approach, mainly concerning woodland and grassland. A sensitivity analysis showed the selected economic value (EV) was relevant and suitable for the study area associated with our ES for LULC changes. We suggested that changes in landscape patterns affected the ESV trends, while the increases on some LULC classes slightly improved the landscape diversity. Using an interdisciplinary approach, we recommend that local au-thorities and environmental practitioners should balance the economic benefits and ecological gains in different landscapes to achieve a sustainable development from local to regional scales. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Environmental monitoring; Image fusion; Landscape patterns; Remote sens-ing; Urban ecosystem services","Authors":"Shuangao W., Padmanaban R., Mbanze A.A., Silva J.M.N., Shamsudeen M., Cabral P., Campos F.S.","DOI":"10.3390\/rs13050851","x":14.2,"y":3.03},{"HDBSCAN_Cluster":1,"DocId":128,"Cited by":1.0,"Year":2021,"Document Type":"Conference Paper","Title":"A study on vehicle detection through aerial images: Various challenges, issues and applications","Abstract":"Nowadays vehicle detection and counting at the border of countries, as well as states\/cities, has become popular through aerial images because of security concerns. It will play a vital role to reduce the various crimes i.e. (children kidnapping, drug\/alcohol smuggling, traffic misconduct, weapons smuggling, sexual misconduct and mission of country-related crime, etc.) at the border of the cities as well as countries. Vehicle detection and counting have various other applications like traffic management, parking allotment, tracking the rescue vehicle in hill areas, digital watermarking, vehicle tracking at the toll plaza and urban planning, etc. However, vehicle detection and counting task are very challenging and difficult because of the complex background, the small size of the vehicle, other similar visual appearance objects, distance, etc. Till now, traditional methodology introduced several robust algorithms which has limitations while extracting the features from aerial images. Recently, deep learning-based algorithms introduced and the outcomes of these algorithms are robust for such kind of applications in the area of computer vision. But accuracy of these algorithms is not optimized in aerial images because the deep learning algorithm required a huge amount of data to train the machine and the size of the object in aerial images is also too small. All these factors affecting the efficiency of the real-time device. This paper provides a brief description of traditional algorithms as well as machine learning and deep learning concepts to identifying the object through aerial images. The study has shown the comprehensive analysis of benchmark datasets and their parameters and corresponding challenges used by researchers and scientists in the area of object detection\/tracking through aerial images. \u00a9 2021 IEEE.","Author Keywords":"Aerial Images; Machine Learning; Security; Vehicle","Authors":"Kumar S., Rajan E.G., Rani S.","DOI":"10.1109\/ICCCIS51004.2021.9397116","x":15.78,"y":5.4},{"HDBSCAN_Cluster":-1,"DocId":129,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Fusion of airborne lidar point clouds and aerial images for heterogeneous land-use urban mapping","Abstract":"The World Health Organization has reported that the number of worldwide urban residents is expected to reach 70% of the total world population by 2050. In the face of challenges brought about by the demographic transition, there is an urgent need to improve the accuracy of urban land-use mappings to more efficiently inform about urban planning processes. Decision-makers rely on accurate urban mappings to properly assess current plans and to develop new ones. This study investigates the effects of including conventional spectral signatures acquired by different sensors on the classification of airborne LiDAR (Light Detection and Ranging) point clouds using multiple feature spaces. The proposed method applied three machine learning algorithms\u2014ML (Maximum Likelihood), SVM (Support Vector Machines), and MLP (Multilayer Perceptron Neural Network)\u2014to classify LiDAR point clouds of a residential urban area after being geo-registered to aerial photos. The overall classification accuracy passed 97%, with height as the only geometric feature in the classifying space. Misclassifications occurred among different classes due to independent acquisition of aerial and LiDAR data as well as shadow and orthorectification problems from aerial images. Nevertheless, the outcomes are promising as they surpassed those achieved with large geometric feature spaces and are encouraging since the approach is computationally reasonable and integrates radiometric properties from affordable sensors. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Bootstrap aggregation; K-fold cross-validation; LiDAR classification; LiDAR-aerial geo-registration; LiDAR-aerial integration; Maximum likelihood; Neural networks; Supervised machine learning; Support vector machines; Urban land-use","Authors":"Megahed Y., Shaker A., Yan W.Y.","DOI":"10.3390\/rs13040814","x":14.17,"y":5.68},{"HDBSCAN_Cluster":0,"DocId":130,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Optimization of a novel urban growth simulation model integrating an artificial fish swarm algorithm and cellular automata for a smart city","Abstract":"As one of the 17 Sustainable Development Goals, it is sensible to analysis historical urban land use characteristics and project the potentials of urban sustainable development for a smart city. The cellular automaton (CA) model is the widely applied in simulating urban growth, but the optimum parameters of variables driving urban growth in the model remains to be continued to improve. We propose a novel model integrating an artificial fish swarm algorithm (AFSA) and CA for optimizing parameters of variables in the urban growth model and make a comparison between AFSA-CA and other five models, which is used to study a 40-year urban land growth of Wuhan. We found that the urban growth types from 1995 to 2015 appeared relatively consistent, mainly including infilling, edge-expansion and distant-leap types in Wuhan, which a certain range of urban land growth on the periphery of the central area. Additionally, although the genetic algorithms (GA)-CA model and the AFSA-CA model among the six models due to the distance variables, the parameter value of the GA-CA model is \u221215.5409 according to the fact that the population (POP) variable should be positively. As a result, the AFSA-CA model regardless of the initial parameter setting is superior to the GA-CA model and the GA-CA model is superior to all the other models. Finally, it is projected that the potentials of urban growth in Wuhan for 2025 and 2035 under three scenarios (natural urban land growth without any restrictions (NULG), sustainable urban land growth with cropland protection and ecological security (SULG), and economic urban land growth with sustainable development and economic development in the core area (EULG)) focus mainly on existing urban land and some new town centers based on AFSA-CA urban growth simulation model. An increasingly precise simulation can determine the potential increase area and quantity of urban land, providing a basis to judge the layout of urban land use for urban planners. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"An artificial fish swarm algorithm; Landscape indicators; Machine learning; Optimization; Scenario simulation; Sustainable urban development","Authors":"Huang X., Xu G., Xiao F.","DOI":"10.3390\/su13042338","x":11.64,"y":2.82},{"HDBSCAN_Cluster":0,"DocId":135,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Using satellite data to analyse raw material consumption in Hanoi, Vietnam","Abstract":"In this work, we provide an innovative route for analysing urban expansion and population growth and their link to the consumption of construction materials by combining satellite data with material consumption analysis within the Hanoi Province (Vietnam). Urban expansion is investigated with the use of landcover maps for the period 1975\u20132020 derived from satellite. During this period, artificial surfaces and agricultural areas have increased by 11.6% and 15.5%, re-spectively, while forests have decreased by 26.7%. We have used publicly available datasets to calculate and forecast the construction materials consumption and measure its statistical correla-tion with urban expansion between 2007 and 2018. Our results show that official figures for sand consumption are currently underestimated, and that by 2030, steel and sand and gravel consumption will increase even further by three and two times, respectively. Our analysis uses a new method to assess urban development and associated impacts by combining socio-economic and Earth Observation datasets. The analysis can provide evidence, underpin decision-making by au-thorities, policymakers, urban planners and sustainability experts, as well as support the development of informed strategies for resource consumption. It can also provide important information for identifying areas of land conservation and ecological greenways during urban planning. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Cloud computing; Construction materials; Land cover; Machine learning; Material consumption analysis","Authors":"Novellino A., Brown T.J., Bide T., Anh N.T.T., Petavratzi E., Kresse C.","DOI":"10.3390\/rs13030334","x":12.98,"y":3.36},{"HDBSCAN_Cluster":-1,"DocId":137,"Cited by":2.0,"Year":2021,"Document Type":"Article","Title":"Use of deep learning models in street-level images to classify one-story unreinforced masonry buildings based on roof diaphragms","Abstract":"In this paper, we explore the potential of convolutional neural networks to classify street-level imagery of one-story unreinforced masonry buildings (MURs) according to the flexibility of the roof diaphragm (rigid or flexible). This information is critical for vulnerability studies, disaster risk assessments, disaster management strategies, etc., and is of great relevance in cities where unreinforced masonry is the most common building typology or where the majority of the population resides in such buildings. Our contribution could be useful for local governments of cities in developing countries seeking to significantly reduce the number of deaths caused by disasters. Our research results indicate that VGG19 is the convolutional neural network architecture with the best performance, with an accuracy of 0.80, a precision of 0.88, and a recall of 0.84. The results are encouraging and could be used to reduce the amount of resources (both human and economic) for the development of detailed exposure models for unreinforced masonry buildings. \u00a9 2020 Elsevier Ltd","Author Keywords":"Convolutional neural networks; Deep learning; Diaphragm; Risk assessment; Seismic risk; Unreinforced masonry; Urban planning","Authors":"Rueda-Plata D., Gonz\u00e1lez D., Acevedo A.B., Duque J.C., Ramos-Poll\u00e1n R.","DOI":"10.1016\/j.buildenv.2020.107517","x":15.81,"y":6.47},{"HDBSCAN_Cluster":1,"DocId":141,"Cited by":10.0,"Year":2021,"Document Type":"Article","Title":"Deep learning-based multi-feature semantic segmentation in building extraction from images of UAV photogrammetry","Abstract":"Building information is an essential part of geographic information system (GIS) applications in urban planning and management. However, it changes rapidly with economic growth. Unmanned aerial vehicles (UAV)-based photogrammetry works well in this situation with its advantages of quick and high-resolution data updating. In this paper, in order to improve building extraction accuracy in complex areas where buildings are characterized by various patterns, complex structures, and unique styles, we present a framework which applies deep learning (DL) semantic segmentation to UAV images with digital surface model (DSM) and visible-band difference vegetation index (VDVI). The results show that extraction accuracy improves. The combination of red, green, blue (RGB) and VDVI bands (RGBVI) can effectively distinguish the building area and vegetation. The application of RGB with DSM bands (RGBD) helps separate buildings from ground objects. The combination of RGB, DSM, and VDVI bands (RGBDVI) can identify small buildings which are usually not high and covered partly by tree branches. The proposed method is further applied to an open standard dataset to evaluate its robustness and results indicate an increased overall accuracy from RGB only (93%) to RGBD (97%). \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Boonpook W., Tan Y., Xu B.","DOI":"10.1080\/01431161.2020.1788742","x":15.81,"y":5.94},{"HDBSCAN_Cluster":-1,"DocId":144,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Transfer Learning Models for Land Cover and Land Use Classification in Remote Sensing Image","Abstract":"Land Cover or Land Use (LCLU) classification is an important, challenging problem in remote sensing (RS) images. RS image classification is a recent technology used to extract hidden information from remotely sensed images in the observed earth environment. This classification is essential for sustainable development in agricultural decisions and urban planning using deep learning (DL) methods. DL gets more attention for accuracy and performance improvements in large datasets. This paper is aimed to apply one of the DL methods called transfer learning (TL). TL is the recent research problem in machine learning and DL approaches for image classification. DL consumes much time for training when starting from scratch. This problem could be overcome in the TL modeling technique, which uses pre-trained models to build deep TL models efficiently. We applied the TL model using bottleneck feature extraction from the pre-trained models: InceptionV3, Resnet50V2, and VGG19 to LCLU classification in the UC Merced dataset. With these experiments, the TL model has been built the outdate performance of 92.46, 94.38, and 99.64 in Resnet50V2, InceptionV3, and VGG19, respectively. \u00a9 2021 The Author(s). Published with license by Taylor & Francis Group, LLC.","Author Keywords":null,"Authors":"Alem A., Kumar S.","DOI":"10.1080\/08839514.2021.2014192","x":16.06,"y":4.5},{"HDBSCAN_Cluster":-1,"DocId":153,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Assessment of approaches for the extraction of building footprints from pl\u00e9iades images","Abstract":"The Marina area represents an official new gateway of entry to Egypt and the development of infrastructure is proceeding rapidly in this region. The objective of this research is to obtain building data by means of automated extraction from Pl\u00e9iades satellite images. This is due to the need for efficient mapping and updating of geodatabases for urban planning and touristic development. It compares the performance of random forest algorithm to other classifiers like maximum likelihood, support vector machines, and backpropagation neural networks over the well-organized buildings which appeared in the satellite images. Images were subsequently classified into two classes: buildings and non-buildings. In addition, basic morphological operations such as opening and closing were used to enhance the smoothness and connectedness of the classified imagery. The overall accuracy for random forest, maximum likelihood, support vector machines, and backpropagation were 97%, 95%, 93% and 92% respectively. It was found that random forest was the best option, followed by maximum likelihood, while the least effective was the backpropagation neural network. The completeness and correctness of the detected buildings were evaluated. Experiments confirmed that the four classification methods can effectively and accurately detect 100% of buildings from very high-resolution images. It is encouraged to use machine learning algorithms for object detection and extraction from very high-resolution images. \u00a9 2021 Author.","Author Keywords":"Backpropagation; Ensemble classifiers; Image classification; Machine learning; Maximum likelihood; Random forest; Support vector machines","Authors":"Taha L.G.E.-D., Ibrahim R.E.","DOI":"10.7494\/geom.2021.15.4.101","x":14.48,"y":5.6},{"HDBSCAN_Cluster":-1,"DocId":158,"Cited by":null,"Year":2021,"Document Type":"Conference Paper","Title":"Development of a Methodology for Complex Monitoring of the Development of Urban and Suburban Areas Based on the Intellectual Analysis of Earth Remote Sensing Data and Geospatial Technologies","Abstract":"Over the past half century, mankind is increasingly faced with the problems of rational use of the Earth\u2019s territories and its resources without negative impact on the environment and the person himself. The organization of human life activity requires solving the issues of urban planning and the correct distribution of zones for the construction of industrial facilities, recreation, waste disposal zones, communications, routes, etc. Balanced planning is based on monitoring the current state of infrastructure and territory. This article proposes a methodology for integrated monitoring of the development of urban and suburban areas. It is proposed to use Earth remote sensing data as a basis for the study. The issues of collection, integration and intelligent processing of satellite images are considered. The definition and segmentation of objects in images to create digital maps is performed based on machine learning algorithms. \u00a9 2021, Springer Nature Switzerland AG.","Author Keywords":"Area monitoring; Intelligent analysis; Machine learning; Remote sensing data; Urban area","Authors":"Malikov V., Sadovnikova N., Parygin D., Aleshkevich A., Savina O.","DOI":"10.1007\/978-3-030-87034-8_29","x":12.99,"y":3.76},{"HDBSCAN_Cluster":1,"DocId":161,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Scale-Robust Deep-Supervision Network for Mapping Building Footprints from High-Resolution Remote Sensing Images","Abstract":"Building footprint information is one of the key factors for sustainable urban planning and environmental monitoring. Mapping building footprints from remote sensing images is an important and challenging task in the earth observation field. Over the years, convolutional neural networks have shown outstanding improvements in the building extraction field due to their ability to automatically extract hierarchical features and make building predictions. However, as buildings are various in different sizes, scenes, and roofing materials, it is hard to precisely depict buildings of varied sizes, especially in large areas (e.g., nationwide). To tackle these limitations, we propose a novel deep-supervision convolutional neural network (denoted as DS-Net) for extracting building footprints from high-resolution remote sensing images. In the proposed network, we applied deep supervision with an extra lightweight encoder, which enables the network to learn representative building features of different scales. Furthermore, a scale attention module is designed to aggregate multiscale features and generate the final building prediction. Experiments on two publicly available building datasets, including the WHU Building Dataset and the Massachusetts Building Dataset, show the effectiveness of the proposed method. With only a 0.22-M increment of parameters compared with U-Net, the proposed DS-Net achieved an IoU of 90.4% on the WHU Building Dataset and 73.8% on the Massachusetts Dataset. DS-Net also outperforms the state-of-the-art building extraction methods on the two datasets, indicating the effectiveness of the proposed deep supervision and scale attention. \u00a9 2008-2012 IEEE.","Author Keywords":"Building footprint extraction; convolutional neural network; deep learning; remote sensing image","Authors":"Guo H., Su X., Tang S., Du B., Zhang L.","DOI":"10.1109\/JSTARS.2021.3109237","x":16.16,"y":6.36},{"HDBSCAN_Cluster":-1,"DocId":162,"Cited by":2.0,"Year":2021,"Document Type":"Article","Title":"Urban tree species classification using UAV-based multi-sensor data fusion and machine learning","Abstract":"Urban tree species classification is a challenging task due to spectral and spatial diversity within an urban environment. Unmanned aerial vehicle (UAV) platforms and small-sensor technology are rapidly evolving, presenting the opportunity for a comprehensive multi-sensor remote sensing approach for urban tree classification. The objectives of this paper were to develop a multi-sensor data fusion technique for urban tree species classification with limited training samples. To that end, UAV-based multispectral, hyperspectral, LiDAR, and thermal infrared imagery was collected over an urban study area to test the classification of 96 individual trees from seven species using a data fusion approach. Two supervised machine learning classifiers, Random Forest (RF) and Support Vector Machine (SVM), were investigated for their capacity to incorporate highly dimensional and diverse datasets from multiple sensors. When using hyperspectral-derived spectral features with RF, the fusion of all features extracted from all sensor types (spectral, LiDAR, thermal) achieved the highest overall classification accuracy (OA) of 83.3% and kappa of 0.80. Despite multispectral reflectance bands alone producing significantly lower OA of 55.2% compared to 70.2% with minimum noise fraction (MNF) transformed hyperspectral reflectance bands, the full dataset combination (spectral, LiDAR, thermal) with multispectral-derived spectral features achieved an OA of 81.3% and kappa of 0.77 using RF. Comparison of the features extracted from individual sensors for each species highlight the ability for each sensor to identify distinguishable characteristics between species to aid classification. The results demonstrate the potential for a high-resolution multi-sensor data fusion approach for classifying individual trees by species in a complex urban environment under limited sampling requirements. \u00a9 2021 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"Random Forest; Remote Sensing; Support Vector Machine; Tree Species Detection","Authors":"Hartling S., Sagan V., Maimaitijiang M.","DOI":"10.1080\/15481603.2021.1974275","x":14.56,"y":4.8},{"HDBSCAN_Cluster":1,"DocId":165,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Using 3-D Convolution and Multimodal Architecture for Earthquake Damage Detection Based on Satellite Imagery and Digital Urban Data","Abstract":"When a large earthquake occurs, it is quite important to quickly figure out the damage distribution of housing structures for disaster prevention measures. Currently, the information is confirmed manually by local public organizations, which takes a lot of time. Therefore, a method is required for gathering the information more swiftly and objectively. In this work, a novel method for detecting damage to single buildings from a set of multitemporal satellite images is developed by applying a recent machine learning approach. The damage detection system is designed as a deep learning model that uses multimodal data, consisting of optical satellite images and structural attributes. The proposed method achieved over 90% detection accuracy on damaged housing in the affected area of 2016 Kumamoto earthquake, Japan from satellite images taken by Pleiades as well as digital urban data. \u00a9 2008-2012 IEEE.","Author Keywords":"3-D convolution; earthquake damage detection; multimodal learning; satellite imagery; spatiotemporal data","Authors":"Miyamoto T., Yamamoto Y.","DOI":"10.1109\/JSTARS.2021.3102701","x":15.95,"y":6.38},{"HDBSCAN_Cluster":0,"DocId":167,"Cited by":null,"Year":2021,"Document Type":"Article","Title":"Detection of Urban Built-Up Area Change from Sentinel-2 Images Using Multiband Temporal Texture and One-Class Random Forest","Abstract":"Detection of urban land expansion is important for understanding the urbanization process and improving urban planning. Spatio-temporal contextual information derived from multitemporal high-resolution imagery is useful for highlighting urban land cover changes. This article proposes a new method for detecting urban built-up area change from multitemporal high spatial resolution imagery by combining spectral and spatio-temporal features. A multiband temporal texture measured using pseudo cross multivariate variogram (PCMV) is adopted to quantify the local spatio-temporal dependence between bitemporal multispectral images. The PCMV textures at multiple scales, bitemporal spectral features, and normalized difference vegetation indices are together input to an improved one-class random forest classifier for urban built-up area change mapping. The proposed method is evaluated in urban built-up area change detection using multitemporal Sentinel-2 images of Tianjin area acquired from 2015 to 2019. It is also compared with three feature combinations and an existing postclassification comparison method based on one-class support vector machine. Experimental results demonstrate that the proposed method outperformed the traditional ones, with increases of 2.15%-7.38%, 2.07%-5.45%, 1.93%-6.76%, and 5.98%-13.11% in overall accuracy. Moreover, the proposed method also achieves the best performance using the bitemporal Sentinel-2 images over the east of Beijing area. The proposed method is promising as a simple and reliable way to detect urban built-up area change with multitemporal Sentinel-2 imagery. \u00a9 2008-2012 IEEE.","Author Keywords":"Built-up area change; improved one-class random forest (iOCRF); multiband temporal texture; multitemporal data; pseudo cross multivariate variogram (PCMV)","Authors":"Feng X., Li P., Cheng T.","DOI":"10.1109\/JSTARS.2021.3092064","x":14.2,"y":4.14},{"HDBSCAN_Cluster":1,"DocId":169,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Satellite derived bathymetry using deep learning","Abstract":"Coastal development and urban planning are facing different issues including natural disasters and extreme storm events. The ability to track and forecast the evolution of the physical characteristics of coastal areas over time is an important factor in coastal development, risk mitigation and overall coastal zone management. Traditional bathymetry measurements are obtained using echo-sounding techniques which are considered expensive and not always possible due to various complexities. Remote sensing tools such as satellite imagery can be used to estimate bathymetry using incident wave signatures and inversion models such as physical models of waves. In this work, we present two novel approaches to bathymetry estimation using deep learning and we compare the two proposed methods in terms of accuracy, computational costs, and applicability to real data. We show that deep learning is capable of accurately estimating ocean depth in a variety of simulated cases which offers a new approach for bathymetry estimation and a novel application for deep learning. \u00a9 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.","Author Keywords":"Deep learning; Earth observation; Machine learning; Regression; Satellite-derived bathymetry","Authors":"Al Najar M., Thoumyre G., Bergsma E.W.J., Almar R., Benshila R., Wilson D.G.","DOI":"10.1007\/s10994-021-05977-w","x":16.06,"y":5.04},{"HDBSCAN_Cluster":0,"DocId":171,"Cited by":1.0,"Year":2021,"Document Type":"Book Chapter","Title":"Object-Oriented Approach for Urbanization Growth by Using Remote Sensing and GIS Techniques: A Case Study in Hilla City, Babylon Governorate, Iraq","Abstract":"High rate of urbanization coupled with population growth has led to unexpected land use and land cover changes in Hilla city, which is located in the Babylon governorate of Iraq. Understanding and quantifying the spatiotemporal dynamics of the urban land use and land cover changes, as well as the driving factors behind them, are therefore vital in order to design appropriate policies and monitoring mechanisms to govern urban growth. This study analyzes land use and land cover changes over Hilla city through remote sensing and GIS (Geographical Information System) techniques. IKONOS satellite imagery from years 2000, 2005, and 2011 was collected and pre-processed using ENVI and ArcGIS, which then goes through an object-based supervised image classification stage to generate land use and land cover maps. The classification is performed using the statistical machine learning algorithm, SVM (Support Vector Machine). The confusion matrix and kappa coefficients are used to evaluate the overall accuracy of the results. The statistical results obtained enable assessment of class changes from years 2000 to 2011 and also identify the gain and loss of the built-up areas in relation to other land cover classes. The results also allow assessment of the spatial trend of these built-up areas. Ultimately, forecasts can be made to predict expected future class changes in 2026 and 2036. Generally, the results of this study show increased expansions of built-up areas, i.e., from 8.14% in 2000 to 14.53% in 2005 and up to 18.36% in 2011. All this was at the expense of bare land areas. Simultaneously, there was an increased expansion of vegetation\/agricultural land area, specifically from 36.14% in 2000 to 41.71% in 2005 and 45.13% in 2011. The spatial trend also shows that the growth of built-up areas is focused in the southwestern part of Hilla city. In all, we foresee that the findings of this study can provide a good visual resource for decision-makers to perform more efficient urban planning. \u00a9 2021, Springer Nature Switzerland AG.","Author Keywords":"Built-up areas; Land use dynamics; Spatial trend; Support vector machine; Urbanization","Authors":"Mahmoud A.S., Kalantar B., Al-Najjar H.A.H., Moayedi H., Halin A.A., Mansor S.","DOI":"10.1007\/978-3-030-71945-6_3","x":13.32,"y":3.46},{"HDBSCAN_Cluster":0,"DocId":175,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Analysis of built-up areas of small polish cities with the use of deep learning and geographically weighted regression","Abstract":"Small cities are an important part of the settlement system, a link between rural areas and large cities. Although they perform important functions, research focuses on large cities and metropolises while marginalizing small cities, the study of which is of great importance to progress in social sciences, geography, and urban planning. The main goal of this paper was to verify the impact of selected socio-economic factors on the share of built-up areas in 665 small Polish cities in 2019. Data from the Database of Topographic Objects (BDOT), Sentinel-2 satellite imagery from 2015 and 2019, and Local Data Bank by Statistics Poland form 2019 were used in the research. A machine learning segmentation procedure was used to obtain the data on the occurrence of built-up areas. Hot Spot (Getis-Ord Gi*) analysis and geographically weighted regression (GWR) was applied to explain spatially varying impact of factors related to population, spatial and economic development, and living standards on the share of built-up areas in the area of small cities. Significant association was found between the population density and the share of built-up areas in the area of the cities studied. The influence of the other socio-economic factors examined, related to the spatial and economic development of the cities and the quality of life of the inhabitants, showed great regional variation. The results also indicated that the share of built-up areas in the area of the cities under study is a result of the conditions under which they were established and developed throughout their existence, and not only of the socio-economic factors affecting them at present. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Build-up areas; Deep learning; GWR; Hot Spot (Getis-Ord Gi*); Poland; Small cities","Authors":"Adamiak M., Ja\u017cd\u017cewska I., Nalej M.","DOI":"10.3390\/geosciences11050223","x":12.46,"y":3.72},{"HDBSCAN_Cluster":0,"DocId":182,"Cited by":2.0,"Year":2021,"Document Type":"Article","Title":"Analyzing the spatiotemporal uncertainty in urbanization predictions","Abstract":"With the availability of computational resources, geographical information systems, and remote sensing data, urban growth modeling has become a viable tool for predicting urbanization of cities and towns, regions, and nations around the world. This information allows policy makers, urban planners, environmental and civil organizations to make investments, design infrastructure, extend public utility networks, plan housing solutions, and mitigate adverse environmental impacts. Despite its importance, urban growth models often discard the spatiotemporal uncertainties in their prediction estimates. In this paper, we analyzed the uncertainty in the urban land predictions by comparing the outcomes of two different growth models, one based on a widely applied cellular automata model known as the SLEUTH CA and the other one based on a previously published machine learning framework. We selected these two models because they are complementary, the first is based on human knowledge and pre-defined and understandable policies while the second is more data-driven and might be less influenced by any a priori knowledge or bias. To test our methodology, we chose the cities of Jiaxing and Lishui in China because they are representative of new town planning policies and have different characteristics in terms of land extension, geographical conditions, growth rates, and economic drivers. We focused on the spatiotemporal uncertainty, understood as the inherent doubt in the predictions of where and when will a piece of land become urban, using the concepts of certainty area in space and certainty area in time. The proposed analyses in this paper aim to contribute to better urban planning exercises, and they can be extended to other cities worldwide. \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Machine learning; SLEUTH CA; Spatiotemporal uncertainty; Urban growth; Urban planning tools; Urban science; Urbanization processes","Authors":"G\u00f3mez J.A., Guan C., Tripathy P., Duque J.C., Passos S., Keith M., Liu J.","DOI":"10.3390\/rs13030512","x":11.68,"y":3.03},{"HDBSCAN_Cluster":1,"DocId":183,"Cited by":4.0,"Year":2021,"Document Type":"Article","Title":"UVid-Net: Enhanced Semantic Segmentation of UAV Aerial Videos by Embedding Temporal Information","Abstract":"Semantic segmentation of aerial videos has been extensively used for decision making in monitoring environmental changes, urban planning, and disaster management. The reliability of these decision support systems is dependent on the accuracy of the video semantic segmentation algorithms. The existing CNN-based video semantic segmentation methods have enhanced the image semantic segmentation methods by incorporating an additional module such as LSTM or optical flow for computing temporal dynamics of the video which is a computational overhead. The proposed research work modifies the CNN architecture by incorporating temporal information to improve the efficiency of video semantic segmentation. In this work, an enhanced encoder-decoder based CNN architecture (UVid-Net) is proposed for unmanned aerial vehicle (UAV) video semantic segmentation. The encoder of the proposed architecture embeds temporal information for temporally consistent labeling. The decoder is enhanced by introducing the feature-refiner module, which aids in accurate localization of the class labels. The proposed UVid-Net architecture for UAV video semantic segmentation is quantitatively evaluated on extended ManipalUAVid dataset. The performance metric mean Intersection over Union of 0.79 has been observed which is significantly greater than the other state-of-the-art algorithms. Further, the proposed work produced promising results even for the pretrained model of UVid-Net on urban street scene by fine tuning the final layer on UAV aerial videos. \u00a9 2008-2012 IEEE.","Author Keywords":"Deep learning; semantic segmentation; transfer learning; U-Net; unmanned aerial vehicle (UAV) video","Authors":"Girisha S., Verma U., Manohara Pai M.M., Pai R.M.","DOI":"10.1109\/JSTARS.2021.3069909","x":15.78,"y":5.46},{"HDBSCAN_Cluster":-1,"DocId":186,"Cited by":3.0,"Year":2021,"Document Type":"Article","Title":"Estimating Socio-Economic Parameters via Machine Learning Methods Using Luojia1-01 Nighttime Light Remotely Sensed Images at Multiple Scales of China in 2018","Abstract":"Mapping socio-economic indicators with a raster format is still a great challenge. The nighttime light (NTL) datasets have been widely utilized to estimate the socio-economic parameters. However, the precision of the published datasets was too coarse to meet related issues such as flood losses assessment, urban planning, and epidemiological studies. The present study calibrated gross domestic product (GDP), population (POP), electric consumption (EC), and urban build-up area (B-A) at 100 m resolution for 45 cities of China in 2018 using Luojia1-01 NTL datasets via random forest (RF) as well as geographically weighted regression (GWR) model. The linear regression (LR), back propagation neural network (BPNN), and support vector machine (SVM) methods were selected for comparison with GWR and RF models. Besides, the Suomi National Polar-Orbiting Partnership-Visible Infrared Imaging Radiometer Suite (NPP-VIIRS) was chosen for comparison with Luojia1-01. The ten-folded cross-validation (CV) has been used for evaluating accuracy at county and city scales. Finally, the distribution maps of socio-economic parameters were illustrated and some findings were obtained. First, the validation results revealed that the calibration at the city-scale outperformed the county or district scale. Second, the precision of the Luojia1-01 NTL dataset surpassed the NPP-VIIRS NTL dataset on the same administrative scale except for some specific situations. Third, the precision of the simulation for the gross domestic product (GDP) is the highest than the others, followed by electric consumption (EC), build-up area (B-A), and population (POP). Fourth, the optimum model varied according to the socio-economic parameters. Fifth, the distribution of socio-economic parameters exhibited obvious spatial heterogeneity. This paper can supply scientific support for calibrating socio-economic parameters in other regions. \u00a9 2013 IEEE.","Author Keywords":"China; GWR; Luojia1-01; machine learning; multiple scales; NPP\/VIIRS; socio-economic parameters","Authors":"Guo B., Bian Y., Zhang D., Su Y., Wang X., Zhang B., Wang Y., Chen Q., Wu Y., Luo P.","DOI":"10.1109\/ACCESS.2021.3059865","x":12.79,"y":4.18},{"HDBSCAN_Cluster":1,"DocId":188,"Cited by":11.0,"Year":2021,"Document Type":"Article","Title":"Attention-Gate-Based Encoder-Decoder Network for Automatical Building Extraction","Abstract":"Rapidly developing remote sensing technology provides massive data for urban planning, mapping, and disaster management. As a carrier of human productive activities, buildings are essential to both urban dynamic monitoring and suburban construction inspection. Fully-convolutional-network-based methods have provided a paradigm for automatically extracting buildings from high-resolution imagery. However, high intraclass variance and complexity are two problems in building extraction. It is hard to identify different scales of buildings by using a single receptive field. For this purpose, in this article, we use the stable encoder- decoder architecture, combined with a grid-based attention gate and atrous spatial pyramid pooling module, to capture and restore features progressively and effectively. A modified ResNet50 encoder is also applied to extract features. The proposed method could learn gated features and distinguish buildings from complex surroundings such as trees. We evaluate our model on two building datasets, WHU aerial building dataset and our DB UAV rural building dataset. Experiments show that our model outperforms other five most recent models. The results also exhibit great potential for extracting buildings with different scales and validate the effectiveness of deep learning in practical scenarios. \u00a9 2008-2012 IEEE.","Author Keywords":"Attention gate (AG); building extraction; deep learning; fully convolutional networks (FCNs); semantic segmentation","Authors":"Deng W., Shi Q., Li J.","DOI":"10.1109\/JSTARS.2021.3058097","x":16.04,"y":6.12},{"HDBSCAN_Cluster":0,"DocId":190,"Cited by":4.0,"Year":2021,"Document Type":"Article","Title":"Urban Water Demand Modeling Using Machine Learning Techniques: Case Study of Fortaleza, Brazil","Abstract":"Despite recent efforts to apply machine learning (ML) for water demand modeling, overcoming the black-box nature of these techniques to extract practical information remains a challenge, especially in developing countries. This study integrated random forest (RF), self-organizing map (SOM), and artificial neural network (ANN) techniques to assess water demand patterns and to develop a predictive model for the city of Fortaleza, Brazil. We performed the analysis at two spatial scales, with different level of information: census tracts (CTs) at the fine scale, and census blocks (CBs) at the coarse scale. At the CB scale, demand was modeled with socioeconomic, demographic, and household characteristics. The RF technique was applied to rank these variables, and the most relevant were used to cluster census blocks with SOMs. RFs and ANNs were used in an iterative approach to define the input variables for the predictive model with minimum redundancy. At the CT scale, demand was modeled using HDI and per capita income. Variables which assess the education level and economic aspects of households demonstrated a direct relationship with water demand. The analysis at the coarse scale provided more insight into the relationship between the variables; however, the predictive model performed better at the fine scale. This study demonstrates how data-driven models can be helpful for water management, especially in environments with strong socioeconomic inequalities, where urban planning decisions should be integrated and inclusive. \u00a9 2020 American Society of Civil Engineers.","Author Keywords":null,"Authors":"Carvalho T.M.N., De Souza Filho F.D.A., Porto V.C.","DOI":"10.1061\/(ASCE)WR.1943-5452.0001310","x":12.56,"y":2.56},{"HDBSCAN_Cluster":-1,"DocId":193,"Cited by":1.0,"Year":2021,"Document Type":"Article","Title":"Synthesizing location semantics from street view images to improve urban land-use classification","Abstract":"Land-use maps are instrumental to inform urban planning and environmental research. Street view images (SVIs) have shown great potential for automated land-use classification for land-use mapping. However, previous studies overlooked SVI-derived location contextual information that may help improve land-use classification. This study proposes a novel land-use classification method that synthesizes location semantics from SVIs to account for contextual information from SVIs, land parcels and roads around the SVIs. The proposed method first generates land-use scene images (LUSIs) by using an SVI-derived straightforward algorithm. The LUSIs are then relocated to land parcels by using a displacement strategy and classified into land-use types by using a deep learning network. This study determines the land-use types of land parcels with classified LUSIs. Two case studies, consisting of LUSIs for five land-use types, show that introducing location semantics of SVIs can remarkably improve the classification accuracy of land-use types. \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"land-use classification; Land-use map; location semantics; street view image","Authors":"Fang F., Yu Y., Li S., Zuo Z., Liu Y., Wan B., Luo Z.","DOI":"10.1080\/13658816.2020.1831515","x":15.43,"y":4.95},{"HDBSCAN_Cluster":0,"DocId":208,"Cited by":7.0,"Year":2020,"Document Type":"Article","Title":"Assessing urban growth in Ghana using machine learning and intensity analysis: A case study of the New Juaben Municipality","Abstract":"Population growth coupled with economic, housing and environmental factors have significantly contributed into accelerated land use change in the New Juaben Municipality of Ghana. These factors have caused destruction of natural habitat and increased natural hazards such as flooding in the Municipality. Monitoring land use\/land cover change is essential in respect to the dynamics of both human and natural factors that affect the biophysical and biochemical properties of the land surface. This research investigates the transitions among the major land use\/land cover categories in the Municipality as a highly populated urban region that is facing some environmental challenges such as deforestation and degradation of the environment. Random Forest was adopted for the classification of 1985, 1991, 2002 and 2015 land cover maps while the analysis of the dynamics was conducted using intensity analysis. The unique contribution of this article is the combine usage of machine learning algorithm and intensity analysis to assess the changes in land use\/land cover. The results showed that 1985\u20131991 and 2002\u20132015 periods experience fast change and the land use transformation has been accelerating over the whole period. The major changes were caused by the Built-up and Agricultural activities constituting 21.24 % and 13.19 % respectively in the category level. It is recommended that, authorities should consider several structural transformation measures within Ghana, including inter-sectoral land use harmonization policies (e.g. the Land Use and Spatial Planning Act 2016), land use planning and legal reforms to help address the underlying drivers of urban led deforestation. \u00a9 2020 Elsevier Ltd","Author Keywords":"Ghana; Intensity analysis; Random forest classification; UN sustainable development goals; Urbanization","Authors":"Nyamekye C., Kwofie S., Ghansah B., Agyapong E., Boamah L.A.","DOI":"10.1016\/j.landusepol.2020.105057","x":13.19,"y":3.15},{"HDBSCAN_Cluster":-1,"DocId":212,"Cited by":2.0,"Year":2020,"Document Type":"Article","Title":"Urban population distribution mapping with multisource geospatial data based on zonal strategy","Abstract":"Mapping population distribution at fine resolutions with high accuracy is crucial to urban planning and management. This paper takes Guangzhou city as the study area, illustrates the gridded population distribution map by using machine learning methods based on zoning strategy with multisource geospatial data such as night light remote sensing data, point of interest data, land use data, and so on. The street-level accuracy evaluation results show that the proposed approach achieved good overall accuracy, with determinant coefficient (R2) being 0.713 and root mean square error (RMSE) being 5512.9. Meanwhile, the goodness of fit for single linear regression (LR) model and random forest (RF) regression model are 0.0039 and 0.605, respectively. For dense area, the accuracy of the random forest model is better than the linear regression model, while for sparse area, the accuracy of the linear regression model is better than the random forest model. The results indicated that the proposed method has great potential in fine-scale population mapping. Therefore, it is advised that the zonal modeling strategy should be the primary choice for solving regional differences in the population distribution mapping research. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Guangzhou; Point of interest; Population mapping; Random forest; Zonal model","Authors":"Zhao G., Yang M.","DOI":"10.3390\/ijgi9110654","x":12.53,"y":3.95},{"HDBSCAN_Cluster":0,"DocId":213,"Cited by":1.0,"Year":2020,"Document Type":"Article","Title":"Analysing urban development patterns in a conflict zone: A case study of kabul","Abstract":"A large part of the population in low-income countries (LICs) lives in fragile and conflict-affected states. Many cities in these states show high growth dynamics, but little is known about the relation of conflicts and urban growth. In Afghanistan, the Taliban regime, which lasted from 1996 to 2001, caused large scale displacement of the population. People from Afghanistan migrated to neighboring countries like Iran and Pakistan, and all developments came to a halt. After the US invasion in October 2001, all the major cities in Afghanistan experienced significant population growth, in particular, driven by the influx of internally displaced persons. Maximum pressure of this influx was felt by the capital city, Kabul. This rapid urbanization, combined with very limited capacity of local authorities to deal with this growth, led to unplanned urbanization and challenges for urban planning and management. This study analyses the patterns of growth between 2001 and 2017, and the factors influencing the growth in the city of Kabul with the help of high-resolution Earth Observation-based data (EO) and spatial logistic regression modelling. We analyze settlement patterns by extracting image features from high-resolution images (aerial photographs of 2017) and terrain features as input to a random forest classifier. The urban growth is analyzed using an available built-up map (extracted from IKONOS images for the year 2001). Results indicate that unplanned settlements have grown 4.5 times during this period, whereas planned settlements have grown only 1.25 times. The unplanned settlements expanded mostly towards the west and north west parts of the city, and the growth of planned settlements happened mainly in the central and eastern parts of the city. Population density and the locations of military bases are the most important factors that influence the growth, of both planned and unplanned settlements. The growth of unplanned settlement occurs predominantly in areas of steeper slopes on the hillside, while planned settlements are on gentle slopes and closer to the institutional areas (central and eastern parts of the city). We conclude that security and availability of infrastructure were the main drivers of growth for planned settlements, whereas unplanned growth, mainly on hillsides, was driven by the availability of land with poor infrastructure. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Author Keywords":"Conflict; GLCM; Informal areas; Machine learning; Random forest classification; Spatial logistic regression; Unplanned areas; Urban growth; Urban growth model","Authors":"Chaturvedi V., Kuffer M., Kohli D.","DOI":"10.3390\/rs12213662","x":12.74,"y":3.61},{"HDBSCAN_Cluster":0,"DocId":225,"Cited by":14.0,"Year":2020,"Document Type":"Article","Title":"Improving land-use change modeling by integrating ANN with Cellular Automata-Markov Chain model","Abstract":"Urban growth and land-use change are a few of many puzzling factors affecting our future cities. Creating a precise simulation for future land change is a challenging process that requires temporal and spatial modeling. Many recent studies developed and trained models to predict urban expansion patterns using Artificial Intelligence (AI). This study aims to enhance the simulation capability of Cellular Automata Markov Chain (CA-MC) model in predicting changes in land-use. This study integrates the Artificial Neural Network (ANN) into CA-MC to incorporate several driving forces that highly impact land-use change. The research utilizes different socio-economic, spatial, and environmental variables (slope, distance to road, distance to urban centers, distance to commercial, density, elevation, and land fertility) to generate potential transition maps using ANN Data-driven model. The generated maps are fed to CA-MC as additional inputs. We calibrated the original CA-MC and our models for 2015 cross-comparing simulated maps and actual maps obtained for Irbid city, Jordan in 2015. Validation of our model was assessed and compared to the CA-MC model using Kappa indices including the agreement in terms of quantity and location. The results elucidated that our model with an accuracy of 90.04% substantially outperforms CA-MC (86.29%) model. The improvement we obtained from integrating ANN with CA-MC suggested that the influence imposed by the driving force was necessary to be taken into account for more accurate prediction. In addition to the improved model prediction, the predicted maps of Irbid for the years 2021 and 2027 will guide local authorities in the development of management strategies that balance urban expansion and protect agricultural regions. This will play a vital role in sustaining Jordan's food security. \u00a9 2020Environmental science, Computer science, Geography, Land use planning, Land use change, Urban growth, Machine learning, Urban planning, Modeling; Artificial intelligence, Cellular Automata, Markov Chain. \u00a9 2020","Author Keywords":"Artificial intelligence; Cellular Automata; Computer science; Environmental science; Geography; Land use change; Land use planning; Machine learning; Markov Chain; Modeling; Urban growth; Urban planning","Authors":"Gharaibeh A., Shaamala A., Obeidat R., Al-Kofahi S.","DOI":"10.1016\/j.heliyon.2020.e05092","x":11.54,"y":2.72},{"HDBSCAN_Cluster":1,"DocId":226,"Cited by":4.0,"Year":2020,"Document Type":"Article","Title":"Precise object detection using adversarially augmented local\/global feature fusion","Abstract":"Object detection, which aims at recognizing or locating the objects of interest in remote sensing imagery with high spatial resolutions (HSR), plays a significant role in many real-world scenarios, e.g., environment monitoring, urban planning, civil infrastructure construction, disaster rescuing, and geographic image retrieval. As a long-lasting challenging problem in both machine learning and geoinformatics communities, many approaches have been proposed to tackle it. However, previous methods always overlook the abundant information embedded in the HSR remote sensing images. The effectiveness of these methods, e.g., accuracy of detection, is therefore limited to some extent. To overcome the mentioned challenge, in this paper, we propose a novel two-phase deep framework, dubbed GLGOD-Net, to effectively detect meaningful objects in HSR images. GLGOD-Net firstly attempts to learn the enhanced deep representations from super-resolution image data. Fully utilizing the augmented image representations, GLGOD-Net then learns the fused representations into which both local and global latent features are implanted. Such fused representations learned by GLGOD-Net can be used to precisely detect different objects in remote sensing images. The proposed framework has been extensively tested on a real-world HSR image dataset for object detection and has been compared with several strong baselines. The remarkable experimental results validate the effectiveness of GLGOD-Net. The success of GLGOD-Net not only advances the cutting-edge of image data analytics, but also promotes the corresponding applicability of deep learning in remote sensing imagery. \u00a9 2020","Author Keywords":"Data augmentation; Geospatial object detection; High spatial resolution (HSR) remote sensing imagery; Local\/global feature fusion; Super resolution generative adversarial network","Authors":"Han X., He T., Ong Y.-S., Zhong Y.","DOI":"10.1016\/j.engappai.2020.103710","x":16.33,"y":5.19},{"HDBSCAN_Cluster":0,"DocId":230,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"On the development of a novel approach for identifying perennial drainage in Southern Brazil: A study case integrating sentinel-2 and high-resolution digital elevation models with machine learning techniques","Abstract":"Riparian vegetation plays a key role in maintaining water quality and preserving the ecosystems along riverine systems, as they prevent soil erosion, retain water by increased infiltration, and act as a buffer zone between rivers and their surroundings. Within urban spaces, these areas have also an important role in preventing illegal occupation in areas of hydrologic risk, such as in floodplains. The goal of this research is to propose a framework for identifying areas of permanent protection associated with perennial drainage, utilizing satellite imagery and digital elevation models (DEM) in association with machine learning techniques. The specific objectives include the development of a decision tree to retrieve perennial drainage over high resolution, 1-meter DEM's, and the development of digital image processing workflow to retrieve surface water bodies from Sentinel-2 imagery. In-situ information on perennial and ephemeral conditions of streams and rivers were obtained to validate our results, that happened in the first trimester of 2020. We propose a minimum of 7 days without precipitation prior to in-situ validation, for more accurate assessment of streamflow conditions, in order to minimize impacts of surface water runoff in flow regime. The proposed method will benefit decision makers by providing them with reliable information on drainage network and their buffer zones, as well as yield detailed mapping of the areas of permanent protection that are key to urban planning and management. \u00a9 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.","Author Keywords":"Digital Elevation Models; Machine Learning; Perennial Drainage; Riparian Vegetation; Sentinel-2","Authors":"Montibeller A., Vilela M., Hino F., Mallmann P., Nadas M., Caruso F., Delabary H.","DOI":"10.5194\/isprs-archives-XLIII-B3-2020-161-2020","x":14.36,"y":3.14},{"HDBSCAN_Cluster":-1,"DocId":231,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"A NOVEL SELF-TAUGHT LEARNING FRAMEWORK USING SPATIAL PYRAMID MATCHING for SCENE CLASSIFICATION","Abstract":"Remote sensing earth observation images have a wide range of applications in areas like urban planning, agriculture, environment monitoring, etc. While the industrial world benefits from availability of high resolution earth observation images since recent years, interpreting such images has become more challenging than ever. Among many machine learning based methods that have worked out successfully in remote sensing scene classification, spatial pyramid matching using sparse coding (ScSPM) is a classical model that has achieved promising classification accuracy on many benchmark data sets. ScSPM is a three-stage algorithm, composed of dictionary learning, sparse representation and classification. It is generally believed that in the dictionary learning stage, although unsupervised, one should use the same data set as classification stage to get good results. However, recent studies in transfer learning suggest that it might be a better strategy to train the dictionary on a larger data set different from the one to classify. In our work, we propose an algorithm that combines ScSPM with self-taught learning, a transfer learning framework that trains a dictionary on an unlabeled data set and uses it for multiple classification tasks. In the experiments, we learn the dictionary on Caltech-101 data set, and classify two remote sensing scene image data sets: UC Merced LandUse data set and Changping data set. Experimental results show that the classification accuracy of proposed method is compatible to that of ScSPM. Our work thus provides a new way to reduce resource cost in learning a remote sensing scene image classifier. \u00a9 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.","Author Keywords":"High Resolution Imagery; Remote Sensing; Scene Classification; Self-taught Learning; Spatial Pyramid Matching","Authors":"Yang Y., Zhu D., Ren F., Cheng C.","DOI":"10.5194\/isprs-archives-XLIII-B2-2020-725-2020","x":16.1,"y":4.54},{"HDBSCAN_Cluster":1,"DocId":234,"Cited by":6.0,"Year":2020,"Document Type":"Article","Title":"A generalized multi-task learning approach to stereo DSM filtering in urban areas","Abstract":"City models and height maps of urban areas serve as a valuable data source for numerous applications, such as disaster management or city planning. While this information is not globally available, it can be substituted by digital surface models (DSMs), automatically produced from inexpensive satellite imagery. However, stereo DSMs often suffer from noise and blur. Furthermore, they are heavily distorted by vegetation, which is of lesser relevance for most applications. Such basic models can be filtered by convolutional neural networks (CNNs), trained on labels derived from digital elevation models (DEMs) and 3D city models, in order to obtain a refined DSM. We propose a modular multi-task learning concept that consolidates existing approaches into a generalized framework. Our encoder-decoder models with shared encoders and multiple task-specific decoders leverage roof type classification as a secondary task and multiple objectives including a conditional adversarial term. The contributing single-objective losses are automatically weighted in the final multi-task loss function based on learned uncertainty estimates. We evaluated the performance of specific instances of this family of network architectures. Our method consistently outperforms the state of the art on common data, both quantitatively and qualitatively, and generalizes well to a new dataset of an independent study area. \u00a9 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"3D city models; Deep learning; Multi-task learning; Roof type segmentation; Stereo DSM filtering","Authors":"Liebel L., Bittner K., K\u00f6rner M.","DOI":"10.1016\/j.isprsjprs.2020.03.005","x":16.08,"y":5.7},{"HDBSCAN_Cluster":-1,"DocId":236,"Cited by":12.0,"Year":2020,"Document Type":"Article","Title":"A robust segmentation framework for closely packed buildings from airborne LiDAR point clouds","Abstract":"Urban villages (UVs) are commonly found in many Asian cities. These villages contain many closely packed buildings constructed decades ago without proper urban planning. There is a need for those buildings to be identified and put into statistics. In this paper, we present a segmentation framework that invokes multiple machine learning techniques and point cloud\/image processing algorithms to segment individual closely packed buildings from large urban scenes. The presented framework consists of two major segmentation processes. The framework first filters out the non-ground objects from the point cloud, then it classified them by using the Random Forest classifier to isolate buildings from the entire scene. After that, the building point clouds will be segmented based on several building attribute analysis methods. This is followed by using the Random Sample Consensus (RANSAC) plane filtering method to expand the space between two closely packed buildings, so that the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering technique can be used to more accurately segment each individual building from the closely packed building areas. Two airborne Light Detection and Ranging (LiDAR) datasets collected in two different cities with some typical closely packed buildings were used to verify the proposed framework. The results show that the framework can effectively identify the closely packed buildings with unified structures from large airborne LiDAR datasets. The overall segmentation accuracy reaches 84% for the two datasets. The proposed framework can serve as a basis for analysis and segmentation of closely packed buildings with a more complicated structure. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Wang X., Chan T.O., Liu K., Pan J., Luo M., Li W., Wei C.","DOI":"10.1080\/01431161.2020.1727053","x":14.6,"y":6.07},{"HDBSCAN_Cluster":1,"DocId":237,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"Object detection of aerial image using mask-region convolutional neural network (mask R-CNN)","Abstract":"The most fundamental task in remote sensing data processing and analysis is object detection. It plays an important role in classification and very useful for various applications such as forestry, urban planning, agriculture, land use and land cover mapping, etc. However, it has many challenges to find an appropriate method due to many variations in the appearance of the object in image. The object may have occlusion, illumination, viewpoint variation, shadow, etc. Many object detection method has been researched and developed. Recently, the development of various machine learning-based methods for object detection has been increasing. Among of them are methods based on artificial neural network, deep learning and its derivatives. In this research, object detection method of aerial image by using mask-region convolutional neural network (mask-R CNN) is developed. The result shows that this method gives a significant accuracy by increasing the image training and epoch time. \u00a9 2020 IOP Publishing Ltd. All rights reserved.","Author Keywords":null,"Authors":"Musyarofah, Schmidt V., Kada M.","DOI":"10.1088\/1755-1315\/500\/1\/012090","x":15.92,"y":5.23},{"HDBSCAN_Cluster":0,"DocId":245,"Cited by":17.0,"Year":2020,"Document Type":"Article","Title":"Coupling cellular automata with area partitioning and spatiotemporal convolution for dynamic land use change simulation","Abstract":"Urbanization processes have accelerated over recent decades, prompting efforts to model land use change (LUC) patterns for decision support and urban planning. Cellular automata (CA) are extensively employed given their simplicity, flexibility, and intuitiveness when simulating dynamic LUC. Previous research, however, has ignored the spatial heterogeneity among sub-regions, instead applying the same transition rules across entire regions; moreover, most existing methods extract neighborhood effects with only one data time slice, which is inconsistent with the nature of neighborhood interactions as a long-term process exhibiting obvious spatiotemporal dependency. Accordingly, we propose a hybrid cellular automata model coupling area partitioning and spatiotemporal neighborhood features learning, named PST-CA. We use a machine-learning-based partitioning strategy, self-organizing map (SOM), to divide entire regions into several homogeneous sub-regions, and further apply a spatiotemporal three-dimensional convolutional neural network (3D CNN) to extract the spatiotemporal neighborhood features. An artificial neural network (ANN) is then built to create a conversion probability map for each sub-region using both spatiotemporal neighborhood features and factors that drive the LUC. Finally, the dynamic simulation results of entire study area are generated by fusing these probability maps, constraints and stochastic factors. Land use data collected from 2000 to 2015 in Shanghai were selected to verify our proposed method. Four traditional models were implemented for comparison, including logistic regression (LR)-CA, support vector machine (SVM)-CA, random forest (RF)-CA and conventional ANN-CA. Results illustrate that the proposed PST-CA outperformed four traditional models, with overall accuracy increased by 4.66%~6.41%. Moreover, three distinctly different \u201ccoverage rate-growth rate\u201d composite patterns of built-up areas are shown in the SOM partitioning results, which verifies SOM's ability to address spatial heterogeneity; while the optimal time steps in 3D CNN generally maintained a positive correlation with the growth rate of built-up areas, which implies longer temporal dependency should be captured for rapidly developing areas. \u00a9 2020 Elsevier B.V.","Author Keywords":"Cellular automata; Land use; Neighborhood effects; Spatial heterogeneity; Spatiotemporal features","Authors":"Qian Y., Xing W., Guan X., Yang T., Wu H.","DOI":"10.1016\/j.scitotenv.2020.137738","x":11.62,"y":2.64},{"HDBSCAN_Cluster":0,"DocId":251,"Cited by":7.0,"Year":2020,"Document Type":"Article","Title":"Population spatialization in Beijing city based on machine learning and multisource remote sensing data","Abstract":"Remote sensing data have been widely used in research on population spatialization. Previous studies have generally divided study areas into several sub-areas with similar features by artificial or clustering algorithms and then developed models for these sub-areas separately using statistical methods. These approaches have drawbacks due to their subjectivity and uncertainty. In this paper, we present a study of population spatialization in Beijing City, China based on multisource remote sensing data and town-level population census data. Six predictive algorithms were compared for estimating population using the spatial variables derived from The National Polar-Orbiting Partnership\/ Visible Infrared Imaging Radiometer Suite (NPP\/VIIRS) night-time light and other remote sensing data. Random forest achieved the highest accuracy and therefore was employed for population spatialization. Feature selection was performed to determine the optimal variable combinations for population modeling by random forest. Cross-validation results indicated that the developed model achieved a mean absolute error (MAE) of 2129.52 people\/km2 and a R2 of 0.63. The gridded population density in Beijing at a spatial resolution of 500 m produced by the random forest model was also adjusted to be consistent with the census population at the town scale. By comparison with Google Earth high-resolution images, the remotely-sensed population was qualitatively validated at the intra-town scale. Validation results indicated that remotely sensed results can effectively depict the spatial distribution of population within town-level districts. This study provides a valuable reference for urban planning, public health and disaster prevention in Beijing, and a reference for population mapping in other cities. \u00a9 2020 by the authors.","Author Keywords":"Beijing; Population spatialization; Random forest; Remote sensing","Authors":"He M., Xu Y., Li N.","DOI":"10.3390\/rs12121910","x":12.69,"y":4.01},{"HDBSCAN_Cluster":-1,"DocId":252,"Cited by":22.0,"Year":2020,"Document Type":"Article","Title":"Comparative assessment of machine learning methods for urban vegetation mapping using multitemporal Sentinel-1 imagery","Abstract":"Mapping of green vegetation in urban areas using remote sensing techniques can be used as a tool for integrated spatial planning to deal with urban challenges. In this context, multitemporal (MT) synthetic aperture radar (SAR) data have not been equally investigated, as compared to optical satellite data. This research compared various machine learning methods using single-date and MT Sentinel-1 (S1) imagery. The research was focused on vegetation mapping in urban areas across Europe. Urban vegetation was classified using six classifiers-random forests (RF), support vector machine (SVM), extreme gradient boosting (XGB), multi-layer perceptron (MLP), AdaBoost. M1 (AB), and extreme learning machine (ELM). Whereas, SVM showed the best performance in the single-date image analysis, the MLP classifier yielded the highest overall accuracy in the MT classification scenario. Mean overall accuracy (OA) values for all machine learning methods increased from 57% to 77% with speckle filtering. Using MT SAR data, i.e., three and five S1 imagery, an additional increase in the OA of 8.59% and 13.66% occurred, respectively. Additionally, using three and five S1 imagery for classification, the F1 measure for forest and low vegetation land-cover class exceeded 90%. This research allowed us to confirm the possibility of MT C-band SAR imagery for urban vegetation mapping. \u00a9 2020 by the authors.","Author Keywords":"Land-cover classification; Multitemporal; Sentinel-1; Speckle filtering; Synthetic aperture radar (SAR); Urban vegetation","Authors":"Ga\u0161parovi\u0107 M., Dobrini\u0107 D.","DOI":"10.3390\/rs12121952","x":14.68,"y":3.85},{"HDBSCAN_Cluster":1,"DocId":254,"Cited by":28.0,"Year":2020,"Document Type":"Article","Title":"Local climate zone mapping as remote sensing scene classification using deep learning: A case study of metropolitan China","Abstract":"China, with the world's largest population, has gone through rapid development in the last forty years and now has over 800 million urban citizens. Although urbanization leads to great social and economic progress, they may be confronted with other issues, including extra heat and air pollution. Local climate zone (LCZ), a new concept developed for urban heat island research, provides a standard classification system for the urban environment. LCZs are defined by the context of the urban environment; the minimum diameter of an LCZ is expected to be 400\u20131,000 m so that it can have a valid effect on the urban climate. However, most existing methods (e.g., the WUDAPT method) regard this task as pixel-based classification, neglecting the spatial information. In this study, we argue that LCZ mapping should be considered as a scene classification task to fully exploit the environmental context. Fifteen cities covering 138 million population in three economic regions of China are selected as the study area. Sentinel-2 multispectral data with a 10 m spatial resolution are used to classify LCZs. A deep convolutional neural network composed of residual learning and the Squeeze-and-Excitation block, namely the LCZNet, is proposed. We obtained an overall accuracy of 88.61% by using a large image (48\u00d748 corresponding to 480\u00d7480 m2) as the representation of an LCZ, 7.5% higher than that using a small image representation (10\u00d710) and nearly 20% higher than that obtained by the standard WUDAPT method. Image sizes from 32\u00d732 to 64\u00d764 were found suitable for LCZ mapping, while a deeper network achieved better classification with larger inputs. Compared with natural classes, urban classes benefited more from a large input size, as it can exploit the environment context of urban areas. The combined use of the training data from all three regions led to the best classification, but the transfer of LCZ models cannot achieve satisfactory results due to the domain shift. More advanced domain adaptation methods should be applied in this application. \u00a9 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"Convolutional neural network; Local climate zone; Metropolitan China; Scene classification; Urban climate","Authors":"Liu S., Shi Q.","DOI":"10.1016\/j.isprsjprs.2020.04.008","x":15.73,"y":4.93},{"HDBSCAN_Cluster":0,"DocId":256,"Cited by":13.0,"Year":2020,"Document Type":"Article","Title":"An agent-based learning-embedded model (ABM-learning) for urban land use planning: A case study of residential land growth simulation in Shenzhen, China","Abstract":"A forward-looking urban land use plan is crucial to a city's sustainability, which requires a deep understanding of human-environment interactions between different domains, and modelling them soundly. One of the key challenges of modelling these interactions is to understand and model how human individuals make and develop their location decisions by learning that then shape urban land-use patterns. To investigate this issue, we have constructed an extended experience-weighted attraction learning model to represent the human agents\u2019 learning when they make location decisions. Consequently, we propose and have developed an agent-based learning-embedded model (ABM-learning) for residential land growth simulation that incorporates a learning model, a decision-making model, a land use conversion model and the constraint of urban land use master plan. The proposed model was used for a simulation of the residential land growth in Shenzhen city, China. By validating the model against empirical data, the results showed that the site-specific accuracy of the model has been improved when embedding learning model. The analysis on the simulation accuracies has proved the argument that modelling individual-level learning matters in the agent's decision model and the agent-based models. We also applied the model to predict residential land growth in Shenzhen from 2015 to 2035, and the result can be a reference for land-use allocation in detailed planning of Shenzhen. The ABM-learning is applicable to studying the past urban growth trajectory, aiding in the formulation of detailed residential land and public service facility planning and assessing the land use planning effectiveness. \u00a9 2020 Elsevier Ltd","Author Keywords":"ABM-learning; Agent-Based modelling; Experience-Weighted attraction learning model; Residential land growth; Shenzhen city","Authors":"Li F., Li Z., Chen H., Chen Z., Li M.","DOI":"10.1016\/j.landusepol.2020.104620","x":11.67,"y":2.95},{"HDBSCAN_Cluster":1,"DocId":259,"Cited by":10.0,"Year":2020,"Document Type":"Article","Title":"A locally-constrained YOLO framework for detecting small and densely-distributed building footprints","Abstract":"Building footprints are among the most predominant features in urban areas, and provide valuable information for urban planning, solar energy suitability analysis, etc. We aim to automatically and rapidly identify building footprints by leveraging deep learning techniques and the increased availability of remote sensing datasets at high spatial resolution. The task is computationally challenging due to the use of large training datasets and large number of parameters. In related work, You-Only-Look-Once (YOLO) is a state-of-the-art deep learning framework for object detection. However, YOLO is limited in its capacity to identify small objects that appear in groups, which is the case for building footprints. We propose a LOcally-COnstrained (LOCO) You-Only-Look-Once framework to detect small and densely-distributed building footprints. LOCO is a variant of YOLO. Its layer architecture is determined by the spatial characteristics of building footprints and it uses a constrained regression modeling to improve the robustness of building size predictions. We also present an invariant augmentation based voting scheme to further improve the precision in the prediction phase. Experiments show that LOCO can greatly improve the solution quality of building detection compared to related work. \u00a9 2019, \u00a9 2019 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"Building detection; deep learning; locally constrained; remote sensing; YOLO","Authors":"Xie Y., Cai J., Bhojwani R., Shekhar S., Knight J.","DOI":"10.1080\/13658816.2019.1624761","x":15.9,"y":6.09},{"HDBSCAN_Cluster":-1,"DocId":260,"Cited by":16.0,"Year":2020,"Document Type":"Letter","Title":"Regional mapping of essential urban land use categories in China: A segmentation-based approach","Abstract":"Understanding distributions of urban land use is of great importance for urban planning, decision support, and resource allocation. The first mapping results of essential urban land use categories (EULUC) in China for 2018 have been recently released. However, such kind of national maps may not sufficiently meet the growing demand for regional analysis. To address this shortcoming, here we proposed a segmentation-based framework named EULUC-seg to improve the mapping results of EULUC at the city scale. An object-based segmentation approach was first applied to generate the basic mapping units within urban parcels. Multiple features derived from high-resolution remotely sensed and social sensing data were updated and then recalculated within each unit. Random forest was adopted as the machine learning algorithm for classifying urban land use into five Level I classes and twelve Level II classes. Finally, an accuracy assessment was carried out based on a collection of manually interpreted samples. Results showed that our derived map achieved an overall accuracy of 87.58% for Level I, and 73.53% for Level II. The accurate and refined map of EULUC-seg is expected to better support various applications in the future. \u00a9 2020, by the authors.","Author Keywords":"Machine learning; Ningbo; Segmentation; Urban land use","Authors":"Tu Y., Chen B., Zhang T., Xu B.","DOI":"10.3390\/rs12071058","x":13.32,"y":4.02},{"HDBSCAN_Cluster":-1,"DocId":282,"Cited by":2.0,"Year":2020,"Document Type":"Conference Paper","Title":"Land cover classification based on machine learning using UAV multi-spectral images","Abstract":"Land cover classification using UAV multi-spectral images is of great significance in precision agriculture, urban planning, land use and other fields. However, traditional remote sensing image classification methods cannot meet the classification accuracy requirements of UAV multi-spectral images. This paper aims to propose an object-based machine learning classification method to improve the land over classification accuracy of UAV multi-spectral images. The experimental area is a standard test field located in the Jilin Province of China. The experimental data was captured by a UAV equipped with a multi-spectral camera which includes four bands from 550 nm to 790 nm. First, the original images were preprocessed and the spectral curves of land cover were analyzed, thus four kinds of land cover with large differences were selected as categories. Then pixel-based, boosting-based and object-based machine learning methods were used for classification. The object-based classification method could make full use of the spatial and spectral information, and eliminate the noise problem caused by the high resolution of the UAV image to a certain extent. Finally, accuracy analysis using the verification image showed that the RF-O method achieved the highest classification accuracy of 92.2419%, and the kappa coefficient was 0.8904. All results indicate that the object-based machine learning classification method proposed in this paper is more suitable for the research of land cover classification, comparing with the traditional remote sensing image classification methods, and performs well on the land cover classification of UAV multi-spectral images. \u00a9 2020 SPIE.","Author Keywords":"Image classification; Machine learning; UAV remote sensing","Authors":"Pan L., Gu L., Ren R., Yang S.","DOI":"10.1117\/12.2566128","x":14.83,"y":4.21},{"HDBSCAN_Cluster":-1,"DocId":283,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"Remote sensing and GIS approach for environmental green areas planning using Landsat satellite imagery, Dubai-UAE","Abstract":"Over the last decade, Dubai emirate witnessed a vast, rapidly growing population, that doubled since 2008. Nowadays, Dubai considers as the most populated emirate within the United Arab Emirates (UAE). With such an increasing population and new urban developments, sustainable urban planning procedures play an essential role in Dubai's environmental quality such as air quality, and pollution. Therefore, this study will utilize the Remote Sensing and Geographic Information system (GIS) to investigate Dubai's environmental quality by addressing and locating green areas and pollution percentages within each district. The study methodology is divided into three steps. First, Landsat Satellite medium spatial resolution and multi-spectral imagery will be used as an input for segmentation and object-based analysis. Considering the spectral and spatial signatures for green areas machine learning techniques will be adopted to select the most significant features to classify and extract green areas. Second, using environmental relational indices, green areas percentages will be quantitatively compared to Sentinel air quality data, such as NO2 and SO2, as well as the population density maps. Finally, GIS techniques will be used to create Dubai Environmental Critical Map (DECM), to locate districts with limited green areas and high pollution to improve environmental standards. The study results can be used as a measure for the municipality policymakers to ensure sustainable urban development for a healthy living. \u00a9 2020 SPIE","Author Keywords":"Dubai Environmental Vulnerability Map (DEVM); Geographic Information system (GIS); Remote Sensing","Authors":"Aldogom D., Mansoori S.A., AlMaazmi A., Nazzal T.","DOI":"10.1117\/12.2573904","x":13.37,"y":3.63},{"HDBSCAN_Cluster":-1,"DocId":285,"Cited by":70.0,"Year":2020,"Document Type":"Article","Title":"Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review","Abstract":"Remote sensing (RS) systems have been collecting massive volumes of datasets for decades, managing and analyzing of which are not practical using common software packages and desktop computing resources. In this regard, Google has developed a cloud computing platform, called Google Earth Engine (GEE), to effectively address the challenges of big data analysis. In particular, this platform facilitates processing big geo data over large areas and monitoring the environment for long periods of time. Although this platform was launched in 2010 and has proved its high potential for different applications, it has not been fully investigated and utilized for RS applications until recent years. Therefore, this study aims to comprehensively explore different aspects of the GEE platform, including its datasets, functions, advantages\/limitations, and various applications. For this purpose, 450 journal articles published in 150 journals between January 2010 and May 2020 were studied. It was observed that Landsat and Sentinel datasets were extensively utilized by GEE users. Moreover, supervised machine learning algorithms, such as Random Forest, were more widely applied to image classification tasks. GEE has also been employed in a broad range of applications, such as Land Cover\/land Use classification, hydrology, urban planning, natural disaster, climate analyses, and image processing. It was generally observed that the number of GEE publications have significantly increased during the past few years, and it is expected that GEE will be utilized by more users from different fields to resolve their big data processing challenges. \u00a9 2008-2012 IEEE.","Author Keywords":"Big data; cloud computing; Google Earth Engine (GEE); remote sensing (RS)","Authors":"Amani M., Ghorbanian A., Ahmadi S.A., Kakooei M., Moghimi A., Mirmazloumi S.M., Moghaddam S.H.A., Mahdavi S., Ghahremanloo M., Parsian S., Wu Q., Brisco B.","DOI":"10.1109\/JSTARS.2020.3021052","x":14.84,"y":3.67},{"HDBSCAN_Cluster":0,"DocId":288,"Cited by":null,"Year":2020,"Document Type":"Conference Paper","Title":"A Machine Learning-Based Method for Predicting Urban Land Use","Abstract":"Land use is one of the most basic elements of urban management. In urban planning and design, land use is often determined by experience and case studies. However, the development of urbanization has led to a combinatory trend for land use, and the land use of a plot is always impacted by the surrounding environment. In such a complex situation, it is difficult to find hidden relationships among types of land use by humans alone. Within artificial intelligence, machine learning can help find correlations among data. This paper presents a new method for learning the rules relating the known land use data and predicting the land use of a target plot by constructing an artificial neural network. We take Nanjing as a specific case and study the logic of its land use. The results not only demonstrate associations between the surroundings and the target but also show the feasibility of a combinatory land use index in urban planning and design. \u00a9 2020 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.","Author Keywords":"Artificial neural network; Land use; Machine learning; Urban planning and design","Authors":"Xia X., Tong Z.","DOI":null,"x":12.3,"y":2.86},{"HDBSCAN_Cluster":-1,"DocId":289,"Cited by":4.0,"Year":2020,"Document Type":"Article","Title":"A Self-Supervised Learning Framework for Road Centerline Extraction from High-Resolution Remote Sensing Images","Abstract":"Road extraction from the high-resolution remote sensing image is significant for the land planning, vehicle navigation, etc. The existing road extraction methods normally need many preprocessing and subsequent optimization steps. Therefore, an automatic road centerline extraction method based on the self-supervised learning framework for high-resolution remote sensing image is proposed. This proposed method does not need to manually select training samples and other optimization steps, such as the nonroad area removing. First, the positive sample selection method combining the spectral and shape features is proposed to extract the road sample. Then, the one-class classifier framework is introduced and the random forest positive unlabeled learning classifier is constructed to get the posterior probability of the pixel belonging to road. The shape feature and the posterior probability are combined to form the final road network in the object-oriented way. Finally, the road centerline is obtained through the tensor voting algorithm. In order to verify the effectiveness of the proposed algorithm, high-resolution remote sensing images and benchmark datasets are used to do experiments. The indexes of the completeness ratio, the correctness ratio, and the detection quality are used for the quantitative accuracy evaluation. Compared with the supervised, the unsupervised, and the one-class classification road extraction algorithms, this proposed algorithm achieves high accuracy and efficiency. For the deep learning method comparison, the deep learning method performs well in most cases especially in the complex urban area. However, the deep learning method needs a large number of samples and a long training time, and our self-supervised learning framework does not need the training samples. \u00a9 2008-2012 IEEE.","Author Keywords":"High-resolution remote sensing image; one-class classifier; road centerline; road extraction; self-supervised learning","Authors":"Guo Q., Wang Z.","DOI":"10.1109\/JSTARS.2020.3014242","x":15.03,"y":5.32},{"HDBSCAN_Cluster":0,"DocId":293,"Cited by":3.0,"Year":2020,"Document Type":"Article","Title":"Sensing Mixed Urban Land-Use Patterns Using Municipal Water Consumption Time Series","Abstract":"The biased population coverage and short temporal lengths of newly emerged data sets (e.g., data sets of social media, mobile phones, and smart cards) obstruct the effective analysis of long-term dynamics of landuse patterns, particularly in small and developing cities. This study proposed a framework to delineate and analyze mixed land-use patterns and their evolution using municipal water consumption data. A two-step classification strategy was designed based on the rotation forest scheme to differentiate the socioeconomic types of customers (e.g., residence, commerce, public facility, manufacturing, and recreation) using multiple features extracted from the various forms of water consumption time series. The spatial distributions of the socioeconomic functions were then derived, and the mixed land use was measured using a diversity index based on information entropy. Such an approach was applied to Changshu, a typical developing county-level city in China, for the period 2004 to 2013. The results showed that the urbanization of Changshu experienced both spatial expansion and intensification, with a slightly declining rate of growth in recent years. Apart from the city center, two subcenters have emerged for industrial development. The degree of land-use mixture has increased with urban growth, indicating a maturing of urbanization. This study explored the approach of identifying individual socioeconomic functions by the consumption patterns of municipal services and demonstrated that municipal service data sets can reveal land-use patterns and dynamics at a fine spatial resolution to evaluate urban planning and management, with the advantages of large population coverage and long-term temporal lengths. \u00a9 2020, \u00a9 2020 by American Association of Geographers.","Author Keywords":"land-use patterns; mixed land use; municipal water consumption; rotation forest; social sensing","Authors":"Guan Q., Cheng S., Pan Y., Yao Y., Zeng W.","DOI":"10.1080\/24694452.2020.1769463","x":12.91,"y":3.05},{"HDBSCAN_Cluster":0,"DocId":299,"Cited by":13.0,"Year":2020,"Document Type":"Article","Title":"Spatiotemporal modeling of urban growth using machine learning","Abstract":"This paper presents a general framework for modeling the growth of three important variables for cities: population distribution, binary urban footprint, and urban footprint in color. The framework models the population distribution as a spatiotemporal regression problem using machine learning, and it obtains the binary urban footprint from the population distribution through a binary classifier plus a temporal correction for existing urban regions. The framework estimates the urban footprint in color from its previous value, as well as from past and current values of the binary urban footprint using a semantic inpainting algorithm. By combining this framework with free data from the Landsat archive and the Global Human Settlement Layer framework, interested users can get approximate growth predictions of any city in the world. These predictions can be improved with the inclusion in the framework of additional spatially distributed input variables over time subject to availability. Unlike widely used growth models based on cellular automata, there are two main advantages of using the proposed machine learning-based framework. Firstly, it does not require to define rules a priori because the model learns the dynamics of growth directly from the historical data. Secondly, it is very easy to train new machine learning models using different explanatory input variables to assess their impact. As a proof of concept, we tested the framework in Valledupar and Rionegro, two Latin American cities located in Colombia with different geomorphological characteristics, and found that the model predictions were in close agreement with the ground-truth based on performance metrics, such as the root-mean-square error, zero-mean normalized cross-correlation, Pearson's correlation coefficient for continuous variables, and a few others for discrete variables such as the intersection over union, accuracy, and the f1 metric. In summary, our framework for modeling urban growth is flexible, allows sensitivity analyses, and can help policymakers worldwide to assess different what-if scenarios during the planning cycle of sustainable and resilient cities. \u00a9 2019 by the authors.","Author Keywords":"Computer vision; Machine learning; Spatiotemporal modeling; Urban growth; Urban planning tools; Urban science","Authors":"G\u00f3mez J.A., Pati\u00f1o J.E., Duque J.C., Passos S.","DOI":"10.3390\/rs12010109","x":12.03,"y":3.6},{"HDBSCAN_Cluster":1,"DocId":301,"Cited by":1.0,"Year":2020,"Document Type":"Conference Paper","Title":"Application of satellite image segmentation for urban planning optimization","Abstract":"This article presents research results of a convolution neural network for building detection on high-resolution aerial images of Planet database. Jaccard index was used for analysis of the quality of machine learning algorithm. This index of similarity compares results of algorithms with real masks. The masks were sliced on smaller parts together with images before training of developed model. The convolution neural network was launched on NVIDIA DGX-1 supercomputer, which was provided by AI-center of P.G Demidov Yaroslavl State University. The problem of building detection on satellite images can be put into practice for urban planning, building control, search of the best locations for outlets etc. \u00a9 WCSE 2019. All rights reserved.","Author Keywords":"Aerial image segmentation; Building detection; Machine learning","Authors":"Khryashchev V., Ivanovsky L., Ostrovskaya A., Semenov A.","DOI":null,"x":15.19,"y":5.91},{"HDBSCAN_Cluster":0,"DocId":302,"Cited by":1.0,"Year":2020,"Document Type":"Article","Title":"Mapping Urban Slum Settlements Using Very High-Resolution Imagery and Land Boundary Data","Abstract":"Accurate mapping of slums is crucial for urban planning and management. This article proposes a machine learning, hierarchical object-based method to map slum settlements using very high-resolution (VHR) imagery and land boundary data to support slum upgrading. The proposed method is tested in Kingston Metropolitan Area, Jamaica. First, the VHR imagery is classified into major land cover classes (i.e., the initial land cover map). Second, the VHR imagery and land boundary layer are used to obtain homogenous neighborhoods (HNs). Third, the initial land cover map is used to derive multiple context, spectral, and texture image features according to the local physical characteristics of slum settlements. Fourth, a machine-learning classifier, classification and regression trees, is used to classify HNs into slum and nonslum settlements using only the effective image features. Finally, reference data collected manually are used to assess the accuracy of the classification. In the training site, an overall accuracy of 0.935 is achieved. The effective image indicators for slum mapping include the building layout, building density, building roof characteristics, and distance from buildings to gullies. The classifier and those features selected from the training site are further used to map slums in two validating sites to assess the transferability of our approach. Overall accuracy of the two validating sites reached 0.928 and 0.929, respectively, suggesting that the features and classification model obtained from one site has the potential to be transferred to other areas in Jamaica and possibly other developing Caribbean countries with similar situation and data availability. \u00a9 2008-2012 IEEE.","Author Keywords":"Classification and regression trees (CART); Jamaica; object-oriented classification; slum settlements; very high-resolution (VHR) image","Authors":"Williams T.K.-A., Wei T., Zhu X.","DOI":"10.1109\/JSTARS.2019.2954407","x":13.55,"y":4.51},{"HDBSCAN_Cluster":0,"DocId":303,"Cited by":null,"Year":2020,"Document Type":"Book Chapter","Title":"Comparison of performance of artificial neural network (ANN) and random forest (RF) in the classification of land cover zones of urban slum region","Abstract":"India is one of the world\u2019s largest economies and economic growth has remained continuous. This has led to accelerating urbanization which requires proper planning and monitoring. As the urban areas are expanding, urban slum areas are also increasing along with it. These growing urban slum areas require proper observation so that existing resources can be employed to provide these regions with the best possible livelihood conditions. For this purpose, urban slum areas as well as surrounding land resources should be well identified and classified so that the existing land resources can be appropriately utilized for future implementation of development activities. Machine learning classification algorithms are found to be very suitable for the identification and classification of remotely sensed images. Their efficiency in feature identification and extraction has established these algorithms as important tools in decision making. In this study, our major objective is to identify and classify different land cover zones in the urban slums areas of Chingrajpara area of Chhattisgarh using remotely-sensed images. For this purpose, high-resolution images, collected using unmanned aerial vehicles (UAVs), are used and these images are classified into different land cover features using two different machine learning algorithms Artificial Neural Network (ANN) and Random Forest (RF). The results obtained show that the overall accuracy achieved by ANN and RF are 72.6% and 84.35% respectively. The study highlights the role and importance of landcover classification for future planning and management. \u00a9 Springer Nature Switzerland AG 2020.","Author Keywords":"Artificial neural network (ANN); Random forest (RF); Unmanned aerial vehicles (UAVs)","Authors":"Tyagi D., Haq M.A., Rahaman G., Baral P., Datta J.","DOI":"10.1007\/978-3-030-37393-1_20","x":14.09,"y":4.15},{"HDBSCAN_Cluster":0,"DocId":310,"Cited by":8.0,"Year":2020,"Document Type":"Article","Title":"Analyzing the spatial factors related to the distributions of building heights in urban areas: A comparative case study in Guangzhou and Shenzhen","Abstract":"Rapid urbanization has become an increasingly serious issue worldwide. While most previous studies focused on two-dimensional urban development, the spatial characteristics of building heights are rarely explored. Such information could provide valuable implications for smart urban planning and management. However, previous attempts did not systematically investigate the spatial factors that influence building heights and their associations with urban development. Therefore, this study developed a machine learning-based method to compare the distributions of building heights in Guangzhou and Shenzhen, two cities with different development patterns. First, we collected detailed information on the buildings, such as the location and land values. Second, the height of each building was simulated based on the above information using the well-known random forests, k-nearest neighbor algorithm, and artificial neural network. The random forests algorithm outperformed the other two in both cities. We also found that the commercial land value is the most important factor associated with building heights. Moreover, the building heights in Guangzhou are more sensitive to the distances to administrative centers, while the distances to transportation networks exert stronger influences on the building heights in Shenzhen. Overall, these findings could support urban planning and management. More importantly, the proposed method can be used to predict the heights of new buildings and investigate the distributions of building heights in other regions. \u00a9 2019 Elsevier Ltd","Author Keywords":"Building heights; Machine learning; Spatial factors; Urban modeling","Authors":"Lin J., Wan H., Cui Y.","DOI":"10.1016\/j.scs.2019.101854","x":11.92,"y":3.7},{"HDBSCAN_Cluster":-1,"DocId":312,"Cited by":11.0,"Year":2019,"Document Type":"Conference Paper","Title":"Mapping Urban Trees Within Cadastral Parcels Using an Object-Based Convolutional Neural Network","Abstract":"Urban trees offer significant benefits for improving the sustainability and liveability of cities, but its monitoring is a major challenge for urban planners. Remote-sensing based technologies can effectively detect, monitor and quantify urban tree coverage as an alternative to field-based measurements. Automatic extraction of urban land cover features with high accuracy is a challenging task and it demands artificial intelligence workflows for efficiency and thematic quality. In this context, the objective of this research is to map urban tree coverage per cadastral parcel of Sandy Bay, Hobart from very high-resolution aerial orthophoto and LiDAR data using an Object Based Convolution Neural Network (CNN) approach. Instead of manual preparation of a large number of required training samples, automatically classified Object based image analysis (OBIA) output is used as an input samples to train CNN method. Also, CNN output is further refined and segmented using OBIA to assess the accuracy. The result shows 93.2% overall accuracy for refined CNN classification. Similarly, the overlay of improved CNN output with cadastral parcel layer shows that 21.5% of the study area is covered by trees. This research demonstrates that the accuracy of image classification can be improved by using a combination of OBIA and CNN methods. Such a combined method can be used where manual preparation of training samples for CNN is not preferred. Also, our results indicate that the technique can be implemented to calculate parcel level statistics for urban tree coverage that provides meaningful metrics to guide urban planning and land management practices. \u00a9 2019 Authors.","Author Keywords":"Cadastral Parcel; Convolutional Neural Network; GEOBIA; Machine Learning; Urban Trees","Authors":"Timilsina S., Sharma S.K., Aryal J.","DOI":"10.5194\/isprs-annals-IV-5-W2-111-2019","x":15.14,"y":4.81},{"HDBSCAN_Cluster":1,"DocId":314,"Cited by":null,"Year":2019,"Document Type":"Conference Paper","Title":"Urban Intelligent Navigator for Drone Using Convolutional Neural Network (CNN)","Abstract":"It is still a difficult and challenging task for a drone to maneuver autonomously at low altitude in the urban environments. This is due to the complexity of the urban environment and its unpredictability. Many researches have been carried out in the past decades until recent time, to find a way to solve this problem using powerful sensors such as laser rangefinder sensor, RGB-D camera, stereo vision system, LIDAR and computer vision methods. This paper is aimed to present an urban intelligent navigator for drone using CNN (convolutional neural network). The application of computer vision (object detection) is cheap and has low power consumption compared to other kinds of vision systems. The machine learning allows a drone to detect and recognize all the objects and obstacles on the roads, which can block drone's way. One thousand images were captured of six different street objects (tree, lamp, bump sign, free-smoking sign, no-horn sign, and roof-wall). Those images were used as a dataset to create a machine learning using Faster R-CNN (region convolutional neural network) method. Three machine-learning models were created using different parameters for each model. The controlled parameters are the initial learning rate and the batch-size. Only the third model could successfully detect and recognize all the objects at a specified location showing 98% accuracy. \u00a9 2019 IEEE.","Author Keywords":"Convolution neural networks; Faster R-CNN; Object detection; object recognition","Authors":"Moteir I.G.M.I., Ismail K., Zawawi F.M., Azhar M.M.M.","DOI":"10.1109\/SmartNets48225.2019.9069781","x":15.66,"y":5.61},{"HDBSCAN_Cluster":0,"DocId":316,"Cited by":null,"Year":2019,"Document Type":"Article","Title":"Integrating activity-based geographic information and long-term remote sensing to characterize urban land use change","Abstract":"The land use structure is a key component to understand the complexity of urban systems because it provides a snapshot of urban dynamics and how people use space. This paper integrates socially sensed activity data with a remotely sensed land cover product in order to infer urban land use and its changes over time. We conducted a case study in theWashington D.C.-Baltimore metropolitan area to identify the pattern of land use change from undeveloped to developed land, including residential and non-residential uses for a period covering 1986-2008. The proposed approach modeled physical and behavioral features of land parcels from a satellite-based impervious surface cover change product and georeferenced Tweets, respectively. A model assessment with random forests classifiers showed that the proposed classification workflow could classify residential and non-residential land uses at an accuracy of 81%, 4% better than modeling the same land uses from physical features alone. Using the timestamps of the impervious surface cover change product, the study also reconstructed the timeline of the identified land uses. The results indicated that the proposed approach was capable of mapping detailed land use and change in an urban region, and represents a new and viable way forward for urban land use surveying that could be especially useful for surveying and tracking changes in cities where traditional approaches and mapping products (i.e., from remote sensing products) may have a limited capacity to capture change. \u00a9 2019 by the authors.","Author Keywords":"Activity patterns; Land use; Machine learning; Social sensing; Twitter","Authors":"Fu C., Song X.-P., Stewart K.","DOI":"10.3390\/rs11242965","x":13.53,"y":3.07},{"HDBSCAN_Cluster":0,"DocId":317,"Cited by":3.0,"Year":2019,"Document Type":"Article","Title":"Spatiotemporal dynamics of urbanization and cropland in the Nile Delta of Egypt using machine learning and satellite big data: implications for sustainable development","Abstract":"The Nile Delta of Egypt is increasingly facing sustainability threats, due to a combination of nature- and human-induced changes in land cover and land use. In this paper, an analysis of big time series data from remotely sensed satellite images and the random forests classifier was undertaken to assess the spatial and temporal dynamics of urbanization and cropland in the Nile Delta between 2007 and 2017. Out of thirteen variables, five spectral indices were chosen to build 500 decision trees, with a resulting overall accuracy average of 91.9 \u00b1 1.5%. The results revealed that the urban extent in the Nile Delta has increased, between 2007 and 2017, by 592.4 km2 (1.92%). Particularly, the results indicated that the years 2011 and 2012, which coincided the 2011 political uprising in Egypt, so-called the Arab Spring, were associated with significant land-use changes in the Nile Delta, both in rate and scale. As a result, the cropland area in the region decreased between 2010 and 2011 by 1.63% (502.21 km2). Moreover, the results showed that during the period 2012\u20132017, the mean annual urbanization rate in the region stood at 60 km2\/year. In contrast, croplands decreased during the same period at an average annual rate of 2 km2\/year. At the governorates\u2019 level, the results suggested that top agricultural producing governorates in the Nile Delta, such as Elmonoufia, Elkalubia, Elbouhyra, and Elghrbia, witnessed the highest rates of decrease in cropland areas during the period 2012\u20132017. Over the same period, urban areas increased the most in Elkalubia, Domiate, and Elmonoufia by 1.98%, 1.72%, and 1.34%, respectively. The f indings from this analysis are discussed along with their implications for sustainable land-use and urban planning policies. \u00a9 2019, Springer Nature Switzerland AG.","Author Keywords":"Big data; LULC; Nile Delta; Random forests; Sustainable development; Urbanization","Authors":"Badreldin N., Abu Hatab A., Lagerkvist C.-J.","DOI":"10.1007\/s10661-019-7934-x","x":13.39,"y":3.12},{"HDBSCAN_Cluster":0,"DocId":320,"Cited by":17.0,"Year":2019,"Document Type":"Article","Title":"Evaluation and comparison of eight machine learning models in land use\/land cover mapping using Landsat 8 OLI: a case study of the northern region of Iran","Abstract":"Land use land cover change mapping has been used for monitoring environmental changes as an essential factor to study on the earth\u2019s surface land cover in the field of climate change phenomena such as floods and droughts. Remote sensing images have been suggested to present inexpensive and fine-scale data offering multi-temporal coverage. This tool is useful in the field of environmental monitoring, land-cover mapping, and urban planning. This study aims to evaluate eight machine learning algorithms for image classification implemented in WEKA and R programming language. Firstly, Landsat 8 OLI\/TIRS Level-2 images based on eight machine learning techniques including Random Forest, Decision Table, DTNB, J48, Lazy IBK, Multilayer Perceptron, Non-Nested Generalized Exemplars (NN ge), and Simple Logistic are classified. Then, obtained results are compared in term of Overall Accuracy (OA), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) for land use land cover mapping. Among the eight machine learning algorithms used for image classification based on the training and test dataset, NN ge classifier is ranked first with values of 100, 0, and 0 for Overall\u00a0Accuracy, Mean\u00a0Absolute\u00a0Error and Root\u00a0Mean\u00a0Squared\u00a0Error respectively. All machine learning algorithms had an Overall\u00a0Accuracy of more than 99% for the training dataset. On the other hand, for the test dataset, J48 and DTNB algorithms\u00a0had the worst performance with values of 88.1188 and 76.9802 respectively for the Overall\u00a0Accuracy. \u00a9 2019, Springer Nature Switzerland AG.","Author Keywords":"Image classification; LULCC; Machine learning; R statistical packages; WEKA","Authors":"Jamali A.","DOI":"10.1007\/s42452-019-1527-8","x":14.12,"y":3.78},{"HDBSCAN_Cluster":-1,"DocId":327,"Cited by":12.0,"Year":2019,"Document Type":"Conference Paper","Title":"Aerial point cloud classification with deep learning and machine learning algorithms","Abstract":"With recent advances in technology, 3D point clouds are getting more and more frequently requested and used, not only for visualization needs but also e.g. by public administrations for urban planning and management. 3D point clouds are also a very frequent source for generating 3D city models which became recently more available for many applications, such as urban development plans, energy evaluation, navigation, visibility analysis and numerous other GIS studies. While the main data sources remained the same (namely aerial photogrammetry and LiDAR), the way these city models are generated have been evolving towards automation with different approaches. As most of these approaches are based on point clouds with proper semantic classes, our aim is to classify aerial point clouds into meaningful semantic classes, e.g. ground level objects (GLO, including roads and pavements), vegetation, buildings' facades and buildings' roofs. In this study we tested and evaluated various machine learning algorithms for classification, including three deep learning algorithms and one machine learning algorithm. In the experiments, several hand-crafted geometric features depending on the dataset are used and, unconventionally, these geometric features are used also for deep learning. \u00a9 2019 E. \u00d6zdemir et al.","Author Keywords":"Classification; Deep learning; Geometric features; Machine learning; Point cloud; Urban areas","Authors":"\u00d6zdemir E., Remondino F., Golkar A.","DOI":"10.5194\/isprs-archives-XLII-4-W18-843-2019","x":15.04,"y":6.36},{"HDBSCAN_Cluster":-1,"DocId":328,"Cited by":33.0,"Year":2019,"Document Type":"Article","Title":"Simulation of urban expansion via integrating artificial neural network with Markov chain\u2013cellular automata","Abstract":"Accurate simulations and predictions of urban expansion are critical to manage urbanization and explicitly address the spatiotemporal trends and distributions of urban expansion. Cellular Automata integrated Markov Chain (CA-MC) is one of the most frequently used models for this purpose. However, the urban suitability index (USI) map produced from the conventional CA-MC is either affected by human bias or cannot accurately reflect the possible nonlinear relations between driving factors and urban expansion. To overcome these limitations, a machine learning model (Artificial Neural Network, ANN) was integrated with CA-MC instead of the commonly used Analytical Hierarchy Process (AHP) and Logistic Regression (LR) CA-MC models. The ANN was optimized to create the USI map and then integrated with CA-MC to spatially allocate urban expansion cells. The validated results of kappa and fuzzy kappa simulation indicate that ANN-CA-MC outperformed other variously coupled CA-MC modelling approaches. Based on the ANN-CA-MC model, the urban area in South Auckland is predicted to expand to 1340.55\u00a0ha in 2026 at the expense of non-urban areas, mostly grassland and open-bare land. Most of the future expansion will take place within the planned new urban growth zone. \u00a9 2019, \u00a9 2019 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"artificial neural network; cellular automata; kappa simulation; Markov chain; South Auckland; Urban expansion","Authors":"Xu T., Gao J., Coco G.","DOI":"10.1080\/13658816.2019.1600701","x":11.83,"y":2.66},{"HDBSCAN_Cluster":1,"DocId":330,"Cited by":null,"Year":2019,"Document Type":"Conference Paper","Title":"THE POTENTIAL of BUILDING DETECTION from SAR and LIDAR USING DEEP LEARNING","Abstract":"The introduction of airborne Synthetic Aperture Radar (SAR) approach has successfully addressed several challenges for mapping and surveying applications Unlike other conventional sensors, airborne SAR mapping approach offers practicality and significant cost savings for the nation minimizing the need for ground control points on the ground in addition to providing high-resolution, day-and-night, cloud coverage and weather independent images, which in turn provides faster turnaround times for creation of large area geospatial data. Up-to-date building map is necessary to guide the decision making in many fields to understand the urban dynamics such as in disaster management, population estimation, planning and many other applications. Whilst mapping and surveying work using airborne SAR have started to capture many interest among surveyors, professionals and practitioners abroad, Malaysia however is still lacking behind in term of the knowledge and the usage of this technology together with Deep Learning, Machine Learning approach especially in building extraction for topographic mapping and urban planning and development. Deep learning is a subset of the machine learning algorithm. Recently, Deep Learning has been proposed to solve traditional artificial intelligent problems. In order to develop a sustainable national geospatial infrastructure for years to come, the integration between airborne SAR and other sensors as such LIDAR is therefore essential in Malaysia and in high demand for urban planning and management. Thus, this paper reviews current techniques and future trends of multi-sources Remote Sensing for building extraction. \u00a9 2019 Z. Nordin et al.","Author Keywords":"building extraction; deep learning; feature extraction; lidar; orthophoto; synthetic aperture radar (SAR)","Authors":"Nordin Z., Shafri H.Z.M., Abdullah A.F., Hashim S.J.","DOI":"10.5194\/isprs-archives-XLII-4-W16-489-2019","x":15.32,"y":5.99},{"HDBSCAN_Cluster":0,"DocId":331,"Cited by":null,"Year":2019,"Document Type":"Conference Paper","Title":"EVALUATION of ADVANCED DATA MINING ALGORITHMS in LAND USE\/LAND COVER MAPPING","Abstract":"For environmental monitoring, land-cover mapping, and urban planning, remote sensing is an effective method. In this paper, firstly, for land use land cover mapping, Landsat 8 OLI image classification based on six advanced mathematical algorithms of machine learning including Random Forest, Decision Table, DTNB, Multilayer Perceptron, Non-Nested Generalized Exemplars (NN ge) and Simple Logistic is used. Then, results are compared in the terms of Overall Accuracy (OA), Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) for land use land cover (LULC) mapping. Based on the training and test datasets, Simple Logistic had the best performance in terms of OA, MAE and RMSE values of 99.9293, 0.0006 and 0.016 for training dataset and values of 99.9467, 0.0005 and 0.0153 for the test dataset. \u00a9 2019 A. Jamali.","Author Keywords":"data mining; image classification; land use land cover; lulc; machine learning","Authors":"Jamali A., Abdul Rahman A.","DOI":"10.5194\/isprs-archives-XLII-4-W16-283-2019","x":14.16,"y":3.7},{"HDBSCAN_Cluster":-1,"DocId":333,"Cited by":2.0,"Year":2019,"Document Type":"Conference Paper","Title":"Machine Learning for Strategic Urban Planning","Abstract":"Data mining is an important part of strategic planning for the development of modern urban settlement with capacities to accommodate population explosion. Developing countries are fast becoming urbanized giving the developments and opportunities that are lacking in rural areas. Data regarding urban development such as satellite image need to be analysed to ascertain the possibilities for further development or opening up of new settlements. This work presents a binary sub-pixel and feature based method of classification to detect water bodies and vegetation in earth observatory images. In this work, the images were subjected data pre-processing, feature extraction, and analysed the data using machine learning classification method to detection regions that support urban expansion or development of new settlement. The proposed method achieved 88.93% accuracy and 0.06% RMSE. \u00a9 2019 IEEE.","Author Keywords":"feature engineering; Haar-cascade; machine learning; object detection; Satellite image","Authors":"Odaudu S.N., Umoh I.J., Mu'Azu M.B., Adedokun E.A.","DOI":"10.1109\/NigeriaComputConf45974.2019.8949665","x":13.87,"y":4.5},{"HDBSCAN_Cluster":0,"DocId":344,"Cited by":4.0,"Year":2019,"Document Type":"Article","Title":"Investigating adoption patterns of residential low impact development (LID) using classification trees","Abstract":"Local governments are under pressure to improve storm water management and often times must comply with consent decrees with the Federal Government. Decentralizing a portion of the storm water management by integrating private landowners into localized retention and infiltration efforts, that is, low impact development (LID) or green infrastructure projects, is becoming increasingly popular. Some wastewater systems have considered incentivizing private land owners to make improvements aimed at retaining storm water or slowing the conveyance to grey infrastructure. This study examines potential opportunities for incentivizing private residential land owners in Washington DC to install LID projects. This study maps LID configurations to a set of adoption strategies and categories. The C4.5 algorithm is then applied to identify a high performance decision tree for classifying parcels by adoption strategy or adoption categories based on property-level attributes. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Author Keywords":"Adopters, green city; Best management practices; C4.5 algorithm; Combined sewage overflow; CSO; Decision trees; Environmental policy; Green roofs; Impervious; Infiltration; Landscaping; LID; Low impact development; Machine learning; Permeable; Rain barrels; Run-off; Storm water management; Storm water retention; Urban planning; Water quality","Authors":"Amodeo D.C., Francis R.A.","DOI":"10.1007\/s10669-019-09725-3","x":12.89,"y":2.67},{"HDBSCAN_Cluster":0,"DocId":347,"Cited by":10.0,"Year":2019,"Document Type":"Article","Title":"Understanding the spatial distribution of urban forests in China using Sentinel-2 images with Google Earth Engine","Abstract":"Urban forests are vitally important for sustainable urban development and the well-being of urban residents. However, there is, as yet, no country-level urban forest spatial dataset of sufficient quality for the scientific management of, and correlative studies on, urban forests in China. At present, China attaches great importance to the construction of urban forests, and it is necessary to map a high-resolution and high-accuracy dataset of urban forests in China. The open-access Sentinel images and the Google Earth Engine platform provide a significant opportunity for the realization of this work. This study used eight bands (B2-B8, B11) and three indices of Sentinel-2 in 2016 to map the urban forests of China using the Random Forest machine learning algorithms at the pixel scale with the support of Google Earth Engine (GEE). The 7317 sample points for training and testing were collected from field visits and very high resolution images from Google Earth. The overall accuracy, producer's accuracy of urban forest, and user's accuracy of urban forest assessed by independent validation samples in this study were 92.30%, 92.27%, and 92.18%, respectively. In 2016, the percentage of urban forest cover was 19.2%. Nearly half of the cities had an urban forest cover between 10% and 20%, and the average percentage of large cities whose urban populations were over 5 million was 24.8%. Cities with less than half of the average were mainly distributed in northern and western parts of China, which should be focused on in urban greening planning. \u00a9 2019 by the authors.","Author Keywords":"China; Google Earth Engine; Sentinel-2; Urban area; Urban greening","Authors":"Duan Q., Tan M., Guo Y., Wang X., Xin L.","DOI":"10.3390\/f10090729","x":13.2,"y":4.39},{"HDBSCAN_Cluster":0,"DocId":348,"Cited by":12.0,"Year":2019,"Document Type":"Article","Title":"Machine learning-assisted evaluation of land use policies and plans in a rapidly urbanizing district in Chongqing, China","Abstract":"Analysis of annual land use change is crucial to timely assessment of the impacts of land use policies, especially in rapidly urbanizing areas such as the Liangjiang New District of Chongqing, China. This research aims to assess the impacts of multi-level land use policies and plans and their effectiveness in protecting farmland, and to recommend policies to remedy defective ones. Markov Chain\u2013Cellular Automata modelling was integrated with machine learning to predict future urbanization. The results show that prior to the establishment of the District in late 2010, the urban area grew at 13% annually because local policies promoted profit-motivated development. This rate declined drastically to 4% during 2011\u20132012 in direct response to the changed local land use policies and strict enforcement of national policies. These policies stabilized the urbanization rate at 7% over the subsequent years. The safeguard of previous farmland was possible only when the national policies were aligned closely with the local policies in their aim, provided both were rigorously enforced through a land management agency. Urban land in 2020 is predicted to growth by at least 464 km2 with some differences between two scenarios. In the baseline scenario (no change in policies), almost 70% of new growth will take place inside three industry zones and the duty-free ports. However, in the national overall plan scenario, a significant amount of marginal farmland will be changed into greenfields within the planned urban zones. It is recommended that a hierarchical farmland protection policy be implemented. It should incorporate the national policies that must be adapted to the local settings to achieve sustainable urbanization and to minimize farmland loss. \u00a9 2019 Elsevier Ltd","Author Keywords":"Artificial neural network; Land use change; Land use policies and plans; Markov Chain \u2013 Cellular Automata (MC-CA); Rapid urbanization; Spatiotemporal analysis","Authors":"Xu T., Gao J., Li Y.","DOI":"10.1016\/j.landusepol.2019.104030","x":11.88,"y":2.82},{"HDBSCAN_Cluster":0,"DocId":352,"Cited by":8.0,"Year":2019,"Document Type":"Article","Title":"Investigation of the likelihood of green infrastructure (GI)enhancement along linear waterways or on derelict sites (DS)using machine learning","Abstract":"Studies evaluating the potential for green infrastructure (GI)development using traditional Boolean logic-based multi-criteria analysis methods are not capable of predicting future GI development in dynamic urbanscapes. This study evaluated both artificial neural network (ANN)and adaptive, network-based fuzzy inference system (ANFIS)algorithms in conjunction with statistical modelling to predict green or grey transformation likelihoods for derelict sites (DS)and vacant sites along waterway corridors (WWC)in Manchester based on ecological, environmental, and social criteria. The soft-computing algorithms had better predictive capacity at 72% accuracy versus the 65% of logistic models. Site sizes, population coverage, and air pollution were identified as the main influencers in the potential for site transformation. In Manchester, the likelihood of GI transformation was higher for WWC than derelict sites at 80% versus 60% likelihood, respectively. Furthermore, DS were more likely to transform into grey development based on current trends and urban planning practice. \u00a9 2019","Author Keywords":"Artificial neural network (ANN); Green infrastructure; Green space; Machine learning; Urban land use","Authors":"Labib S.M.","DOI":"10.1016\/j.envsoft.2019.05.006","x":12.07,"y":2.64},{"HDBSCAN_Cluster":0,"DocId":361,"Cited by":9.0,"Year":2019,"Document Type":"Article","Title":"Geographic object based image analysis of world view-3 imagery for urban hydrologic modelling at the catchment scale","Abstract":"China's Sponge City initiative will involve widespread installation of new stormwater infrastructure including green roofs, permeable pavements and rain gardens in at least 30 cities. Hydrologic modelling can support the planning of Sponge Cities at the catchment scale, however, highly detailed spatial data for model input can be challenging to compile from the various authorities, or, if available, may not be sufficiently detailed or updated. Remote sensing methods show great promise for mitigating this challenge due to their ability to efficiently classify satellite images into categories relevant to a specific application. In this study Geographic Object Based Image Analysis (GEOBIA) was applied to WorldView-3 satellite imagery (2017) to create a detailed land cover map of an urban catchment area in Beijing. While land cover classification results based on a Bayesian machine learning classifier alone provided an overall land cover classification accuracy of 63%, the subsequent inclusion of a series of refining rules in combination with supplementary data (including elevation and parcel delineations), yielded the significantly improved overall accuracy of 76%. Results of the land cover classification highlight the limitations of automated classification based on satellite imagery alone and the value of supplementary data and additional rules to refine classification results. Catchment scale hydrologic modelling based on the generated land cover results indicated that 61 to 82% of rainfall volume could be captured for a range of 24 h design storms under varying degrees of Sponge City implementation. \u00a9 2019 by the authors.","Author Keywords":"Geographic object based image analysis; Low impact development; Remote sensing; Sponge city; SWMM; Urban hydrology","Authors":"Randall M., Fensholt R., Zhang Y., Jensen M.B.","DOI":"10.3390\/w11061133","x":14.12,"y":3.27},{"HDBSCAN_Cluster":0,"DocId":368,"Cited by":6.0,"Year":2019,"Document Type":"Conference Paper","Title":"Mapping poverty and slums using multiple methodologies in Accra, Ghana","Abstract":"Providing housing to slum dwellers, protecting them from natural disasters and diseases, and connecting them to jobs and services through improved infrastructure are urgent policy issues in many Sub-Saharan African cities. Identifying the location and living conditions of slums is a critical step toward designing effective urban policies. By combining household survey data and census data with high spatial resolution satellite imagery and other geospatial data using multiple methodologies, including machine learning, we attempt to define slums quantitatively within the city of Accra. Within these defined slum areas, the patterns of monetary poverty are assessed. Poverty rates are estimated at the neighborhood level and indicate that living in slums is strongly correlated with higher monetary poverty. Poverty is more prevalent in communities in areas of lower elevation, which in Accra are generally flood-prone areas. However, the results also suggest that not all people living in slums are living in monetary poverty. These results have important policy implications and are crucial to how economic opportunities are generated in slums so that effective urban policies can be designed. \u00a9 2019 IEEE.","Author Keywords":"machine learning; poverty; remote sensing; slums","Authors":"Engstrom R., Pavelesku D., Tanaka T., Wambile A.","DOI":"10.1109\/JURSE.2019.8809052","x":13.03,"y":4.08},{"HDBSCAN_Cluster":0,"DocId":374,"Cited by":26.0,"Year":2019,"Document Type":"Article","Title":"Spatiotemporal detection of land use\/land cover change in the large basin using integrated approaches of remote sensing and GIS in the Upper Awash basin, Ethiopia","Abstract":"Assessment of the changing environmental conditions is essential for planning the wise use of natural resources. The main objective of this paper is to analyze the historical and future modeled LULC changes using multi-temporal Landsat images in the Upper Awash basin, Ethiopia. The supervised image classification method was used to determine the historical LULC changes based on Landsat 1 MSS 1972, Landsat 5 TM 1984, Landsat 7 ETM + 2000, and Landsat 8 OLI TIRS 2014. The future LULC change was predicted using the machine-learning approaches of Land Change Modeler (LCM). The LULC change detection analysis exhibited significant increment in the areal extent of the cropland and urban areas, and decreasing trends in the pasture, forests and shrubland coverage. Mainly, the LULC change matrices indicated that larger conversion rate was observed from shrubland to cropland area. The urban area found to increase by 606.2% from the year 1972 to 2014 and cropland has also increased by 47.3%. Whereas, a decreasing trend was obtained in the forest by \u2212\u00a025.1%, pasture \u2212 87.4%, shrubland \u2212 28.8% and water \u2212 21.0% in the same period. The modeled future LULC change scenarios of the year 2025 and 2035 have exhibited significant expansion of cropland and urban areas at the expense of forest, pasture and shrubland areas. The study has revealed the extent and the rate of LULC change at larger basin and subbasin level which can be useful for knowledge-based future land management practice in the Upper Awash basin. \u00a9 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Author Keywords":"Agricultural expansion; Classification accuracy; Land change modeler; Land cover change; Upper Awash basin; Urban sprawl","Authors":"Shawul A.A., Chakma S.","DOI":"10.1007\/s12665-019-8154-y","x":14.08,"y":3.34},{"HDBSCAN_Cluster":-1,"DocId":378,"Cited by":21.0,"Year":2019,"Document Type":"Article","Title":"Multiscale road centerlines extraction from high-resolution aerial imagery","Abstract":"Accurate road extraction from high-resolution aerial imagery has many applications such as urban planning and vehicle navigation system. The common road extraction methods are based on classification algorithm, which needs to design robust handcrafted features for road. However, designing such features is difficult. For the road centerlines extraction problem, the existing algorithms have some limitations, such as spurs, time consuming. To address the above issues to some extent, we introduce the feature learning based on deep learning to extract robust features automatically, and present a method to extract road centerlines based on multiscale Gabor filters and multiple directional non-maximum suppression. The proposed algorithm consists of the following four steps. Firstly, the aerial imagery is classified by a pixel-wise classifier based on convolutional neural network (CNN). Specifically, CNN is used to learn features from raw data automatically, especially the structural features. Then, edge-preserving filtering is conducted on the resulting classification map, with the original imagery serving as the guidance image. It is exploited to preserve the edges and the details of the road. After that, we do some post-processing based on shape features to extract more reliable roads. Finally, multiscale Gabor filters and multiple directional non-maximum suppression are integrated to get a complete and accurate road network. Experimental results show that the proposed method can achieve comparable or higher quantitative results, as well as more satisfactory visual performance. \u00a9 2018 Elsevier B.V.","Author Keywords":"Centerlines extraction; Convolutional neural network (CNN); Edge-preserving filtering; Multiscale Gabor filters","Authors":"Liu R., Miao Q., Song J., Quan Y., Li Y., Xu P., Dai J.","DOI":"10.1016\/j.neucom.2018.10.036","x":15.23,"y":5.46},{"HDBSCAN_Cluster":1,"DocId":389,"Cited by":13.0,"Year":2019,"Document Type":"Conference Paper","Title":"Self-supervised feature learning for semantic segmentation of overhead imagery","Abstract":"Overhead imageries play a crucial role in many applications such as urban planning, crop yield forecasting, mapping, and policy making. Semantic segmentation could enable automatic, efficient, and large-scale understanding of overhead imageries for these applications. However, semantic segmentation of overhead imageries is a challenging task, primarily due to the large domain gap from existing research in ground imageries, unavailability of large-scale dataset with pixel-level annotations, and inherent complexity in the task. Readily available vast amount of unlabeled overhead imageries share more common structures and patterns compared to the ground imageries, therefore, its large-scale analysis could benefit from unsupervised feature learning techniques. In this work, we study various self-supervised feature learning techniques for semantic segmentation of overhead imageries. We choose image semantic inpainting as a self-supervised task [36] for our experiments due to its proximity to the semantic segmentation task. We (i) show that existing approaches are inefficient for semantic segmentation, (ii) propose architectural changes towards self-supervised learning for semantic segmentation, (iii) propose an adversarial training scheme for self-supervised learning by increasing the pretext task's difficulty gradually and show that it leads to learning better features, and (iv) propose a unified approach for overhead scene parsing, road network extraction, and land cover estimation. Our approach improves over training from scratch by more than 10% and ImageNet pre-trained network by more than 5% mIOU. \u00a9 2018. The copyright of this document resides with its authors.","Author Keywords":null,"Authors":"Singh S., Batra A., Pang G., Torresani L., Basu S., Paluri M., Jawahar C.V.","DOI":null,"x":16.0,"y":5.7},{"HDBSCAN_Cluster":0,"DocId":391,"Cited by":2.0,"Year":2019,"Document Type":"Conference Paper","Title":"Land cover classification and change detection analysis of multispectral satellite images using machine learning","Abstract":"Land cover classification and change detection analysis based on remote sensing images using machine learning algorithm has become one of the important factors for environmental management and urban planning. We select Yangon as the study area because the government faces many problems in urban planning sectors due to the population growth and urban sprawl. Therefore, the proposed method aims to perform the land cover classification in Yangon using Random Forest (RF) classifier in Google Earth Engine (GEE) and post-classification change detection between 1987 and 2017 with 5 years interval periods are evaluated. Despite land cover classifications using satellite imagery have been executed in the past decades, the classification of remotely sensed data integrating with multiple spectral, temporal and textural features and processing time for classification using time series data still have limitations. To overcome these limitations, features extracted from Sentinel-2, Landsat-8, Landsat-7, Landsat-5 and Open Street Map (OSM) are executed for classification and cloud-based GEE platform is used to reduce the processing time. Some spectral indexes such as NDVI, NDBI and slope from SRTM are calculated to achieve better classification. Land cover classification is performed by using the RF classifier with the different bands' combination. Land cover classification map with 7 classes (Shrub Land, Bare Land, Forest, Vegetation, Urban Area, Lake and River) is obtained with the overall accuracy of 96.73% and kappa statistic of 0.95 for 2017. Finally, change detection analysis over 30 years is performed and the significant changes in build-up, bare land, and agriculture have been resulted. \u00a9 2019 SPIE.","Author Keywords":"Change detection; Classification; Google Earth Engine; Land cover; Machine learning; Random forest","Authors":"Soe Thwal N., Ishikawa T., Watanabe H.","DOI":"10.1117\/12.2532988","x":14.2,"y":4.09},{"HDBSCAN_Cluster":-1,"DocId":393,"Cited by":3.0,"Year":2019,"Document Type":"Conference Paper","Title":"Multi-scale correlation-based feature selection and random forest classification for LULC mapping from the integration of SAR and optical Sentinel images","Abstract":"Reliable and accurate land use\/land cover (LULC) map is a crucial data source for the understanding of coupled human-environment systems, monitoring changes, timely low-cost planning, and management of natural resources. Improvements in sensor technologies and machine learning capabilities have shifted the attention of remote sensing community to data complementarity through fusion of multi-sensor data for accurate feature extraction and mapping. Amalgamation of optical and synthetic aperture radar (SAR) images has shown promising advantages in enhancing the accuracy of extracting LULC as such method allows exploitation of information in sensors. This study investigated the potential of using freely available multisource Sentinel images to extract LULC maps in semi-arid environments through multi-scale geographic object-based image analysis (GEOBIA). A multi-scale classification framework that integrates GEOBIA, correlation-based feature selection (CFS), and random forest (RF)-supervised classification was adopted to extract LULC from assimilation of Sentinel multi-sensor products. First, Sentinel-1 and-2 images were pre-processed. Second, optimum multi-scale segmentation levels were selected using F-score segmentation quality measures. Third, 70 features of various spectral indices and derivatives and geometrical features from optical data and multiple ratios and textural features from dual-polarization SAR images were computed, and a CFS based on wrapper approach was used to select the most significant features at multi-scale levels. Finally, a single and multi-scale RF classifier was used to extract LULC classes using the most relevant features extracted from Sentinel SAR and optical images. Results of multi-scale image segmentation optimization showed that scale parameter (SP) values of 40, 60, and 150 were optimal for extraction of LULC classes. Results of feature selection showed that 22, 24, and 27 features were selected at scale SP values of 40, 60, and 150, respectively. Half of the features were common among the three scales. Single RF classification yielded overall accuracy (OA) values of 92.10%, 93%, and 91% and kappa coefficients of 0.901, 0.912, and 0.89 at scale values of 150, 60, and 40, respectively. Multiscale RF classification from scale values of 150 and 60 produced better LULC classification with OA 96.06% and kappa coefficient of 0.95 compared with other scale SP values. The integrated approach demonstrated an effective and promising method for high-quality LULC extraction from coupling optical and SAR images. Overall, multi-sensor Sentinel images along with the adopted approach feature a remarkable potential for improving LULC extraction and can effectively be used to update geographic information system layers for various applications. \u00a9 2019 SPIE.","Author Keywords":"data fusion; image segmentation optimization; LULC; object-based classification; Optical sensors; SAR","Authors":"Al-Ruzouq R., Shanableh A., Gibril M.B., Kalantar B.","DOI":"10.1117\/12.2533123","x":14.51,"y":4.07},{"HDBSCAN_Cluster":1,"DocId":398,"Cited by":3.0,"Year":2019,"Document Type":"Conference Paper","Title":"A big remote sensing data analysis using deep learning framework","Abstract":"Spaceborne and airborne sensors deliver a huge number of Earth Observation Data every day. In this context, we can easily observe the whole earth from its different sides. Therefore, this big data is important in remote sensing and could be exploited in several domains requiring image classification, natural hazard monitoring, global climate change, agriculture, urban planning. Over the last five years, Convolutional Neural Networks (CNN) emerged as the most successful technique for the image classification task, as well as a number of other computer vision tasks. However, to train millions of parameters in CNN one requires a huge amount of annotated data. This requirement leads to a significant challenge if the available training data is limited for a target task at hand. To address this challenge, in the recent literature, researchers proposed various ways to apply a technique called Transfer Learning to transfer the knowledge gained by training CNNs parameters on some large annotated dataset to the target task with limited availability of training data. Most of our work in this paper was dedicated to proposing a hybrid classification of remote sensing images. This architecture combines Spark RDD image coding to consider image's local regions, pre-trained VGGNET-16 and UNET for image segmentation and SVM (Support Vector Machines) from spark Machine Learning to achieve labeling task. \u00a9 Multi Conference on Computer Science and Information Systems, MCCSIS 2019. All rights reserved.","Author Keywords":"Big Data; Deep Learning; Feature extraction; Multi-label Classification; Remote Sensing; Support Vector Machines","Authors":"Balti H., Chebbi I., Mellouli N., Farah I.R., Lamolle M.","DOI":"10.33965\/bigdaci2019_201907l015","x":16.11,"y":4.72},{"HDBSCAN_Cluster":-1,"DocId":405,"Cited by":30.0,"Year":2019,"Document Type":"Article","Title":"Support Vector Machine accuracy assessment for extracting green urban areas in towns","Abstract":"The most commonly used model for analyzing satellite imagery is the Support Vector Machine (SVM). Since there are a large number of possible variables for use in SVM, this paper will provide a combination of parameters that fit best for extracting green urban areas from Copernicus mission satellite images. This paper aims to provide a combination of parameters to extract green urban areas with the highest degree of accuracy, in order to speed up urban planning and ultimately improve town environments. Two different towns in Croatia were investigated, and the results provide an optimal combination of parameters for green urban areas extraction with an overall kappa index of 0.87 and 0.89, which demonstrates a very high classification accuracy. \u00a9 2019 by the authors.","Author Keywords":"Green urban areas extraction; Kernels; Machine learning; Satellite images; Support vector machine","Authors":"Kranj\u010di\u0107 N., Medak D., \u017dupan R., Rezo M.","DOI":"10.3390\/rs11060655","x":13.98,"y":4.78},{"HDBSCAN_Cluster":1,"DocId":418,"Cited by":34.0,"Year":2019,"Document Type":"Article","Title":"Building extraction from LiDAR data applying deep convolutional neural networks","Abstract":"Deep learning paradigm has been shown to be a very efficient classification framework for many application scenarios, including the analysis of Light Detection and Ranging (LiDAR) data for building detection. In fact, deep learning acts as a set of mathematical transformations, encoding the raw input data into appropriate forms of representations that maximize the classification performance. However, it is clear that mathematical computations alone, even highly nonlinear, are not adequate to model the physical properties of a problem, distinguishing, for example, the building structures from vegetation. In this letter, we address this difficulty by augmenting the raw LiDAR data with features coming from a physical interpretation of the information. Then, we exploit a deep learning paradigm based on a convolutional neural network model to find out the best input representations suitable for the classification. As test sites, three complex urban study areas with various kinds of building structures through the LiDAR data set of Vaihingen, Germany were selected. Our method has been evaluated in the context of 'ISPRS Test Project on Urban Classification and 3-D Building Reconstruction.' Comparisons with traditional methods, such as artificial neural networks and support vector machine-based classifiers, indicate the outperformance of the proposed approach in terms of robustness and efficiency. \u00a9 2004-2012 IEEE.","Author Keywords":"Building classification; convolutional neural networks (CNNs); Light Detection and Ranging (LiDAR); machine learning; point cloud","Authors":"Maltezos E., Doulamis A., Doulamis N., Ioannidis C.","DOI":"10.1109\/LGRS.2018.2867736","x":15.4,"y":6.31},{"HDBSCAN_Cluster":0,"DocId":420,"Cited by":2.0,"Year":2018,"Document Type":"Article","Title":"Accelerated exploration for long-term urban water infrastructure planning through machine learning","Abstract":"In this study, the neural network method (Multi-Layer Perceptron, MLP) was integrated with an explorative model, to study the feasibility of using machine learning to reduce the exploration time but providing the same support in long-term water system adaptation planning. The specific network structure and training pattern were determined through a comprehensive statistical trial-and-error (considering the distribution of errors). The network was applied to the case study in Scotchman's Creek, Melbourne. The network was trained with the first 10% of the exploration data, validated with the following 5% and tested on the rest. The overall root-mean-square-error between the entire observed data and the predicted data is 10.5722, slightly higher than the validation result (9.7961), suggesting that the proposed trial-and-error method is reliable. The designed MLP showed good performance dealing with spatial randomness from decentralized strategies. The adoption of MLP-supported planning may overestimate the performance of candidate urban water systems. By adopting the safety coefficient, a multiplicator or exponent calculated by observed data and predicted data in the validation process, the overestimation problem can be controlled in an acceptable range and have few impacts on final decision making. \u00a9 2018 by the authors.","Author Keywords":"Adaptation planning; Artificial neural network; Multi-layer perception; Urban planning; Water infrastructure","Authors":"Zhang J., Fu D., Urich C., Singh R.P.","DOI":"10.3390\/su10124600","x":12.44,"y":2.52},{"HDBSCAN_Cluster":0,"DocId":426,"Cited by":22.0,"Year":2018,"Document Type":"Article","Title":"Predicting multiple land use transitions under rapid urbanization and implications for land management and urban planning: The case of Zhanggong District in central China","Abstract":"Numerous machine learning-based land change models have been presented by researchers over the last two decades. To date, however, far less have simulated multiple land use classes and specific land use subclasses at the same time. In some areas of the world, it is important to simulate both of these dynamics to understand fully the drivers and consequences of land change. One important example is the process of urbanization in China, as urban policies have been developed that guide urban expansion, rural protections, and urban subclass development. This paper presents a new model integrating geographic information systems (GIS) with artificial neural networks (ANNs) to predict multiple transitions among land use types and urban subclasses in the Zhanggong District of Ganzhou city in China. We show that the model produces satisfactory goodness of fit values-based on location, quantity and spatial configuration-between simulated and observed land use maps for 2015. Our simulated future maps produced by the model for 2020 and 2025 demonstrate that transitions from farmland and forest to urban will remain the main pathway of urbanization although we predict that the rate will slow after 2025. The goals of urban planning should be aligned with land use planning according to \u201cCombining multiple laws and regulations\u201d in China. Taking into account the current and future land use transitions will enhance the accuracy and timeliness of land use policy making and urban land planning. For the sustainable land use in Zhanggong District, we argue for a strengthened regulation of the land market by government and believe that planning officials should guide the spatial distribution of land supply actively. Furthermore, improving the production, living and ecological functions of land resources are the key points to optimize urban land use functions and the allocation of land resources. We discuss how our model can be adapted to other areas to benefit land use management and urban planning in China. \u00a9 2018 Elsevier Ltd","Author Keywords":"Artificial neural networks; China; Land use management; Multiple land use transitions; Urban planning; Urbanization","Authors":"Wang L., Pijanowski B., Yang W., Zhai R., Omrani H., Li K.","DOI":"10.1016\/j.habitatint.2018.08.007","x":11.97,"y":3.06},{"HDBSCAN_Cluster":-1,"DocId":427,"Cited by":17.0,"Year":2018,"Document Type":"Article","Title":"Progressively Expanded Neural Network (PEN Net) for hyperspectral image classification: A new neural network paradigm for remote sensing image analysis","Abstract":"Hyperspectral image (HSI) has been used for a wide range of applications including forestry, urban planning, and precision agriculture. In recent years, machine learning based algorithms, such as support vector machines, decision trees, ensemble learning, and their variations have shown promising results in HSI analysis. Such methodologies, nevertheless, can lead to insufficient information abstraction in interpreting hyperspectral pixels. In this paper, we propose a novel neural network based classification algorithm, named Progressively Expanded Neural Network (PEN Net), that can effectively interpret hyperspectral pixels in nonlinear feature spaces and then determine their categories. Furthermore, a spectral-spatial HSI classification framework is also introduced to test the generality and robustness of the PEN Net. Experimental results on four standard hyperspectral datasets illustrate that: (1) PEN Net classifier yields better accuracy and competitive processing speed in HSI classification tasks compared to the state-of-the-art methods; (2) Multi-hidden layer based PEN Net generally provides better performance than single hidden layer one; (3) Combination of spectral and spatial features in the PEN Net classifier can significantly improve the classification accuracy by 6\u201315% compared to the spectral only based HSI classification. This study implies that the proposed neural network architecture opens a new window for future research and the potential for remote sensing image analysis. \u00a9 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"Classification; Hyperspectral image (HSI); Machine learning; Neural network; Remote sensing","Authors":"Sidike P., Asari V.K., Sagan V.","DOI":"10.1016\/j.isprsjprs.2018.09.007","x":15.32,"y":4.31},{"HDBSCAN_Cluster":0,"DocId":436,"Cited by":36.0,"Year":2018,"Document Type":"Article","Title":"Mining transition rules of cellular automata for simulating urban expansion by using the deep learning techniques","Abstract":"Along with the gradually accelerated urbanization process, simulating and predicting the future pattern of the city is of great importance to the prediction and prevention of some environmental, economic and urban issues. Previous studies have generally integrated traditional machine learning with cellular automaton (CA) models to simulate urban development. Nevertheless, difficulties still exist in the process of obtaining more accurate results with CA models; such difficulties are mainly due to the insufficient consideration of neighborhood effects during urban transition rule mining. In this paper, we used an effective deep learning method, named convolution neural network for united mining (UMCNN), to solve the problem. UMCNN has substantial potential to get neighborhood information from its receptive field. Thus, a novel CA model coupled with UMCNN and Markov chain was designed to improve the performance of simulating urban expansion processes. Choosing the Pearl River Delta of China as the study area, we excavate the driving factors and the transformational relations revealed by the urban land-use patterns in 2000, 2005 and 2010 and further simulate the urban expansion status in 2020 and 2030. Additionally, three traditional machine-learning-based CA models (LR, ANN and RFA) are built to attest the practicality of the proposed model. In the comparison, the proposed method reaches the highest simulation accuracy and landscape index similarity. The predicted urban expansion results reveal that the economy will continue to be the primary factor in the study area from 2010 to 2030. The proposed model can serve as guidance in urban planning and government decision-making. \u00a9 2018, \u00a9 2018 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"cellular automata; deep learning; large scale; Markov chain; Urban expansion","Authors":"He J., Li X., Yao Y., Hong Y., Jinbao Z.","DOI":"10.1080\/13658816.2018.1480783","x":11.66,"y":2.96},{"HDBSCAN_Cluster":-1,"DocId":437,"Cited by":12.0,"Year":2018,"Document Type":"Article","Title":"Ultra-Light aircraft-based hyperspectral and colour-infrared imaging to identify deciduous tree species in an urban environment","Abstract":"One may consider the application of remote sensing as a trade-off between the imaging platforms, sensors, and data gathering and processing techniques. This study addresses the potential of hyperspectral imaging using ultra-light aircraft for vegetation species mapping in an urban environment, exploring both the engineering and scientific aspects related to imaging platform design and image classification methods. An imaging system based on simultaneous use of Rikola frame format hyperspectral and Nikon D800E adopted colour infrared cameras installed onboard a Bekas X32 manned ultra-light aircraft is introduced. Two test imaging flight missions were conducted in July of 2015 and September of 2016 over a 4000 ha area in Kaunas City, Lithuania. Sixteen and 64 spectral bands in 2015 and 2016, respectively, in a spectral range of 500-900 nm were recorded with colour infrared images. Three research questions were explored assessing the identification of six deciduous tree species: (1) Pre-treatment of spectral features for classification, (2) testing five conventional machine learning classifiers, and (3) fusion of hyperspectral and colour infrared images. Classification performance was assessed by applying leave-one-out cross-validation at the individual crown level and using as a reference at least 100 field inventoried trees for each species. The best-performing classification algorithm-multilayer perceptron, using all spectral properties extracted from the hyperspectral images-resulted in a moderate classification accuracy. The overall classification accuracy was 63%, Cohen's Kappa was 0.54, and the species-specific classification accuracies were in the range of 51-72%. Hyperspectral images resulted in significantly better tree species classification ability than the colour infrared images and simultaneous use of spectral properties extracted from hyperspectral and colour infrared images improved slightly the accuracy over the 2015 image. Even though classifications using hyperspectral data cubes of 64 bands resulted in relatively larger accuracies than with 16 bands, classification error matrices were not statistically different. Alternative imaging platforms (like an unmanned aerial vehicle and a Cessna 172 aircraft) and settings of the flights were discussed using simulated imaging projects assuming the same study area and field of application. Ultra-light aircraft-based hyperspectral and colour-infrared imaging was considered to be a technically and economically sound solution for urban green space inventories to facilitate tree mapping, characterization, and monitoring. \u00a9 2018 by the authors.","Author Keywords":"Classification; Colour infrared; Hyperspectral; Ultra-light aircraft; Urban trees","Authors":"Mozgeris G., Juodkiene V., Jonikavi\u010dius D., Straigyte L., Gadal S., Ouerghemmi W.","DOI":"10.3390\/rs10101668","x":14.7,"y":4.51},{"HDBSCAN_Cluster":-1,"DocId":443,"Cited by":18.0,"Year":2018,"Document Type":"Article","Title":"Road centerline extraction from very-high-resolution aerial image and LiDAR data based on road connectivity","Abstract":"The road networks provide key information for a broad range of applications such as urban planning, urban management, and navigation. The fast-developing technology of remote sensing that acquires high-resolution observational data of the land surface offers opportunities for automatic extraction of road networks. However, the road networks extracted from remote sensing images are likely affected by shadows and trees, making the road map irregular and inaccurate. This research aims to improve the extraction of road centerlines using both very-high-resolution (VHR) aerial images and light detection and ranging (LiDAR) by accounting for road connectivity. The proposed method first applies the fractal net evolution approach (FNEA) to segment remote sensing images into image objects and then classifies image objects using the machine learning classifier, random forest. A post-processing approach based on the minimum area bounding rectangle (MABR) is proposed and a structure feature index is adopted to obtain the complete road networks. Finally, a multistep approach, that is, morphology thinning, Harris corner detection, and least square fitting (MHL) approach, is designed to accurately extract the road centerlines from the complex road networks. The proposed method is applied to three datasets, including the New York dataset obtained from the object identification dataset, the Vaihingen dataset obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D semantic labelling benchmark and Guangzhou dataset. Compared with two state-of-the-art methods, the proposed method can obtain the highest completeness, correctness, and quality for the three datasets. The experiment results show that the proposed method is an efficient solution for extracting road centerlines in complex scenes from VHR aerial images and light detection and ranging (LiDAR) data. \u00a9 2018 by the authors.","Author Keywords":"LiDAR data; Object recognition; Road centerline; Road connectivity; Very-high-resolution image","Authors":"Zhang Z., Zhang X., Sun Y., Zhang P.","DOI":"10.3390\/rs10081284","x":14.87,"y":5.47},{"HDBSCAN_Cluster":-1,"DocId":444,"Cited by":7.0,"Year":2018,"Document Type":"Article","Title":"Context-Based Filtering of Noisy Labels for Automatic Basemap Updating from UAV Data","Abstract":"Unmanned aerial vehicles (UAVs) have the potential to obtain high-resolution aerial imagery at frequent intervals, making them a valuable tool for urban planners who require up-to-date basemaps. Supervised classification methods can be exploited to translate the UAV data into such basemaps. However, these methods require labeled training samples, the collection of which may be complex and time consuming. Existing spatial datasets can be exploited to provide the training labels, but these often contain errors due to differences in the date or resolution of the dataset from which these outdated labels were obtained. In this paper, we propose an approach for updating basemaps using global and local contextual cues to automatically remove unreliable samples from the training set, and thereby, improve the classification accuracy. Using UAV datasets over Kigali, Rwanda, and Dar es Salaam, Tanzania, we demonstrate how the amount of mislabeled training samples can be reduced by 44.1% and 35.5%, respectively, leading to a classification accuracy of 92.1% in Kigali and 91.3% in Dar es Salaam. To achieve the same accuracy in Dar es Salaam, between 50000 and 60000 manually labeled image segments would be needed. This demonstrates that the proposed approach of using outdated spatial data to provide labels and iteratively removing unreliable samples is a viable method for obtaining high classification accuracies while reducing the costly step of acquiring labeled training samples. \u00a9 2008-2012 IEEE.","Author Keywords":"Basemap updating; image classification; informal settlements; label noise; random forests; unmanned aerial vehicles (UAVs); urban planning","Authors":"Gevaert C.M., Persello C., Elberink S.O., Vosselman G., Sliuzas R.","DOI":"10.1109\/JSTARS.2017.2762905","x":15.03,"y":4.93},{"HDBSCAN_Cluster":-1,"DocId":452,"Cited by":1.0,"Year":2018,"Document Type":"Conference Paper","Title":"Application of machine learning in urban greenery land cover extraction","Abstract":"Urban greenery is a critical part of the modern city and the greenery coverage information is essential for land resource management, environmental monitoring and urban planning. It is a challenging work to extract the urban greenery information from remote sensing image as the trees and grassland are mixed with city built-ups. In this paper, we propose a new automatic pixel-based greenery extraction method using multispectral remote sensing images. The method includes three main steps. First, a small part of the images is manually interpreted to provide prior knowledge. Secondly, a five-layer neural network is trained and optimised with the manual extraction results, which are divided to serve as training samples, verification samples and testing samples. Lastly, the well-trained neural network will be applied to the unlabelled data to perform the greenery extraction. The GF-2 and GJ-1 high resolution multispectral remote sensing images were used to extract greenery coverage information in the built-up areas of city X. It shows a favourable performance in the 619 square kilometers areas. Also, when comparing with the traditional NDVI method, the proposed method gives a more accurate delineation of the greenery region. Due to the advantage of low computational load and high accuracy, it has a great potential for large area greenery auto extraction, which saves a lot of manpower and resources. \u00a9 Authors 2018. CC BY 4.0 License.","Author Keywords":"Auto extraction; Greenery land cover; Machine learning; Multispectral image; Neural network","Authors":"Qiao X., Li L.L., Li D., Gan Y.L., Hou A.Y.","DOI":"10.5194\/isprs-archives-XLII-3-1409-2018","x":14.47,"y":4.47},{"HDBSCAN_Cluster":0,"DocId":458,"Cited by":29.0,"Year":2018,"Document Type":"Article","Title":"A Random Forests classification method for urban land-use mapping integrating spatial metrics and texture analysis","Abstract":"Rapid urban growth in developing countries is causing a great number of urban planning problems. To control and analyse this growth, new and better methods for urban land use mapping are needed. This article proposes a new method for urban land-use mapping, which integrates spatial metrics and texture analysis in an object-based image analysis classification. A high-resolution satellite image was used to generate spatial and texture metrics from the machine learning algorithm of Random Forests landcover classification. The most meaningful spatial indices were selected by visual inspection and then combined with the image and texture values to generate the classification. The proposed method for land-use mapping was tested using a 10-fold crossvalidation scheme, achieving an overall accuracy of 92.3% and a kappa coefficient of 0.896. These steps produced an accurate model of urban land use, without the use of any census or ancillary data, and suggest that the combined use of spatial metrics and texture is promising for urban land-use mapping in developing countries. The maps produced can provide the landuse data needed by urban planners for effective planning in developing countries. \u00a9 2017 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Ruiz Hernandez I.E., Shi W.","DOI":"10.1080\/01431161.2017.1395968","x":13.86,"y":4.15},{"HDBSCAN_Cluster":1,"DocId":460,"Cited by":12.0,"Year":2018,"Document Type":"Article","Title":"Object-based detection of vehicles using combined optical and elevation data","Abstract":"The detection of vehicles is an important and challenging topic that is relevant for many applications. In this work, we present a workflow that utilizes optical and elevation data to detect vehicles in remotely sensed urban data. This workflow consists of three consecutive stages: candidate identification, classification, and single vehicle extraction. Unlike in most previous approaches, fusion of both data sources is strongly pursued at all stages. While the first stage utilizes the fact that most man-made objects are rectangular in shape, the second and third stages employ machine learning techniques combined with specific features. The stages are designed to handle multiple sensor input, which results in a significant improvement. A detailed evaluation shows the benefits of our workflow, which includes hand-tailored features; even in comparison with classification approaches based on Convolutional Neural Networks, which are state of the art in computer vision, we could obtain a comparable or superior performance (F1 score of 0.96\u20130.94). \u00a9 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Author Keywords":"Cluster analysis; Data fusion; Elevation data; Feature extraction; High-resolution; Object-based classification; Random forest; Vehicle detection","Authors":"Schilling H., Bulatov D., Middelmann W.","DOI":"10.1016\/j.isprsjprs.2017.11.023","x":15.55,"y":5.6},{"HDBSCAN_Cluster":1,"DocId":462,"Cited by":458.0,"Year":2018,"Document Type":"Article","Title":"Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework","Abstract":"In this paper, we designed an end-to-end spectral-spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia. \u00a9 1980-2012 IEEE.","Author Keywords":"3-D deep learning; hyperspectral image classification; spectral-spatial feature extraction; spectral-spatial residual network (SSRN)","Authors":"Zhong Z., Li J., Luo Z., Chapman M.","DOI":"10.1109\/TGRS.2017.2755542","x":15.91,"y":4.66},{"HDBSCAN_Cluster":1,"DocId":463,"Cited by":1.0,"Year":2018,"Document Type":"Article","Title":"Building detection from orthophotos using binary feature classification","Abstract":"Building detection in orthophotos is crucial for various applications, such as urban planning and real-estate management. In order to realize accurate and fast building detection, a non-interactive approach based on binary feature classification is brought forward in this paper. The proposed approach includes two major stages, i.e., building area detection and building contours extraction. In the first stage, a sequence of intersections is obtained by superpixel segmentation in the subsampled orthophoto, and then building area is reserved roughly according to the classification of intersections. In the second stage, the sequence of intersections is updated by superpixel segmentation in the building area from original orthophoto, and then building contours is extracted in accordance with the classification of intersections likewise. The local feature of the intersections is descripted employing our extremely compact binary descriptor, and is classified using binary bag-of-features. Experiments show that benefiting from binary description and making full use of texture details and color channels, the proposed descriptor is not only computationally frugal, but also accurate. Experiments are also conducted on orthophotos with different roof colors, textures, shapes, sizes and orientations, and demonstrate that the proposed approach are capable of achieving desirable results. \u00a9 2017, Springer Science+Business Media, LLC.","Author Keywords":"Building detection; Classifier; Descriptor; Local feature; Machine learning","Authors":"Hu Y., Hu X., Li P., Ding Y.","DOI":"10.1007\/s11042-017-5093-z","x":14.95,"y":5.86},{"HDBSCAN_Cluster":0,"DocId":464,"Cited by":null,"Year":2018,"Document Type":"Conference Paper","Title":"Urban sprawl modeling of Lahore, Pakistan using machine learning techniques","Abstract":"Population is the fundamental concentration because population is related with all resources and urban sprawl, an effect of socioeconomic improvement in specific conditions, has progressively turned into a noteworthy issue confronting numerous metropolitan zones. This is very essential to understand the significant factors affecting the population. This research analyzed the spatial and temporal characteristics of metropolitan city Lahore, Pakistan. Supervised classification method is applied to examine the urban expansion and to evaluate signatures of Lahore city into four categories (urban, vegetation, bare land and water bodies). For the land cover change analysis and to predict the urban sprawl in future different techniques and methods can be used and out of numerous, geospatial techniques like (MOLUSCE) QGIS plug-in, GIS along with remote sensing is used. In this study, Landsat V and VIII satellite images of 1998, 2008 and 2017 were used to classify the urban expansion. The precision appraisal was completed for characterized maps. Distinctive images Transition probability matrix and region change were acquired by utilizing plug-in created in QGIS and future year 2036 urban expansion was obtained. In this study, an attempt was made to develop a relationship between urban sprawl and population of Lahore. In light of accessible informational index, from 2017 to 2036 the change in urban area is 40% while a 367.02 sq.km loss in vegetation is chronicled. The majority of the urban sprawl occurred along primary roadways. The outcome demonstrates that urban region is relied upon to develop substantially higher in the year 2036 when contrasted with 2017. This analysis gives awareness of urban development and supports in macro and micro level urban planning, policy making in metropolitan cities. \u00a9 2018 Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018","Author Keywords":"GIS; Land Use and Land Cover; Landsat; Population; Remote Sensing","Authors":"Ahmed A., Sekimoto Y., Kashiyama T.","DOI":null,"x":12.42,"y":3.45},{"HDBSCAN_Cluster":1,"DocId":469,"Cited by":2.0,"Year":2018,"Document Type":"Conference Paper","Title":"Understanding Historical Cityscapes from Aerial Imagery Through Machine Learning","Abstract":"Understanding cityscapes using remote sensing data has been an active research field for more than two decades. Meanwhile, machine learning provides generalization capabilities compared to hierarchical and rule-based methods. This paper evaluates several machine learning algorithms in order to fuse shadow detection and shadow compensation methods for building detection using high resolution aerial imagery. Three complex and real-life urban study areas were used as test datasets with various: (i) kinds of buildings structures of special architecture, (ii) pixel resolutions and, (iii) types of data. Objective evaluation metrics have been used for assessing the compared algorithms such recall, precision and F1-score as well as rates of completeness, correctness and quality. For both approaches, i.e., shadow detection and building detection, the computational complexity of each machine learning algorithm was examined. The results indicate that deep learning schemes, such a Convolutional Neural Network (CNN), provides the best classification performance in terms of shadow detection and building detection. \u00a9 2018, Springer Nature Switzerland AG.","Author Keywords":"Building detection; Machine learning; Point cloud; Shadow compensation; Shadow detection","Authors":"Maltezos E., Protopapadakis E., Doulamis N., Doulamis A., Ioannidis C.","DOI":"10.1007\/978-3-030-01762-0_17","x":15.5,"y":6.05},{"HDBSCAN_Cluster":1,"DocId":473,"Cited by":null,"Year":2018,"Document Type":"Conference Paper","Title":"Automatic semantic segmentation for change detection in remote sensing images","Abstract":"Change detection (CD) mainly focuses on the extraction of change information from multispectral remote sensing images of the same geographical location for environmental monitoring, natural disaster evaluation, urban studies, and deforestation monitoring. While capturing the Landsat imagery, there may occur data missing issues such as occlusion of cloud, camera sensor, and aperture artifacts. The existing machine learning approaches do not provide significant results. This paper proposes a DeepLab Dilated convolutional neural network (DL-DCNN) for semantic segmentation with the goal to occur the change map for earth observation applications. Experimental results reveal that the accuracy of the proposed change detection results provides improved results as compared with the existing algorithms and maps the semantic objects within the predefined class as change or no change. \u00a9 Springer Nature Singapore Pte Ltd. 2018.","Author Keywords":"Change detection; Deep learning; Multispectral; Remote sensing","Authors":"Kulkarni T., Venugopal N.","DOI":"10.1007\/978-981-10-8569-7_34","x":16.52,"y":5.79},{"HDBSCAN_Cluster":0,"DocId":475,"Cited by":28.0,"Year":2018,"Document Type":"Article","Title":"Analyzing land cover change and urban growth trajectories of the mega-urban region of Dhaka using remotely sensed data and an ensemble classifier","Abstract":"Accurate information on, and human interpretation of, urban land cover using satellite-derived sensor imagery is critical given the intricate nature and niches of socioeconomic, demographic, and environmental factors occurring at multiple temporal and spatial scales. Detailed knowledge of urban land and their changing pattern over time periods associated with ecological risk is, however, required for the best use of critical land and its environmental resources. Interest in this topic has increased recently, driven by a surge in the use of open-source computing software, satellite-derived imagery, and improved classification algorithms. Using the machine learning algorithm Random Forest, combined with multi-date Landsat imagery, we classified eight periods of land cover maps with up-to-date spatial and temporal information of urban land between the period of 1972 and 2015 for the mega-urban region of greater Dhaka in Bangladesh. Random Forest-a non-parametric ensemble classifier-has shown a quantum increase in satellite-derived image classification accuracy due to its outperformance over traditional approaches, e.g., Maximum Likelihood. Employing Random Forest as an image classification approach for this study with independent cross-validation techniques, we obtained high classification accuracy, user and producer accuracy. Our overall classification accuracy ranges were between 85% and 97% with kappa values between 0.81 and 0.94. The area statistics derived from the thematic land cover map show that the built-up area in the 43-year study period expanded quickly, from 35 km2 in 1972 to 378 km2 in 2015, with a net increase rate of approximately 980% and an average annual growth rate of 6%. This growth rate, however, was higher in peripheral areas, with a 2903% increase and an annual expansion rate of 8%, compared to a 460% increase with an annual growth rate of 4% in the core city area (Dhaka City Corporation). This huge urban expansion took place in the north, northwest, and southwest regions of Dhaka, transforming areas that were previously agricultural land, vegetation cover, wetland, and water bodies. The main factors driving the city towards northern corridors include flood-free higher land, the availability of a transportation network, and the agglomeration of manufacturing-based employment centers. The resulting thematic map and spatial information produced from this study therefore serve to facilitate a detailed understanding of urban growth dynamics and land cover change patterns in the mega-urban region of Dhaka, Bangladesh. \u00a9 2017 by the authors.","Author Keywords":"Ensemble classifier; Greater Dhaka; Land cover change; Random forest; Remote sensing; Urban growth","Authors":"Hassan M.M., Southworth J.","DOI":"10.3390\/su10010010","x":13.62,"y":3.62},{"HDBSCAN_Cluster":-1,"DocId":476,"Cited by":61.0,"Year":2018,"Document Type":"Article","Title":"Exploring the optimal integration levels between SAR and optical data for better urban land cover mapping in the Pearl River Delta","Abstract":"Integrating synthetic aperture radar (SAR) and optical data to improve urban land cover classification has been identified as a promising approach. However, which integration level is the most suitable remains unclear but important to many researchers and engineers. This study aimed to compare different integration levels for providing a scientific reference for a wide range of studies using optical and SAR data. SAR data from TerraSAR-X and ENVISAT ASAR in both WSM and IMP modes were used to be combined with optical data at pixel level, feature level and decision levels using four typical machine learning methods. The experimental results indicated that: 1) feature level that used both the original images and extracted features achieved a significant improvement of up to 10% compared to that using optical data alone; 2) different levels of fusion required different suitable methods depending on the data distribution and data resolution. For instance, support vector machine was the most stable at both the feature and decision levels, while random forest was suitable at the pixel level but not suitable at the decision level. 3) By examining the distribution of SAR features, some features (e.g., homogeneity) exhibited a close-to-normal distribution, explaining the improvement from the maximum likelihood method at the feature and decision levels. This indicated the benefits of using texture features from SAR data when being combined with optical data for land cover classification. Additionally, the research also shown that combining optical and SAR data does not guarantee improvement compared with using single data source for urban land cover classification, depending on the selection of appropriate fusion levels and fusion methods. \u00a9 2017 Elsevier B.V.","Author Keywords":"Fusion level; Fusion strategies; Optical and SAR fusion; Urban land cover","Authors":"Zhang H., Xu R.","DOI":"10.1016\/j.jag.2017.08.013","x":14.63,"y":3.98},{"HDBSCAN_Cluster":-1,"DocId":478,"Cited by":5.0,"Year":2017,"Document Type":"Conference Paper","Title":"3D shape descriptor for objects recognition","Abstract":"3D point cloud classification is an important task in applications for many areas such as robotics, urban planning and augmented reality. 3D sensors measure a high amount of points in the 3D scene objects' surface at a high collect rate, so robust techniques are needed to process all input data and also deal with some imprecision. A common solution for these tasks is the use of robust features extraction techniques to gather representative scene information at the lowest computational cost possible. This paper presents a new approach for object recognition in 3D scenes, using a novel 3D shape descriptor which is used as input for a supervised machine learning method. Proposed robust 3D feature is invariant to translation and scale and provides a very simplified object representation for pattern recognition input. Experiments were performed using an Artificial Neural Network to recognize six different object shapes, and obtained results showed that the proposed method is a promising approach for object recognition in 3D scenes. \u00a9 2017 IEEE.","Author Keywords":"3D Feature Extraction; Object Classification; Pattern Recognition","Authors":"Sales D.O., Amaro J., Os\u00f3rio F.S.","DOI":"10.1109\/SBR-LARS-R.2017.8215285","x":14.72,"y":6.19},{"HDBSCAN_Cluster":-1,"DocId":479,"Cited by":7.0,"Year":2017,"Document Type":"Conference Paper","Title":"Deep highway unit network for land cover type classification with GF-3 SAR imagery","Abstract":"The fully polarized synthetic aperture radar (SAR) is an advanced earth observation system with day and night imaging capability, which can obtain rich information of terrain and has a wide range of applications in environmental protection, urban planning and resource investigation. As the first selfdeveloped C-band multi-polarized SAR image, the acquisition of massive data and operational operation of Chinese SAR remote sensing has entered the era of big data. Under the era of remote sensing large data, however, SAR image interpretation is a great challenge for scientific applications. At present, big data-based intelligent methods such as computer vision technology have achieved great success. Deep learning such as deep highway unit networks has revolutionized the computer vision area. However, due to the characteristics of SAR microwave band imaging and phase coherence processing, SAR images are very different from ordinary optical images in terms of band, projection direction, data composition and so on. Therefore, deep learning can not be directly used for quad-pol SAR image classification. In this paper, deep learning is applied to land cover type classification with GF-3 quad-pol SAR imagery. A deep highway unit network is employed to automatically extract a hierarchic feature representation from the data, based on which the land cover type classification can be conducted. Our classification model is trained on limited training data from forest resource inventory and planning data, and tested on a Radarsat-2 quad-pol images, which is the image of the same area acquired at different times. We also employ the machine learning such as SVM, Random Forest on the same samples for comparison. The deep highway unit network trained by the GF-3 images, which can reduce speckle, fully excavate the regularity of SAR images in time and space. \u00a9 2017 IEEE.","Author Keywords":"Deep highway unit networks; Deep learning; GaoFen-3; Land cover type classification","Authors":"Guo Y., Chen E., Guo Y., Li Z., Li C., Xu K.","DOI":"10.1109\/BIGSARDATA.2017.8124926","x":15.59,"y":4.47},{"HDBSCAN_Cluster":1,"DocId":490,"Cited by":83.0,"Year":2017,"Document Type":"Conference Paper","Title":"Using convolutional networks and satellite imagery to identify patterns in urban environments at a large scale","Abstract":"Urban planning applications (energy audits, investment, etc.) require an understanding of built infrastructure and its environment, i.e., both low-level, physical features (amount of vegetation, building area and geometry etc.), as well as higher-level concepts such as land use classes (which encode expert understanding of socioeconomic end uses). This kind of data is expensive and labor-intensive to obtain, which limits its availability (particularly in developing countries). We analyze patterns in land use in urban neighborhoods using large-scale satellite imagery data (which is available worldwide from third-party providers) and state-of-the-art computer vision techniques based on deep convolutional neural networks. For supervision, given the limited availability of standard benchmarks for remote-sensing data, we obtain ground truth land use class labels carefully sampled from open-source surveys, in particular the Urban Atlas land classification dataset of 20 land use classes across 300 European cities. We use this data to train and compare deep architectures which have recently shown good performance on standard computer vision tasks (image classification and segmentation), including on geospatial data. Furthermore, we show that the deep representations extracted from satellite imagery of urban environments can be used to compare neighborhoods across several cities. We make our dataset available for other machine learning researchers to use for remote-sensing applications. \u00a9 2017 Copyright held by the owner\/author(s).","Author Keywords":"Convolutional networks; Land use classification; Satellite imagery","Authors":"Albert A., Kaur J., Gonzalez M.C.","DOI":"10.1145\/3097983.3098070","x":15.63,"y":5.06},{"HDBSCAN_Cluster":0,"DocId":494,"Cited by":50.0,"Year":2017,"Document Type":"Article","Title":"Integrating the multi-label land-use concept and cellular automata with the artificial neural network-based Land Transformation Model: an integrated ML-CA-LTM modeling framework","Abstract":"Cellular automata (CA) and artificial neural networks (ANNs) have been used by researchers over the last three decades to simulate land-use change (LUC). While conventional CA and ANN models assign a cell to only one land-use class, in reality, a cell may belong to several land-use classes simultaneously. The recently developed multi-label (ML) concept overcomes this limitation in land change science. Although the ML concept is a new paradigm with nonexclusive classes and has shown considerable merit in several applications, few studies in land change science have applied it. In addition, determining transition rules in conventional CA is difficult when the number of drivers is large. Since CA has been shown as a potential model to consider neighborhood effects and ANN has been shown effective in determining CA transition rules, we integrated both CA with an ANN model to overcome limitations of each tool. In this study, we specifically extended the ANN-based Land Transformation Model (LTM) with both a CA-based model and the ML concept to create an integrated ML-CA-LTM modeling framework. We also compared, using standard evaluation measures, differences between the proposed integrated model with a conventional CA-based LTM model (called the ml-CA-LTM). Parameterization was made using a learning and testing procedure common in machine learning. Results showed that the modified LUC model, ML-CA-LTM, produced consistently better goodness of fit calibration values compared to the ml-CA-LTM. The outcome of this modified model can be used by managers and decision makers for improved urban planning. \u00a9 2017 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"arti\ufb01cial neural networks; cellular automata; land-use change; mono-label class; multi-label classes","Authors":"Omrani H., Tayyebi A., Pijanowski B.","DOI":"10.1080\/15481603.2016.1265706","x":11.92,"y":2.62},{"HDBSCAN_Cluster":-1,"DocId":496,"Cited by":4.0,"Year":2017,"Document Type":"Article","Title":"Urban areas extraction from multi sensor data based on machine learning and data fusion","Abstract":"Accurate urban areas information is important for a variety of applications, especially city planning and natural disaster prediction and management. In recent years, extraction of urban structures from remotely sensed images has been extensively explored. The key advantages of this imaging modality are reduction of surveying expense and time. It also elevates restrictions on ground surveys. Thus far, much research typically extracts these structures from very high resolution satellite imagery, which are unfortunately of relatively poor spectral resolution, resulting in good precision yet moderate accuracy. Therefore, this paper investigates extraction of buildings from middle and high resolution satellite images by using spectral indices (Normalized Difference Building Index: NDBI, Normalized Difference Vegetation Index: NDVI, Soil Adjustment Vegetation Index: SAVI, Modified Normalized Difference Index: MNDWI, and Global Environment Monitoring Index: GEMI) by means of various Machine Learning methods (Artificial Neural Network: ANN, K-Nearest Neighbor: KNN, and Support Vector Machine: SVM) and Data Fusion (i.e., Majority Voting). Herein empirical results suggested that suitable learning methods for urban areas extraction are in preferring order Data Fusion, SVM, KNN, and ANN. Their accuracies were 85.46, 84.86, 84.66, and 84.91%, respectively. \u00a9 2017, Pleiades Publishing, Ltd.","Author Keywords":"data fusion; machine learning; spectral indices; urban areas extraction","Authors":"Puttinaovarat S., Horkaew P.","DOI":"10.1134\/S1054661816040131","x":14.28,"y":5.12},{"HDBSCAN_Cluster":0,"DocId":497,"Cited by":40.0,"Year":2017,"Document Type":"Article","Title":"Land-cover classification and analysis of change using machine-learning classifiers and multi-temporal remote sensing imagery","Abstract":"Frequent human activity and rapid urbanization have led to an assortment of environmental issues. Monitoring land-cover change is critical to efficient environmental management and urban planning. The current study had two objectives. The first was to compare pixel-based random forest (RF) and decision tree (DT) classifier methods and a support vector machine (SVM) algorithm both in pixel-based and object-based approaches for classification of land-cover in a heterogeneous landscape for 2010. The second was to examine spatio-temporal land-cover change over the last two decades (1990\u20132010) using Landsat data. This study found that the object-based SVM classifier is the most accurate with an overall classification accuracy of 93.54% and a kappa value of 0.88. A post-classification change detection algorithm was used to determine the trend of change between land-cover classes. The most significant change from 1990 to 2010 was caused by the expansion of built-up areas. In addition to the net changes, the rate of annual change for each phenomenon was calculated to obtain a better understanding of the process of change. Between 1990 and 2010, an average of 4.53% of lands turned to the built-up annually and there was an annual decrease of about 0.81% in natural land. If the current trend of change continues, regardless of the actions of sustainable development, drastic declines in natural areas will ensue. The results of this study can be a valuable baseline for land-cover managers in the region to better understand the current situation and adopt appropriate strategies for management of land-cover. \u00a9 2017, Saudi Society for Geosciences.","Author Keywords":"Decision tree; Land-cover; Object-based; Random forest; Support vector machines","Authors":"Keshtkar H., Voigt W., Alizadeh E.","DOI":"10.1007\/s12517-017-2899-y","x":13.98,"y":3.5},{"HDBSCAN_Cluster":-1,"DocId":507,"Cited by":null,"Year":2017,"Document Type":"Conference Paper","Title":"A support vector machine approach on object based image analysis for feature extraction from high resolution images","Abstract":"Satellite images are the most important available data sources for generation and updating of available maps. They have highly improved in terms of spatial, spectral and temporal resolutions and by the sheer volume of collected images, the necessity of simplification of automation in feature extraction. Road data play a key role in urban planning, traffic management, military applications, and vehicle navigation as well as for decision making in numerous applications. The faster updation of road infrastructure is a need because the technology has brought map in the hands of people in the form of mobile phones and tablets. Road detection is one of the major issues of the road infrastructure extraction. Its accuracy depends on the type of methodology used. An attempt is made here to analyse the first order, the co-occurrence texture features and image transforms useful for discriminating roads from other features specially the buildings. The identified dataset forms high dimension feature space and the Support Vector Machine is a theoretically superior machine learning methodology with great results in classification of high dimensional datasets. In the past, SVMs have been tested and evaluated only as pixel-based image classifiers. Moving from pixel-based techniques towards object-based representation, the dimensions of remote sensing imagery feature space increases significantly. An SVM approach for classification was followed, based on primitive image objects produces by a multi-resolution segmentation algorithm. The SVM procedure produced the final object classification results which were compared to the Nearest Neighbor classifier results and were found to give better results in OBIA domain. \u00a9 2017 ACRS. All rights reserved.","Author Keywords":"Feature Extraction; Grey-Level Co-occurrence textures; Object Based Image Analysis (OBIA); Support Vector Machine (SVM)","Authors":"Kumar M., Srivastav S.K., Garg P.K.","DOI":null,"x":14.44,"y":5.25},{"HDBSCAN_Cluster":0,"DocId":509,"Cited by":null,"Year":2017,"Document Type":"Article","Title":"Urban inefficient industrial land recognition system based on augmented learning model","Abstract":"From a salient point of view, urban planning has a significant impact on the expansion of the residential, industrial and commercial land. Land planning has a positive impact on the development of residential land but negatively affects the expansion of industrial, commercial and mining land, that is to say, the plot planned for construction land has a lower probability of transforming into construction land, which is not in line with common sense, indicating that the compilation of the land planning is far from the expansion of actual construction land. Therefore, this paper presents the urban inefficient industrial land recognition system based on augmented learning model. We adopt endogenous optimization method to determine the weight of each input factor, do not need to estimate parameters in advance, no correlation requirement to input and output variables, avoiding the input-output relationship of the expression and the index weight to determine the specific functional form of subjectivity. With this model, the urban planning model is then optimized to satisfy the general requirements.","Author Keywords":"Augmented learning; Inefficient industrial; Land recognition; Machine learning; Urban","Authors":"Rao Y., Dai D.","DOI":null,"x":12.3,"y":3.14},{"HDBSCAN_Cluster":0,"DocId":515,"Cited by":null,"Year":2017,"Document Type":"Conference Paper","Title":"Algorithm for modeling agricultural land cover classification and land surface temperature","Abstract":"The rampant and unintended spread of urban areas resulted to the increase artificial component in the land cover types of the countryside bringing forth urban heat island (UHI). This paved the way to wide range of negative influences on the human health and environment which commonly relates to air pollution, drought, higher energy demand, and water shortage. The land cover also plays a relevant role in the process of understanding the interaction between ground surfaces with the local temperature. At the moment, depiction of the land surface temperature (LST) at city\/municipality scale particularly in certain areas of Misamis Oriental, Philippines is inadequate as support to efficient mitigations and adaptations of the surface urban heat island (SUHI). Thus, this study purposely attempts to provide application on the Landsat 8 satellite data and low density Light Detection and Ranging (LiDAR) products in mapping out quality semi-Automated LST model and crop-level land cover classification in a local scale through theoretical and algorithm base approach utilizing the principle of data analysis subjected to object based model. The paper also aims to explore the relationship between the derived LST and land cover classification. The results of the presented model showed the ability of comprehensive data analysis, GIS functionalities and object based image analysis (OBIA) approach with the integration of machine learning intelligence on automating complex map production processes with considerable efficiency and high accuracy. The findings may potentially lead to expanded investigation of temporal dynamics of land surface UHI. It is worthwhile to note that the environmental significance of these interactions can provide microclimate perception, awareness and improved decision making for land use planning and characterization at local and neighborhood scale. As a result, it can aid in facilitating problem identification, support mitigations and adaptations more efficiently. \u00a9 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Author Keywords":"Landsat 8 OLI\/TIRS; LiDAR; Local scale; Remote sensing","Authors":"Villar R.G., Pelayo J.L., Bantugan J., Opiso E.","DOI":null,"x":13.68,"y":3.55},{"HDBSCAN_Cluster":0,"DocId":524,"Cited by":25.0,"Year":2016,"Document Type":"Article","Title":"Modeling Urban Land Use Changes Using Support Vector Machines","Abstract":"Support Vector Machines (SVM) is a machine learning (ML) algorithm commonly applied to the classification of remotely sensing data and more recently for modeling land use changes. However, in most geospatial applications the current literature does not elaborate on specifications of the SVM method with respect to data sampling, attribute selection and optimal parameters choices. Therefore the main objective of this study is to present and investigate the SVM technique for modeling urban land use change. The SVM model building procedure is presented together with the detailed evaluation of the output results with respect to the choice of datasets, attributes and the change of SVM parameters. Geospatial datasets containing nine land use classes and spatial attributes for the Municipality of Zemun, Republic of Serbia were used for years 2001, 2003, 2007 and 2011. The Correlation-based Feature Subset method, kappa coefficient, Area Under Receiver Operating Characteristic Curve (AUC) and kappa simulation were used to perform the model evaluation and compare the model outputs with the real land use datasets. The obtained results indicate that the SVM-based models perform better when implementing balanced data sampling, reduced data sets to informative subsets of attributes and properly identify the optimal learning parameters. \u00a9 2015 John Wiley & Sons Ltd","Author Keywords":null,"Authors":"Samard\u017ei\u0107-Petrovi\u0107 M., Dragi\u0107evi\u0107 S., Kova\u010devi\u0107 M., Bajat B.","DOI":"10.1111\/tgis.12174","x":13.53,"y":3.31},{"HDBSCAN_Cluster":1,"DocId":525,"Cited by":34.0,"Year":2016,"Document Type":"Article","Title":"Building detection from orthophotos using a machine learning approach: An empirical study on image segmentation and descriptors","Abstract":"Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling. \u00a9 2016 Elsevier Ltd. All rights reserved.","Author Keywords":"Automatic building detection and delineation; Classifier; Image descriptors; Image segmentation; Orthophotos; Supervised learning","Authors":"Dornaika F., Moujahid A., El Merabet Y., Ruichek Y.","DOI":"10.1016\/j.eswa.2016.03.024","x":14.94,"y":5.94},{"HDBSCAN_Cluster":-1,"DocId":528,"Cited by":34.0,"Year":2016,"Document Type":"Article","Title":"A supervoxel-based spectro-spatial approach for 3D urban point cloud labelling","Abstract":"ABSTRACT: Three-dimensional (3D) point cloud labelling of airborne lidar (light detection and ranging) data has promising applications in urban city modelling. Automatic and efficient methods for semantic labelling of airborne urban point cloud data with multiple classes still remains a challenge. We propose a novel 3D object-based classification framework for labelling urban lidar point cloud using a computer vision technique, supervoxels. The supervoxel approach is promising for representing dense lidar point cloud in a compact manner for 3D segmentation and for improving the computational efficiency. Initially, supervoxels are generated by over-segmenting the coloured point cloud using the voxel-based cloud connectivity algorithm in the geometric space. The local connectivity established between supervoxels has been used to produce meaningful and realistic objects (segments). The segments are classified by different machine learning techniques based on several spectral and geometric features extracted from the segments. All the points within a labelled segment are assigned the same segment label. Furthermore, the effect of different feature vectors and varying point density on the classification accuracy has been studied. Results indicate an accurate labelling of points in realistic 3D space conforming to the boundaries of objects. An overall classification accuracy of 90% is achieved by the proposed method. The labelled 3D points can be used directly for the reconstruction of buildings and other man-made objects. \u00a9 2016 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":null,"Authors":"Ramiya A.M., Nidamanuri R.R., Ramakrishnan K.","DOI":"10.1080\/01431161.2016.1211348","x":14.57,"y":6.23},{"HDBSCAN_Cluster":-1,"DocId":531,"Cited by":29.0,"Year":2016,"Document Type":"Article","Title":"Land Classification Using Remotely Sensed Data: Going Multilabel","Abstract":"Obtaining an up-to-date high-resolution description of land cover is a challenging task due to the high cost and labor-intensive process of human annotation through field studies. This work introduces a radically novel approach for achieving this goal by exploiting the proliferation of remote sensing satellite imagery, allowing for the up-to-date generation of global-scale land cover maps. We propose the application of multilabel classification, a powerful framework in machine learning, for inferring the complex relationships between the acquired satellite images and the spectral profiles of different types of surface materials. Introducing a drastically different approach compared to unsupervised spectral unmixing, we employ contemporary ground-collected data from the European Environment Agency to generate the label set and multispectral images from the MODIS sensor to generate the spectral features, under a supervised classification framework. To validate the merits of our approach, we present results using several state-of-the-art multilabel learning classifiers and evaluate their predictive performance with respect to the number of annotated training examples, as well as their capability to exploit examples from neighboring regions or different time instances. We also demonstrate the application of our method on hyperspectral data from the Hyperion sensor for the urban land cover estimation of New York City. Experimental results suggest that the proposed framework can achieve excellent prediction accuracy, even from a limited number of diverse training examples, surpassing state-of-the-art spectral unmixing methods. \u00a9 2016 IEEE.","Author Keywords":"CORINE; data processing; land cover; MODIS; pattern classification; remote sensing; satellite applications; time series; unmixing","Authors":"Karalas K., Tsagkatakis G., Zervakis M., Tsakalides P.","DOI":"10.1109\/TGRS.2016.2520203","x":15.02,"y":4.38},{"HDBSCAN_Cluster":1,"DocId":547,"Cited by":203.0,"Year":2015,"Document Type":"Conference Paper","Title":"Building detection in very high resolution multispectral data with deep learning features","Abstract":"The automated man-made object detection and building extraction from single satellite images is, still, one of the most challenging tasks for various urban planning and monitoring engineering applications. To this end, in this paper we propose an automated building detection framework from very high resolution remote sensing data based on deep convolutional neural networks. The core of the developed method is based on a supervised classification procedure employing a very large training dataset. An MRF model is then responsible for obtaining the optimal labels regarding the detection of scene buildings. The experimental results and the performed quantitative validation indicate the quite promising potentials of the developed approach. \u00a9 2015 IEEE.","Author Keywords":"deep convolutional networks; extraction; ImageNet; Machine learning; man made objects","Authors":"Vakalopoulou M., Karantzalos K., Komodakis N., Paragios N.","DOI":"10.1109\/IGARSS.2015.7326158","x":15.7,"y":6.19},{"HDBSCAN_Cluster":1,"DocId":548,"Cited by":42.0,"Year":2015,"Document Type":"Conference Paper","Title":"Improving Spatial Feature Representation from Aerial Scenes by Using Convolutional Networks","Abstract":"The performance of image classification is highly dependent on the quality of extracted features. Concerning high resolution remote image images, encoding the spatial features in an efficient and robust fashion is the key to generating discriminatory models to classify them. Even though many visual descriptors have been proposed or successfully used to encode spatial features of remote sensing images, some applications, using this sort of images, demand more specific description techniques. Deep Learning, an emergent machine learning approach based on neural networks, is capable of learning specific features and classifiers at the same time and adjust at each step, in real time, to better fit the need of each problem. For several task, such image classification, it has achieved very good results, mainly boosted by the feature learning performed which allows the method to extract specific and adaptable visual features depending on the data. In this paper, we propose a novel network capable of learning specific spatial features from remote sensing images, with any pre-processing step or descriptor evaluation, and classify them. Specifically, automatic feature learning task aims at discovering hierarchical structures from the raw data, leading to a more representative information. This task not only poses interesting challenges for existing vision and recognition algorithms, but also brings huge opportunities for urban planning, crop and forest management and climate modelling. The propose convolutional neural network has six layers: three convolutional, two fully-connected and one classifier layer. So, the five first layers are responsible to extract visual features while the last one is responsible to classify the images. We conducted a systematic evaluation of the proposed method using two datasets: (i) the popular aerial image dataset UCMerced Land-use and, (ii) a multispectral high-resolution scenes of the Brazilian Coffee Scenes. The experiments show that the proposed method outperforms state-of-the-art algorithms in terms of overall accuracy. \u00a9 2015 IEEE.","Author Keywords":"Deep Learning; Feature Learning; High-resolution Images; Image Classification; Machine Learning; Remote Sensing","Authors":"Nogueira K., Miranda W.O., Santos J.A.D.","DOI":"10.1109\/SIBGRAPI.2015.39","x":15.74,"y":4.74},{"HDBSCAN_Cluster":0,"DocId":551,"Cited by":18.0,"Year":2015,"Document Type":"Article","Title":"Automatic classification of high resolution land cover using a new data weighting procedure: The combination of k-means clustering algorithm and central tendency measures (KMC-CTM)","Abstract":"Information on a well-scale urban land cover is important for a number of urban planning practices involving tree shade mapping, green space analysis, urban hydrologic modeling and urban land use mapping. In this study, an urban land cover dataset received from the database of UCI (University of California at Irvine) machine learning was used as the urban land cover data. This dataset is the urban area located in Deerfield Beach, FL, USA. Separately, this dataset is a high definition atmospheric image consisting of 9 different urban land covers. The characteristics of a multi-scale spectral, magnitude and formal tectology were used to sort out and classify these different images. The dataset comprises a total of 147 features and land covers of 9 different areas involving trees, grass, soil, concrete, asphalt, buildings, cars, pools and shadows. A new data weighting method was recommended to classify these 9 different patterns automatically. This recommended data weighting method is based on the combination of the measures of central tendency composed of mean value, harmonic value, mode and median along with the k-means clustering method. In the data weighting method, the data sets belonging to each class within the dataset are first calculated by using k-means clustering method, after which the measures of central tendency belonging to each class are calculated, as well. The measure of central tendency belonging to each class is divided by the set central value belonging to the class in question, as the result of which the data weight coefficient of that class has already been calculated. This calculation process is performed separately for 9 different land covers, and afterwards, these data weighting coefficients found are multiplied by the dataset, and thus, the dataset has been weighted. In the second stage, on the other hand, 3 different classification algorithms containing k-NN (k-nearest neighbor), extreme learning machine (ELM) and support vector machine (SVM) were used to classify 9 different urban land covers after the data weighting method. In determining the educational and test data sets, the 10-fold cross validation was used. When classification through raw data was performed along with k-NN (for k = 1), ELM and SVM classification algorithms, the overall classification accuracy obtained was 77.15%, 84.70% and 84.79%, respectively. When classification through data weighting method (the combination of k-means clustering and mode measure) along with k-NN (for k = 1), ELM and SVM classification algorithms was made, the overall classification accuracy obtained proved to be 98.58%, 98.62% and 98.77%, respectively. The obtained results suggest that the urban land cover in an atmospheric image via the recommended data weighting method was classified as 9 different areas with a high classification success rate. \u00a9 2015 Elsevier B.V. All rights reserved.","Author Keywords":"Classification; Data pre-processing; Data weighting; The combination of k-means clustering algorithm and central tendency measures (KMC-CTM); Urban land cover","Authors":"Durduran S.S.","DOI":"10.1016\/j.asoc.2015.06.025","x":13.71,"y":4.03},{"HDBSCAN_Cluster":-1,"DocId":552,"Cited by":58.0,"Year":2015,"Document Type":"Article","Title":"Combining Pixel-and Object-Based Machine Learning for Identification of Water-Body Types from Urban High-Resolution Remote-Sensing Imagery","Abstract":"Water is one of the vital components for the ecological environment, which plays an important role in human survival and socioeconomic development. Water resources in urban areas are gradually decreasing due to the rapid urbanization, especially in developing countries. Therefore, the precise extraction and automatic identification of water bodies are of great significance and urgently required for urban planning. It should be noted that although some studies have been reported regarding the water-area extraction, to our knowledge, few papers concern the identification of urban water types (e.g., rivers, lakes, canals, and ponds). In this paper, a novel two-level machine-learning framework is proposed for identifying the water types from urban high-resolution remote-sensing images. The framework consists of two interpretation levels: 1) water bodies are extracted at the pixel level, where the water\/shadow\/vegetation indexes are considered and 2) water types are further identified at the object level, where a set of geometrical and textural features are used. Both levels employ machine learning for the image interpretation. The proposed framework is validated using the GeoEye-1 and WorldView-2 images, over two mega cities in China, i.e., Wuhan and Shenzhen, respectively. The experimental results show that the proposed method achieved satisfactory accuracies for both water extraction [95.4% (Shenzhen), 96.2% (Wuhan)], and water type classification [94.1% (Shenzhen), 95.9% (Wuhan)] in complex urban areas. \u00a9 2015 IEEE.","Author Keywords":"High resolution; machine learning; object-oriented; water detection; water extraction; water index","Authors":"Huang X., Xie C., Fang X., Zhang L.","DOI":"10.1109\/JSTARS.2015.2420713","x":14.17,"y":4.5},{"HDBSCAN_Cluster":0,"DocId":553,"Cited by":24.0,"Year":2015,"Document Type":"Article","Title":"Performance analysis of radial basis function networks and multi-layer perceptron networks in modeling urban change: a case study","Abstract":"The majority of cities are rapidly growing. This makes the monitoring and modeling of urban change\u2019s spatial patterns critical to urban planners, decision makers, and environment protection activists. Although a wide range of methods exists for modeling and simulating urban growth, machine learning (ML) techniques have received less attention despite their potential for producing highly accurate predictions of future urban extents. The aim of this study is to investigate two ML techniques, namely radial basis function network (RBFN) and multi-layer perceptron (MLP) networks, for modeling urban change. By predicting urban change for 2010, the models\u2019 performance is evaluated by comparing results with a reference map and by using a set of pertinent statistical measures, such as average spatial distance deviation and figure of merit. The application of these techniques employs the case study area of Mumbai, India. The results show that both models, which were tested using the same explanatory variables, produced promising results in terms of predicting the size and extent of future urban areas. Although a close match between RBFN and MLP is observed, RBFN demonstrates higher spatial accuracy of prediction. Accordingly, RBFN was utilized to simulate urban change for 2020 and 2030. Overall, the study provides evidence that RBFN is a robust and efficient ML technique and can therefore be recommended for land use change modeling. \u00a9 2015, \u00a9 2015 Taylor & Francis.","Author Keywords":"GIS; multi-layer perceptron network; radial basis function network; spatial accuracy assessment; urban change","Authors":"Shafizadeh-Moghadam H., Hagenauer J., Farajzadeh M., Helbich M.","DOI":"10.1080\/13658816.2014.993989","x":11.97,"y":3.06},{"HDBSCAN_Cluster":0,"DocId":554,"Cited by":1.0,"Year":2015,"Document Type":"Conference Paper","Title":"Systematic data mining into land consumption in Germany","Abstract":"This paper presents a systematic approach for discovering comprehensible, valid, potentially innovative and useful structures in multivariate municipality data. Techniques from statistics, machine learning and data mining are applied in logical consecutive steps. This allows the validation after each step and the generation of important results during the investigation. In particular, the approach does not end with a clustering of the data. If a structure has been identified, then the question is posed: what does the cluster mean? Symbolic machine learning methods are used to produce an understandable description of the clusters in form of classification rules. The approach is demonstrated on a data set of nine variables concerning land consumption of all municipalities in Germany. Selected results demonstrate the capacity of the method.","Author Keywords":null,"Authors":"Ultsch A., Kretschmer O., Behnisch M.","DOI":null,"x":12.64,"y":3.18},{"HDBSCAN_Cluster":-1,"DocId":557,"Cited by":1.0,"Year":2015,"Document Type":"Conference Paper","Title":"Comparison of different machine learning classifiers for building extraction in LiDAR-derived datasets","Abstract":"Building extraction in remotely sensed imagery is an important problem that needs solving. It can be used to aid in urban planning, hazard assessments and disaster risk management among others. Light Detection and Ranging or LiDAR, is one of the most powerful remote sensing technologies nowadays. Many studies have used the fusion of LiDAR data and multispectral images in detecting buildings. This study seeks to maximize the power of LiDAR imagery to be able to classify buildings without the aid of multispectral imagery. This work follows the Object Based Image Analysis (OBIA) approach. Instead of the traditional pixel-based classification methods, pixels are segmented into logical groups called objects. From these objects, features for building extraction are calculated. These features are: the number of returns, difference of returns, and the mean and standard deviation of positive surface openness. These objects are then classified using different machine learning classifiers such as Support Vector Machines, K-Nearest Neighbors, Na\u00efve Bayes Classifier, Decision Trees, and Random Forests. A comparative assessment was done on the performance of these different machine learning classifiers. The classifiers performed similarly with the Random Forest Classifier slightly outperforming the others.","Author Keywords":"Feature extraction; Object based image analysis","Authors":"Escamos I.M.H., Roberto A.R.C., Abucay E.R., Inciong G.K.L., Queliste M.D., Hermocilla J.A.C.","DOI":null,"x":14.41,"y":5.81},{"HDBSCAN_Cluster":-1,"DocId":559,"Cited by":64.0,"Year":2015,"Document Type":"Article","Title":"Urban land use and land cover classification using remotely sensed sar data through deep belief networks","Abstract":"Land use and land cover (LULC) mapping in urban areas is one of the core applications in remote sensing, and it plays an important role in modern urban planning and management. Deep learning is springing up in the field of machine learning recently. By mimicking the hierarchical structure of the human brain, deep learning can gradually extract features from lower level to higher level. The Deep Belief Networks (DBN) model is a widely investigated and deployed deep learning architecture. It combines the advantages of unsupervised and supervised learning and can archive good classification performance. This study proposes a classification approach based on the DBN model for detailed urban mapping using polarimetric synthetic aperture radar (PolSAR) data. Through the DBN model, effective contextual mapping features can be automatically extracted from the PolSAR data to improve the classification performance. Two-date high-resolution RADARSAT-2 PolSAR data over the Great Toronto Area were used for evaluation. Comparisons with the support vector machine (SVM), conventional neural networks (NN), and stochastic Expectation-Maximization (SEM) were conducted to assess the potential of the DBN-based classification approach. Experimental results show that the DBN-based method outperforms three other approaches and produces homogenous mapping results with preserved shape details. \u00a9 2015 Qi Lv et al.","Author Keywords":null,"Authors":"Lv Q., Dou Y., Niu X., Xu J., Xu J., Xia F.","DOI":"10.1155\/2015\/538063","x":15.51,"y":4.55},{"HDBSCAN_Cluster":-1,"DocId":563,"Cited by":11.0,"Year":2014,"Document Type":"Article","Title":"Ensemble methods for binary classifications of airborne LIDAR data","Abstract":"This paper presents a framework that is aimed at improving the performance of two existing ensemble methods (namely, AdaBoost and Bagging) for airborne light detection and ranging (LIDAR) classification. LIDAR is one of the fastest growing technologies to support a multitude of civil engineering applications, such as transportation, urban planning, flood control, and city 3D reconstruction. For the above applications, LIDAR data need to be classified into binary classes (i.e., terrain and nonterrain) or multiple classes (e.g., ground, vegetation, and buildings). The proposed framework is designed to enhance the generalization performance of binary classification approach by minimizing type II errors. The authors developed and tested the framework on different LIDAR data sets representing geographic sites in Germany and the United States. The results showed that the proposed ensemble framework performed better compared to the existing methods. In addition, the AdaBoost method outperformed the Bagging method on all the terrain types. However, the framework has some limitations in terms of dealing with rough terrain and discontinuous surfaces. \u00a9 2014 American Society of Civil Engineers.","Author Keywords":"Computing; Ensemble method; LIDAR; Machine learning; Remote sensing","Authors":"Nourzad S.H.H., Pradhan A.","DOI":"10.1061\/(ASCE)CP.1943-5487.0000276","x":14.14,"y":5.65},{"HDBSCAN_Cluster":0,"DocId":565,"Cited by":48.0,"Year":2014,"Document Type":"Article","Title":"From land cover-graphs to urban structure types","Abstract":"Urban structure types (UST) are an initial interest and basic instrument for monitoring, controlling and modeling tasks of urban planners and decision makers during ongoing urbanization processes. This study focuses on a method to classify UST from land cover (LC) objects, which were derived from high resolution satellite images. The topology of urban LC objects is analyzed by implementing neighborhood LC-graphs. Various graph measures are examined by their potential to distinguish between different UST, using the machine learning classifier random forest. Additionally the influence of different parameter settings of the random forest model, the reduction of training samples, and the graph measure importance is analyzed. An independent test set is classified and validated, achieving an overall accuracy of 87%. It was found that the height of the building with the highest node degree has a strong impact on the classification result. \u00a9 2014 \u00a9 Taylor & Francis.","Author Keywords":"adjacency-graphs; land cover; land use; urban; urban structure types","Authors":"Walde I., Hese S., Berger C., Schmullius C.","DOI":"10.1080\/13658816.2013.865189","x":13.72,"y":4.2},{"HDBSCAN_Cluster":0,"DocId":569,"Cited by":8.0,"Year":2014,"Document Type":"Article","Title":"Analysis of land use and land cover change in a coastal area of Rio de Janeiro using high-resolution remotely sensed data","Abstract":"Coastal areas offer great recreational and economic opportunities, but require intensive resource management and environmental protection. Land use and land cover information provides a rapid and cost-effective means for monitoring and planning coastal area development. This study quantitatively describes spatiotemporal changes of land use and land cover over the last four decades in a coastal area of the state of Rio de Janeiro, Brazil. Historical aerial photographs from 1976 and satellite images from 1990 and 2012 were classified and analyzed. We used supervised classification and machine learning techniques to classify the images. An accuracy assessment of results was performed. Land use change statistics for the period indicate that urban areas have increased to the detriment of dense vegetation, salines, and bare soil. The analysis provides a basis for better control of anthropogenic impacts and geoconservation activities in this coastal area of Rio de Janeiro. \u00a9 2014 Society of Photo-Optical Instrumentation Engineers.","Author Keywords":"AdaBoost; coastal environments; land use and land cover change; Reg\u0129o dos Lagos","Authors":"Avelar S., Tokarczyk P.","DOI":"10.1117\/1.JRS.8.083631","x":13.82,"y":3.25},{"HDBSCAN_Cluster":0,"DocId":570,"Cited by":26.0,"Year":2014,"Document Type":"Article","Title":"Driving forces analysis of urban expansion based on boosted regression trees and Logistic regression","Abstract":"The rapid relentless urban area expansion has led to a series of problems in China. Many researches focused on this issue in recent years. Driving forces are the core topic in urban expansion,as well as the basic component of modeling and predicting. It is very useful and meaningful to analyze the driving force of urban expansion, which may provide us with a scientific basis to rationally utilize land resources, determining the law of urban development, researching the evolution process, predicting the urban expansion trends, and also providing guidance for the development of rational control policies. The Shenyang city was chosen as study area. Eight categories of land use types were extracted from remote sensing images (1997 and 2010) with ArcGIS software. Ten driving forces were chosen, including three natural factors, three distance factors, four social and economic factors. which were calculated based on the land use maps, DEM, topographic maps, zoning maps and the statistical yearbooks. The dependent variable was the change of built-up area of Shenyang from 1997 to 2010. Boosted regression trees (BRT) is an ensemble method and is a combination of techniques between statistical and machine learning traditions that has shown to be effective to identify relationships between results and influencing factors. Logistic regression is a method to discover the empirical relationships between a binary dependent and several independent categorical and continuous variables. Boosted Regression Trees and Logistic regression were used to analyze the main driving force of urban expansion synthetically. The result illustrated the relative influence of driving factors was followed by distance from urban area of 1997, distance from river, DEM, distance from highway and railway, land use types, development plan, GDP, population density, aspect, and slope based on BRT analysis. According to Logistic regression analysis, the relative influence of important factors was followed by development zone, distance from urban land of 1997, DEM, distance from highway and railway, population density, distance from river, rural residential areas and slope. The most important driving forces affecting the expansion of Shenyang are distance from urban area of 1997, DEM, distance from highway and railway. Meanwhile, they were all located in the top four of the main factors. The results revealed that the distance factors were the most important factors, and the total contribution rate of relative influence was up to 61.4%. It is demonstrated distance factors are the main driving forces of urban expansion. Natural factorswere less important, but the relative influence of DEM was important, and the contribution rate was 12.5%. Development zones and rural settlements are the only two factors have much influence in the socio-economic factors. On the whole, location factors, which refer to the distance from urban land in this study, were the leading factors of urban expansion. Natural factors, such as DEM, rivers and so on, are the basis of urban development, determining the overall urban spatial form. The construction of infrastructures, such as roads and railways, are the frame of the city. The social and economic factors decided the speed of urban expansion. Urban planning and development zone construction provided the direction of urban expansion.","Author Keywords":"Boosted regression trees; Driving forces; Logistic regression; Shenyang city; Urban expansion","Authors":"Li C.L., Liu M., Hu Y.M., Xu Y.Y., Sun F.Y.","DOI":"10.5846\/stxb201212121790","x":12.12,"y":3.3},{"HDBSCAN_Cluster":0,"DocId":572,"Cited by":7.0,"Year":2013,"Document Type":"Conference Paper","Title":"A comparative analysis of the urban web of the greater athens agglomeration for the last 20-years period on the basis of landsat imagery","Abstract":"Athens, like most of the world's capital cities, is facing a continuous increase in both population and extent. Although the urban growth in Athens can be mostly attributed to the expansion of the residential areas, the total coverage by impervious surfaces in the city has been significantly increased during the last decade due to construction and new development projects that took place during the preparation period of the 2004 Olympic Games. In this study, a 20-year Landsat imagery archive (1988-2007) was used to map the dynamics of urban growth in greater Athens area, based on the urbanization rates. The characterization and quantification of urban land-cover changes was performed by applying urban feature extraction techniques based on machine learning classifiers. Such classifiers use inductive learning algorithms to generate production rules from training data. For results validation, remote sensing data of higher spatial resolution than Landsat were used, i.e. Ikonosand ASTER (Advanced Specaborn Thermal Emission and Reflection Radiometer) images of the greater Athens agglomeration acquired between 2001 and 2007. The validation procedure involved a set of randomly selected points and overall accuracy of 94.8, 93.3 and 95.9 % for the years 2007, 2004 and 2001, respectively, was observed. Analysis of the results revealed continuing growth of urban features in the study area, particularly in the Messogia plain, where the new international airport of El. Venizelos is located, as well as in the western parts of greater Athens, across the Thriassion industrial area. Growth rate of urban areas was found to be variable in time, obtaining its maximum between 2000 and 2004, as expected. The overall increase of the urban areas during the 20-year period was estimated to be about 30%.","Author Keywords":"Earth observation; Urban growth monitoring; Urban planning.","Authors":"Chrysoulakis N., Mitraka Z., Stathopoulou M., Cartalis C.","DOI":null,"x":13.09,"y":3.44},{"HDBSCAN_Cluster":0,"DocId":576,"Cited by":5.0,"Year":2012,"Document Type":"Conference Paper","Title":"Accuracy comparison of land cover mapping using the object-oriented image classification with machine learning algorithms","Abstract":"Land cover mapping provides basic information for advanced science such as ecological management, biodiversity conservation, forest planning and so on. In remote sensing research, the process of creating an accurate land cover map is an important subject. Recently, there has been growing research interest in the object-oriented image classification techniques. The object-oriented image classification consists of multidimensional features including object features and thus requires multi-dimensional image classification approaches. For example, a linear model such as the maximum likelihood method of pixel-based classification cannot characterize the patterns or relations of multi-dimensional data. In multi-dimensional image classification, data mining and ensemble learning have been shown to increase accuracy and flexibility. This study examined the use of the object-oriented image classification by the multiple machine learning algorithms for land cover mapping. We applied four classifiers: Classification and regression tree (CART), Decision tree with Boosting, Decision tree with Bagging, and Random Forest. The study area was Sado Island in Niigata Prefecture, Japan. Pan-sharpened SPOT\/HRG imagery (June 2007) was used and classified into the following eight classes: broad-leaved deciduous forest, Japanese cedar, Japanese red pine, bamboo forest, paddy field, urban area, road, and bare land. We prepared four data sets with the object based features including textural information. The number of features is increased from data set I through IV. As the result, CART was unsuitable for multi-dimensional classification. Random Forest and Decision tree with Boosting showed high classification accuracies. Furthermore, in the data set with the limited features, Decision tree with Boosting was the accurate classifier. Finally, we propose two machine learning algorithms to every datasets. Random Forest is effective in the case of the multi-dimensional image classification such as data set II, III, and IV. Decision tree with Boosting is effective in the case of the image classification with the limited features such as data set I.","Author Keywords":"Bagging; Boosting; Classification and regression tree; Ensemble classifier; Random Forest","Authors":"Mochizuki S., Murakami T.","DOI":null,"x":14.28,"y":3.89},{"HDBSCAN_Cluster":0,"DocId":578,"Cited by":301.0,"Year":2012,"Document Type":"Article","Title":"Monitoring land cover change in urban and peri-urban areas using dense time stacks of Landsat satellite data and a data mining approach","Abstract":"Given the pace and scale of urban expansion in many parts of the globe, urban environments are playing an increasingly important role in daily quality-of-life issues, ecological processes, climate, material flows, and land transformations. Remote sensing has emerged as a powerful tool to monitor rates and patterns of urban expansion, but many early challenges - such as distinguishing new urban land from bare ground - remain unsolved. To deal with the high temporal and spatial variability as well as complex, multi-signature classes within settlements, this paper presents a new approach that exploits multi-seasonal information in dense time stacks of Landsat imagery using a multi-date composite change detection technique. The central premise of the approach is that lands within\/near urban areas have distinct temporal trajectories both before and after change occurs, and that these lead to characteristic temporal signatures in several spectral regions. The method relies on a supervised classification that exploits training data of stable\/changed areas interpreted from Google Earth images, and a 'brute force' approach of providing all available Landsat data as input, including scenes with data gaps due to the Scan Line Corrector (SLC) problem. Three classification algorithms (maximum likelihood, boosted decision trees, and support vector machines) were tested for their ability to monitor expansion across five time periods (1988-1995, 1996-2000, 2001-2003, 2004-2006, 2007-2009) in three study areas that differ in size, eco-climatic conditions, and rates\/patterns of development. Both the decision trees and support vector machines outperformed the maximum likelihood classifier (overall accuracy of 90-93%, compared to 65%), but the decision trees were superior at handling missing data. Adding transformed features such as band metrics to the Landsat data stack increased accuracy 1-4%, while experiments with a reduced number of features (designed to mimic noisy or missing data) led to a drop in accuracy of 1-9%. The methodology also proved particularly effective for monitoring peri-urbanization outside the urban core, capturing > 98% of village settlements. \u00a9 2012 Elsevier Inc.","Author Keywords":"Change detection; Cities; Classification; Decision trees; Environment; Land cover; Machine learning; Peri-urban; Random forests; Support vector machines; Urban areas; Urbanization","Authors":"Schneider A.","DOI":"10.1016\/j.rse.2012.06.006","x":13.83,"y":3.67},{"HDBSCAN_Cluster":0,"DocId":582,"Cited by":96.0,"Year":2012,"Document Type":"Article","Title":"Mining urban land-use patterns from volunteered geographic information by means of genetic algorithms and artificial neural networks","Abstract":"In the context of OpenStreetMap (OSM), spatial data quality, in particular completeness, is an essential aspect of its fitness for use in specific applications, such as planning tasks. To mitigate the effect of completeness errors in OSM, this study proposes a methodological framework for predicting by means of OSM urban areas in Europe that are currently not mapped or only partially mapped. For this purpose, a machine learning approach consisting of artificial neural networks and genetic algorithms is applied. Under the premise of existing OSM data, the model estimates missing urban areas with an overall squared correlation coefficient (R 2) of 0.589. Interregional comparisons of European regions confirm spatial heterogeneity in the model performance, whereas the R 2 ranges from 0.129 up to 0.789. These results show that the delineation of urban areas by means of the presented methodology depends strongly on location. \u00a9 2012 Taylor &amp; Francis Group, LLC.","Author Keywords":"Machine learning; OpenStreetMap UK; Spatial data quality; Volunteered geographic information","Authors":"Hagenauer J., Helbich M.","DOI":"10.1080\/13658816.2011.619501","x":12.47,"y":3.04},{"HDBSCAN_Cluster":0,"DocId":588,"Cited by":23.0,"Year":2010,"Document Type":"Article","Title":"Urban land cover and land use classification of an informal settlement area using the open-source knowledge-based system InterIMAGE","Abstract":"This study uses the InterIMAGE system and imagery from the Quick Bird sensor for land cover and land use classification at two test sites with informal settlements in the metropolis of S\u00e3o Paulo, Brazil. InterIMAGE is an open source and free access system for knowledge-based image classification. Within InterIMAGE human knowledge is represented as a semantic net and by user-defined rules based on the paradigms of object-oriented image analysis. In the land cover classification step, a genetic algorithm was used for determining appropriate segmentation parameters. For the description of the land cover classes in terms of features and thresholds, a strategy combining machine learning algorithms and a semantic net was elaborated. Based on the land cover classifications, the land use classifications were carried out considering the urban blocks of the test sites as the analysis units. Customized features related to the composition and geometrical structures of the land cover objects within these blocks were used for the description of the land use classes. The proposed methodology has been shown to be efficient for the automatic mapping of the land cover and land use in complex urban areas. The land cover classifications achieved overall accuracies above 70 percent and Kappa indexes above 0.65. Referring to the land use classifications, overall accuracies above 87 percent and Kappa indexes above 0.71 were obtained. This study has explored the main functionalities of the InterIMAGE system, presenting its potential for object-based and knowledge-based image classification. \u00a9 2010 Surveying and Spatial Sciences Institute and Mapping Sciences Institute, Australia.","Author Keywords":"Informal settlements; InterIMAGE; Knowledge-based image classification; Urban land cover; Urban land use; Urban planning","Authors":"Novack T., Kux H.J.H.","DOI":"10.1080\/14498596.2010.487640","x":13.82,"y":3.85},{"HDBSCAN_Cluster":0,"DocId":589,"Cited by":51.0,"Year":2009,"Document Type":"Article","Title":"Land-use-change modeling using unbalanced support-vector machines","Abstract":"Modeling land-use change is a prerequisite to understanding the complexity of land-use-change patterns. This paper presents a novel method to model urban land-use change using support-vector machines (SVMs), a new generation of machine learning algorithms used in classification and regression domains. An SVM modeling framework has been developed to analyze land-use change in relation to various factors such as population, distance to roads and facilities, and surrounding land use. As land-use data are generally unbalanced, in the sense that the unchanged data overwhelm the changed data, traditional methods are incapable of classifying relatively minor land-use changes with high accuracy. To circumvent this problem, an unbalanced SVM has been adopted by enhancing the standard SVMs. A case study of Calgary land-use change demonstrates that the unbalanced SVMs can achieve high and reliable performance for land-use-change modeling. \u00a9 2008 Pion Ltd and its Licensors.","Author Keywords":null,"Authors":"Huang B., Xie C., Tay R., Wu B.","DOI":"10.1068\/b33047","x":13.16,"y":2.91},{"HDBSCAN_Cluster":0,"DocId":590,"Cited by":86.0,"Year":2008,"Document Type":"Article","Title":"Land-cover change and environmental impact analysis in the Greater Mankato area of Minnesota using remote sensing and GIS modelling","Abstract":"Land use and land-cover (LULC) data provide essential information for environmental management and planning. This research evaluates the land-cover change dynamics and their effects for the Greater Mankato Area of Minnesota using image classification and Geographic Information Systems (GIS) modelling in high-resolution aerial photography and QuickBird imagery. Results show that from 1971 to 2003, urban impervious surfaces increased from 18.3% to 32.6%, while cropland and grassland decreased from 54.2% to 39.1%. The dramatic urbanization caused evident environmental impacts in terms of runoff and water quality, whereas the annual air pollution removal rate and carbon storage\/sequestration remained consistent since urban forests were steady over the 32-year span. The results also indicate that highly accurate land-cover features can be extracted effectively from high-resolution imagery by incorporating both spectral and spatial information, applying an image-fusion technique, and utilizing the hierarchical machine-learning Feature Analyst classifier. This research fills the high-resolution LULC data gap for the Greater Mankato Area. The findings of the study also provide valuable inputs for local decision-makers and urban planners.","Author Keywords":null,"Authors":"Yuan F.","DOI":"10.1080\/01431160701294703","x":13.78,"y":3.27},{"HDBSCAN_Cluster":-1,"DocId":592,"Cited by":28.0,"Year":2007,"Document Type":"Conference Paper","Title":"Conditional random field for 3D point clouds with adaptive data reduction","Abstract":"We proposed using Conditional Random Fields with adaptive data reduction for the classification of 3D point clouds acquired from a Riegl Terrestrial laser scanner. The training and inference of the acquired large outdoor urban data can be time consuming. We approach the problem by computing an adaptive support region for each data point using 3D scale theory. For training and inference of the discriminative Conditional Random Fields, smaller set of data samples that contains relevant information within the support region is selected instead of using all point cloud data. We tested the algorithm on synthetically generated data and urban point clouds data acquired from the laser scanner. The computed support region is also used in feature extraction for urban point clouds data. The results showed improvement in the training and inference rate while maintaining comparable classification accuracy. \u00a9 2007 IEEE.","Author Keywords":"Classifications; Conditional random fields; LIDAR data; Machine learning; Scale theory","Authors":"Lim E.H., Suter D.","DOI":"10.1109\/CW.2007.24","x":14.58,"y":6.16},{"HDBSCAN_Cluster":0,"DocId":593,"Cited by":null,"Year":2006,"Document Type":"Conference Paper","Title":"Developing methodologies of knowledge discovery and data mining to investigate metropolitan land use evolution","Abstract":"In the urban\/territorial planning process, the quality of the evaluation procedure is crucial. It is necessary to select and implement innovative tools able to handle the huge amount of available data concerning territorial systems in order to extract useful information from them to enhance the quality of evaluation procedure for urban\/territorial planning. This paper selects some tools derived from Artificial Intelligence, and incorporated GIS through the elaboration of various types of available data, to extract and build knowledge directly from experimental data and also to represent the extracted knowledge very effectively and communicatively, in the form of sets of spatial transformation rules. It describes the structure of the data mining tools which are most suitable for applications in the field of urban planning, aimed at discovering the transformation rules driving the evolution of cities in special of metropolitan in analysis. \u00a9 Springer-Verlag Berlin Heidelberg 2006.","Author Keywords":"Data mining; Knowledge discovery; Machine learning; Spatial and temporal reasoning","Authors":"Shi Y., Liu J., Wang R., Chen M.","DOI":"10.1007\/11801603_83","x":12.29,"y":3.12},{"HDBSCAN_Cluster":0,"DocId":594,"Cited by":7.0,"Year":2005,"Document Type":"Conference Paper","Title":"Comparing machine learning classification schemes - A GIS approach","Abstract":"This project examines the effectiveness of two classification schema: Support Vector Machines (SVM), and Artificial Neural Networks (NN) when applied to geographic (i.e. spatial) data. The context for this study is to examine patterns of urbanization in Mahoning County, OH in relation to several independent driving variables of urban development. These independent variables were constructed using Geographic Information Systems (CIS) and were compared to the dependent variable of the spatial locations of urban areas in Mahoning County. The classification techniques were used in conjunction with the GIS-created variables to predict the location of urban areas within Mahoning County. A comparison of the accuracy of the techniques is presented and conclusions drawn concerning which of the variables are the most influential on urban patterns in the region. Lastly, a spatial analysis of the prediction error is performed for each method. \u00a9 2005 IEEE.","Author Keywords":null,"Authors":"Lazar A., Shellito B.A.","DOI":"10.1109\/ICMLA.2005.16","x":12.48,"y":3.1}]