DocId,Cited by,Year,Document Type,Title,Abstract,Author Keywords,Authors,DOI
2,,2022,Article,"Subjective or objective measures of street environment, which are more effective in explaining housing prices?","Houses with better street design are found to relate to a price premium. Prior studies mainly present the street quality using objective indicators like tree counts and distance to parks with land use data, or most recently using the greenery view index extracted from street view imagery (SVI). We argue objective indicators cannot completely describe people's sense of a place, as perception is a highly subjective process. We hypothesize that subjective measures using visual surveys could capture more subtle human perceptions, thus providing stronger predictive power to housing prices. However, the role of subjectively measured street design qualities is less known due to the lack of large-scale perception data. To test our hypothesis, we first collected designers’ perceptions on five urban design qualities from pairwise SVIs rankings in Shanghai with an online visual survey. Unlike the mainstream of using generic image features, we followed urban design theory and used rule-based features, i.e., about thirty streetscape elements extracted from SVIs to train machine learning (ML) models to predict subjective perceptions. The predictive power of five qualities versus ten selected individual streetscapes on housing price were compared using the hedonic price model. Besides the standard ordinary least squares (OLS), spatial regression and geographical weighted regression (GWR) were also developed to account for the spatial dependence and heterogeneity effects. We found both subjectively measured design qualities and objective indicators outperformed housing structural attributes in explaining housing price. While the objective view indexes collectively explained more price variances, the five perceptions individually exhibited stronger strength. Third, less-studied perceptions like “human scale” showed stronger strength than commonly studied “safety” and “enclosure”. Fourth, less-studied view indexes like “person” and “fence” outperformed ubiquitous features like trees and buildings. Lastly, prior studies might have resulted in biased estimations due to ignoring the multicollinear issues between the sky, tree and building views. Our study addressed the effectiveness of incorporating subjective perceptions at a micro level to infer housing prices. correlations between subjective perceptions were strong while that of objective indicators were negligible, therefore subjective perceptions can complement the objective indicators. The findings provide important reference to decision makers when selecting street quality indicators to infer urban design, city planning and community and housing development plans. © 2022 Elsevier B.V.",Human Perception; Property value; Street design qualities; Street view imagery; Subjective measures,"Qiu W., Zhang Z., Liu X., Li W., Li X., Xu X., Huang X.",10.1016/j.landurbplan.2022.104358
35,2.0,2021,Article,Mapping fine-scale visual quality distribution inside urban streets using mobile LiDAR data,"The visual quality of urban streets is of vital importance for establishing a satisfying and comfortable experience for the residents in an urban community. It also has positive effects on urban vibrancy, public health, and social connections in that community. Numerous studies have been conducted to evaluate the visual quality at the urban street level using street view images. However, the spatial distribution of fine-grained visual quality inside an urban street is rarely investigated. This study presents a new approach for the evaluation of visual quality inside urban streets using mobile LiDAR point clouds. The semantic information of urban streets was first extracted from mobile LiDAR point clouds with a Gradient Boosting classifier. After that, seven well-known key design elements, including the green space factor, sky view factor, enclosure rate, volume index, vehicle occurrence rate, motorization rate, and diversity, were calculated from the classified point clouds using a three-dimensional (3D) visibility model. Finally, the visual quality at 1 m grid resolution inside urban street was achieved automatically by using a random forest model which was trained based on perception samples. This approach has been validated on two study areas and the results indicated that the proposed approach is able to quantitatively examine the visual quality difference inside urban streets. The results generated by the proposed method also match well with the common sense of urban design experts, which are useful for architects and designers to develop best practices in the urban micro-renewal project and to refine the urban planning processes. © 2021 Elsevier Ltd",Fine-scale; Machine learning; Mobile LiDAR; Urban street; Visual quality,"Wu B., Yu B., Shu S., Liang H., Zhao Y., Wu J.",10.1016/j.buildenv.2021.108323
48,1.0,2021,Article,Assessing bikeability with street view imagery and computer vision,"Studies evaluating bikeability usually compute spatial indicators shaping cycling conditions and conflate them in a quantitative index. Much research involves site visits or conventional geospatial approaches, and few studies have leveraged street view imagery (SVI) for conducting virtual audits. These have assessed a limited range of aspects, and not all have been automated using computer vision (CV). Furthermore, studies have not yet zeroed in on gauging the usability of these technologies thoroughly. We investigate, with experiments at a fine spatial scale and across multiple geographies (Singapore and Tokyo), whether we can use SVI and CV to assess bikeability comprehensively. Extending related work, we develop an exhaustive index of bikeability composed of 34 indicators. The results suggest that SVI and CV are adequate to evaluate bikeability in cities comprehensively. As they outperformed non-SVI counterparts by a wide margin, SVI indicators are also found to be superior in assessing urban bikeability and potentially can be used independently, replacing traditional techniques. However, the paper exposes some limitations, suggesting that the best way forward is combining both SVI and non-SVI approaches. The new bikeability index presents a contribution in transportation and urban analytics, and it is scalable to assess cycling appeal widely. © 2021 Elsevier Ltd",Bicycles; Deep learning; GIS; Google Street View; OpenStreetMap; Urban planning,"Ito K., Biljecki F.",10.1016/j.trc.2021.103371
49,1.0,2021,Article,Modeling pedestrian emotion in high-density cities using visual exposure and machine learning: Tracking real-time physiology and psychology in Hong Kong,"People's mental health has been deteriorating as a result of urban living, which also causes disability, pain, or even death among metropolitan residents. Understanding the interaction between human emotions and the built environment is therefore essential for developing strategies towards a psychologically friendly and socially resilient environment. This study aims to model the pedestrian emotion in high-density urban areas of Hong Kong using machine learning based on environmental visual exposure, which is one of the most significant factors affecting emotions. Using ambulatory sensing and portable technologies, two-dimensional emotional data from 99 pedestrians are retrieved from coupled data with respect to wearable arousal, subjective report preference, and the location at a high spatiotemporal resolution (4 m). The visual environment is quantified by isovist and street view factors. This study examines the impact of visual exposures using two multiple linear regression (MLR) models and establishes a predictive model using random forest (RF) (N = 548). The MLR models have R2 values around 0.5 and suggest that in the high-density environment, exposure to more trees, visual volume, and drift magnitude can cause positive emotions. Conversely, areas with a view of sign symbols, object proportion, min-radial, and occlusivity can cause negative emotions. The resultant predictive model with nine visual exposure variables can explain 79% of the spatial variance of pedestrian emotion. Furthermore, the methodological framework provides opportunities for spatial, data-driven approaches to portable sensing and urban planning research. The findings are also applicable to optimize the infrastructure design of outdoor environments for more psychologically friendly experiences. © 2021 Elsevier Ltd",Ambulatory pedestrian emotion track; Deep learning; Environment perception; Isovist; Random forest; Street view,"Xiang L., Cai M., Ren C., Ng E.",10.1016/j.buildenv.2021.108273
51,5.0,2021,Review,Street view imagery in urban analytics and GIS: A review,"Street view imagery has rapidly ascended as an important data source for geospatial data collection and urban analytics, deriving insights and supporting informed decisions. Such surge has been mainly catalysed by the proliferation of large-scale imagery platforms, advances in computer vision and machine learning, and availability of computing resources. We screened more than 600 recent papers to provide a comprehensive systematic review of the state of the art of how street-level imagery is currently used in studies pertaining to the built environment. The main findings are that: (i) street view imagery is now clearly an entrenched component of urban analytics and GIScience; (ii) most of the research relies on data from Google Street View; and (iii) it is used across myriads of domains with numerous applications – ranging from analysing vegetation and transportation to health and socio-economic studies. A notable trend is crowdsourced street view imagery, facilitated by services such as Mapillary and KartaView, in some cases furthering geographical coverage and temporal granularity, at a permissive licence. © 2021 The Author(s)",Built environment; Deep learning; Ground-level; Remote sensing; Urban data science; Urban planning,"Biljecki F., Ito K.",10.1016/j.landurbplan.2021.104217
52,,2021,Article,Places for play: Understanding human perception of playability in cities using street view images and deep learning,"Play benefits childhood development and well-being, and is a key factor in sustainable city design. Though previous studies have examined the effects of various urban features on how much children play and where they play, such studies rely on quantitative measurements of play such as the precise location of play and the duration of play time, while people's subjective feelings regarding the playability of their environment are overlooked. In this study, we capture people's perception of place playability by employing Amazon Mechanical Turk (MTurk) to classify street view images. A deep learning model trained on the labelled data is then used to evaluate neighborhood playability for three U.S. cities: Boston, Seattle, and San Francisco. Finally, multivariate and geographically weighted regression models are used to explore how various urban features are associated with playability. We find that higher traffic speeds and crime rates are negatively associated with playability, while higher scores for perception of beauty are positively associated with playability. Interestingly, a place that is perceived as lively may not be playable. Our research provides helpful insights for urban planning focused on sustainable city growth and development, as well as for research focused on creating nourishing environments for child development. © 2021 Elsevier Ltd",Built environment; Deep learning; Human perception of place; Playability; Street view images,"Kruse J., Kang Y., Liu Y.-N., Zhang F., Gao S.",10.1016/j.compenvurbsys.2021.101693
86,,2021,Review,"Panoramic street-level imagery in data-driven urban research: A comprehensive global review of applications, techniques, and practical considerations","The release of Google Street View in 2007 inspired several new panoramic street-level imagery platforms including Apple Look Around, Bing StreetSide, Baidu Total View, Tencent Street View, Naver Street View, and Yandex Panorama. The ever-increasing global capture of cities in 360◦ provides considerable new opportunities for data-driven urban research. This paper provides the first comprehensive, state-of-the-art review on the use of street-level imagery for urban analysis in five research areas: built environment and land use; health and wellbeing; natural environment; urban modelling and demographic surveillance; and area quality and reputation. Panoramic street-level imagery provides advantages in comparison to remotely sensed imagery and conventional urban data sources, whether manual, automated, or machine learning data extraction techniques are applied. Key advantages include low-cost, rapid, high-resolution, and wide-scale data capture, enhanced safety through remote presence, and a unique pedestrian/vehicle point of view for analyzing cities at the scale and perspective in which they are experienced. However, several limitations are evident, including limited ability to capture attribute information, unreliability for temporal analyses, limited use for depth and distance analyses, and the role of corporations as image-data gatekeepers. Findings provide detailed insight for those interested in using panoramic street-level imagery for urban research. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Baidu; Computer vision; Google Street View; Panoramic; Street View; Street-level; Tencent; Urban data; Virtual audit; Visual analytics,"Cinnamon J., Jahiu L.",10.3390/ijgi10070471
154,,2021,Conference Paper,Urban Perception: Can We Understand Why a Street Is Safe?,"The importance of urban perception computing is relatively growing in machine learning, particularly in related areas to Urban Planning and Urban Computing. This field of study focuses on developing systems to analyze and map discriminant characteristics that might directly impact the city’s perception. In other words, it seeks to identify and extract discriminant components to define the behavior of a city’s perception. This work will perform a street-level analysis to understand safety perception based on the “visual components”. As our result, we present our experimental evaluation regarding the influence and impact of those visual components on the safety criteria and further discuss how to properly choose confidence on safe or unsafe measures concerning the perceptional scores on the city street levels analysis. © 2021, Springer Nature Switzerland AG.",ADE20K; Cityscape; Computer vision; Deep learning; Interpretability; LIME; Perception computing; Perception learning; Place pulse; Segmentation; Street view; Street-level imagery; Urban computing; Urban perception; Visual processing,"Moreno-Vera F., Lavi B., Poco J.",10.1007/978-3-030-89817-5_21
157,,2021,Article,From sonic experiences to urban planning innovations,"It is widely accepted that personal responses to soundscapes are more dependent on listeners’ emotions and attitudes, than on sounds or their physical features alone. Fast-growing cities have catalyzed the importance of designing urban spaces that citizens find pleasant and homely and that support a communal style of living. Unfortunately, there are no standardized methods or techniques to translate sonic experiences into measurable and reliable data, which urban planning professionals or the building industry could turn into innovations and solutions. Most of the data pertaining to noise pollution and city soundscapes is still based on predictive acoustic models and rarely takes any real-life experiences or physical measurements into consideration. This paper presents the concept of a smart and participatory approach for gathering sonic experiences that could be translated into measurable values. The aim is to search for data collection methods to provide data to train deep learning. With machine learning methods, it is possible to find patterns in both desirable and undesirable urban soundscapes. The aim of this concept is to create crowdsourced data collection methods and improve the understanding and communication between citizens and planning processes by producing more accurate and comparable experiential data. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",crowdsourcing; smart cities; Soundscape research; tool support; urban planning,"Kaarivuo A., Salo K., Mikkonen T.",10.1080/09654313.2021.1988062
206,6.0,2020,Article,Predicting human perception of the urban environment in a spatiotemporal urban setting using locally acquired street view images and audio clips,"This study investigates people's perception of visual and auditory landscapes in a mixed-use urban environment. A set of audio and visual data is collected at different intervals during the day in local streets with the help of an audio recorder and camera setup. The High and Low-level features from the collected audio and visual datasets are captured with the help of custom Deep Learning (DL) models and other standard algorithms. The collected data is used in the perception survey, which included human subjects (n = 73). The evaluation of the individual perception is done with the help of eight and six auditory and visual perceptual attributes, respectively. The results from the survey are then studied in relation to the features extracted from algorithms. Finally, a street of 10 km length is chosen within the study area where a spatiotemporal street-level visual and auditory data is collected. Statistical analysis and Machine Learning modeling are performed in the surveyed dataset to predict the human perception of audio and visual scenes in the chosen street. The results helped in understanding specific audio and visual features that are related to individual perceptions. Further, these relationships are utilized to create prediction models, which helped in creating spatiotemporal visual and auditory perception maps. © 2020 Elsevier Ltd",Audio classification; Deep Learning; Environment perception; Perception mapping; Street-view,"Verma D., Jana A., Ramamritham K.",10.1016/j.buildenv.2020.107340
268,,2020,Conference Paper,A machine learning method of predicting behavior vitality using open source data,"The growing popularity of machine learning has provided new opportunities to predict certain behaviors precisely by utilizing big data. In this research, we use an image-based neural network to explore the relationship between the built environment and the activity of bicyclists in that environment. The generative model can produce heat maps that can be used to predict quantitatively the cycling and running activity in a given area, and then use urban design to enhance urban vitality in that area. In the machine learning model, the input image is a plan view of the built environment, and the output image is a heat map showing certain activities in the corresponding area. After it is trained, the model yields output (the predicted heat map) at an acceptable level of accuracy. The heat map shows the levels and conditions of the subject activity in different sections of the built environment. Thus, the predicted results can help identify where regional vitality can be improved. Using this method, designers can not only predict the behavioral heat distribution but also examine the different interactions between behaviors and aspects of the environment. The extent to which factors might influence behaviors is also studied by generating a heat map of the modified plan. In addition to the potential applications of this approach, its limitations and areas for improvement are also proposed. © Proceedings of the 40th Annual Conference of the Association for Computer Aided Design in Architecture: Distributed Proximities, ACADIA 2020. All rights reserved.",,"Sun Y., Jiang L., Zheng H.",
277,,2020,Conference Paper,Modeling and evaluating the residential urban environment perception,"This article discusses the use of machine learning methods for assessing and predicting the perception of urban environment by citizens. The research is based on the analysis of the data collected from social surveys and characteristics of the environment from open sources. The urban environment is seen as a complex system that can be analyzed though the point of view of the urban context. The urban context is formed by the geophisical and social features that forms citizens habitat. At the same time, the perception of the urban environment by citizens depends both on the parameters of the urban environment and on the socio-demographic features of the studied group. The article discusses models for predicting the citizens' perception of the urban environment and evaluation methods of such models. The authors propose the application of the model on the case of St. Petersburg, Russia. © 2020 Elsevier B.V.. All rights reserved.",artificial intelligence; residential perception; spatial modeling; urban environment,"Koroleva P., Chichkova N., Mityagin S.A.",10.1016/j.procs.2020.11.012
287,4.0,2020,Conference Paper,Machine Learning Assisted Urban Filling,"When drawing urban scale plans, designers should always define the position and the shape of each building. This process usually costs much time in the early design stage when the condition of a city has not been finally determined. Thus the designers spend a lot of time working forward and backward drawing sketches for different characteristics of cities. Meanwhile, machine learning, as a decision-making tool, has been widely used in many fields. Generative Adversarial Network (GAN) is a model frame in machine learning, specially designed to learn and generate image data. Therefore, this research aims to apply GAN in creating urban design plans, helping designers automatically generate the predicted details of buildings configuration with a given condition of cities. Through the machine learning of image pairs, the result shows the relationship between the site conditions (roads, green lands, and rivers) and the configuration of buildings. This automatic design tool can help release the heavy load of urban designers in the early design stage, quickly providing a preview of design solutions for urban design tasks. The analysis of different machine learning models trained by the data from different cities inspires urban designers with design strategies and features in distinct conditions. © 2020 and published by the Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), Hong Kong.",Artificial intelligence; Generative adversarial networks; Machine learning; Urban design,"Shen J., Liu C., Ren Y., Zheng H.",
325,70.0,2019,Article,Measuring daily accessed street greenery: A human-scale approach for informing better urban planning practices,"The public benefits of visible street greenery have been well recognised in a growing literature. Nevertheless, this issue was rare to be included into urban greenery and planning practices. As a response to this situation, we proposed an actionable approach for quantifying the daily exposure of urban residents to eye-level street greenery by integrating high resolution measurements on both greenery and accessibility. Google Street View (GSV) images in Singapore were collected and extracted through machine learning algorithms to achieve an accurate measurement on visible greenery. Street networks collected from Open Street Map (OSM) were analysed through spatial design network analysis (sDNA) to quantify the accessibility value of each street. The integration of street greenery and accessibility helps to measure greenery from a human-centred perspective, and it provides a decision-support tool for urban planners to highlight areas with prioritisation for planning interventions. Moreover, the performance between GSV-based street greenery and the urban green cover mapped by remote sensing was compared to justify the contribution of this new measurement. It suggested there was a mismatch between these two measurements, i.e., existing top-down viewpoint through satellites might not be equivalent to the benefits enjoyed by city residents. In short, this analytical approach contributes to a growing trend in integrating large, freely-available datasets with machine learning to inform planners, and it makes a step forward for urban planning practices through focusing on the human-scale measurement of accessed street greenery. © 2018 Elsevier B.V.",Accessible greenery; Google Street View; Human-scale; Machine learning; Space syntax; Visible greenery,"Ye Y., Richards D., Lu Y., Song X., Zhuang Y., Zeng W., Zhong T.",10.1016/j.landurbplan.2018.08.028
367,19.0,2019,Article,A systematic measurement of street quality through multi-sourced Urban data: A human-oriented analysis,"Many studies have been made on street quality, physical activity and public health. However, most studies so far have focused on only few features, such as street greenery or accessibility. These features fail to capture people’s holistic perceptions. The potential of fine grained, multi-sourced urban data creates new research avenues for addressing multi-feature, intangible, human-oriented issues related to the built environment. This study proposes a systematic, multi-factor quantitative approach for measuring street quality with the support of multi-sourced urban data taking Yangpu District in Shanghai as case study. This holistic approach combines typical and new urban data in order to measure street quality with a human-oriented perspective. This composite measure of street quality is based on the well-established 5Ds dimensions: Density, Diversity, Design, Destination accessibility and Distance to transit. They are combined as a collection of new urban data and research techniques, including location-based service (LBS) positioning data, points of interest (PoIs), elements and visual quality of street-view images extraction with supervised machine learning, and accessibility metrics using network science. According to these quantitative measurements from the five aspects, streets were classified into eight feature clusters and three types reflecting the value of street quality using a hierarchical clustering method. The classification was tested with experts. The analytical framework developed through this study contributes to human-oriented urban planning practices to further encourage physical activity and public health. © 2019 by the author. Licensee MDPI, Basel, Switzerland.",Human-oriented; Multi-sourced urban data; Shanghai; Street quality; Systematic measurement; Urban design,"Zhang L., Ye Y., Zeng W., Chiaradia A.",10.3390/ijerph16101782
376,2.0,2019,Conference Paper,City safety perception model based on visual content of street images,"Safety perception measurement has been a subject of interest in many cities of the world. This is due to its social relevance, and to its effect on some local economic activities. Even though people safety perception is a subjective topic, sometimes it is possible to find out common beliefs given a restricted sociocultural context. This paper presents an approach that makes use of image processing and machine learning techniques to model citizen's safety perception using visual information of city images. The proposed method predicts how safe a given street of Bogotá City can be. This is done based on people judgment of the visual appearance of a street image. Results suggest that the obtained model is able to detect city streets, where a visual feature is linked to an activity or street condition that has a significant influence on their associated safety perception. This feature makes the proposed model an alternative tool for decision makers with regard to urban planning, safety and health public policies, as well as a collective memory associated to a particular urban environment. © 2018 IEEE.",,"Acosta S.F., Camargo J.E.",10.1109/ISC2.2018.8656949
411,24.0,2019,Article,Daily accessed street greenery and housing price: Measuring economic performance of human-scale streetscapes via new urban data,"The protective effects of street greenery on ecological, psychological, and behavioral phenomena have been well recognized. Nevertheless, the potential economic effect of daily accessed street greenery, i.e., a human-scale and perceptual-oriented quality focusing on exposure to street greenery in people's daily lives, has not been fully studied because a quantitative measuring of this human-scale indicator is hard to achieve. This study was an attempt in this direction with the help of new urban data and new analytical tools. Shanghai, which has a mature real estate market, was selected for study, and the housing prices of 1395 private neighborhoods in its city center were collected. We selected more than forty variables that were classified under five categories-location features, distances to the closest facilities, density of facilities within a certain radius, housing and neighborhood features, and daily accessed street greenery-in a hedonic pricing model. The distance and density of facilities were computed through a massive number of points-of-interest and a geographical information system. The visible street greenery was collected from Baidu street view images and then measured via a machine-learning algorithm, while accessibility was measured through space syntax. In addition to the well-recognized effects previously discovered, the results show that visible street greenery and street accessibility at global scale hold significant positive coefficients for housing prices. Visible street greenery even obtains the second-highest regression coefficient in the model. Moreover, the combined assessment, the co-presence of local-scale accessibility and eye-level greenery, is significant for housing price as well. This study provides a scientific and quantitative support for the significance of human-scale street greenery, making it an important issue in urban greening policy for urban planners and decision makers. © 2019 by the authors.",Daily accessed street greenery; Housing price; Human scale; New urban data; Shanghai; Street view images,"Ye Y., Xie H., Fang J., Jiang H., Wang D.",10.3390/su11061741
474,,2018,Conference Paper,Designing with citizens: Challenges and evaluation methods for crowd-sourced urban layouts,"This paper presents analysis tools for evaluating crowdsourced geometry-based design proposals for urban planning. With the Quick Urban Analysis Kit, an online platform, citizens are able to manipulate objects and create a preferred layout over a case study area. Given that our case study is on a meso-cale, our analysis is focused on the layout and plot configuration. The proposed analysis tools range from simple counting of object types and a buffer analysis to clustering and spatial autocorrelation tools. Besides these form-based criteria, perception-based criteria are also proposed to link the participating subject's assessment of the designs with the layout. Techniques deployed include supervised machine learning methods, statistical spatial tests, and simple calculations of the area size and frequency of objects. © 2018 CEUR-WS. All rights reserved.",Citizen design science; Creative participatory planning; Crowd-creative evaluation; Geometry-based evaluation,"Mueller J., Lu H.",
477,39.0,2018,Article,StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views,"Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks. © 1995-2012 IEEE.",human scale; street view; Urban forms; visual analytics,"Shen Q., Zeng W., Ye Y., Arisona S.M., Schubiger S., Burkhard R., Qu H.",10.1109/TVCG.2017.2744159
523,97.0,2016,Article,Measuring visual enclosure for street walkability: Using machine learning algorithms and Google Street View imagery,"One major limitation currently with studying street level urban design qualities for walkability is the often inconsistent and unreliable measures of streetscape features across different field surveyors even with costly training due to lack of more objective processes, which also make large scale study difficult. The recent advances in sensor technologies and digitization have produced a wealth of data to help research activities by facilitating improved measurements and conducting large scale analysis. This paper explores the potential of big data and big data analytics in the light of current approaches to measuring streetscape features. By applying machine learning algorithms on Google Street View imagery, we generated objectively three measures on visual enclosure. The results showed that sky areas were identified fairly well for the calculation of proportion of sky. The three visual enclosure measures were found to be correlated with pedestrian volume and Walk Score. This method allows large scale and consistent objective measures of visual enclosure that can be done reproducibly and universally applicable with readily available Google Street View imagery in many countries around the world to help test their association with walking behaviors. © 2016 Elsevier Ltd",Enclosure; Machine learning; Street design features; Walkability,"Yin L., Wang Z.",10.1016/j.apgeog.2016.09.024
529,11.0,2016,Conference Paper,On urban soundscape mapping: A computer can predict the outcome of soundscape assessments,"The purpose of this study was to investigate whether or not a computer may predict the outcome of soundscape assessments, based on acoustic data only. It may be argued that this is impossible, because a computer lack life experience. Moreover, if the computer was able to make an accurate prediction, we also wanted to know what information it needed to make this prediction. We recruited 33 students (18 female; Mage = 25.4 yrs., SDage = 3.6) out of which 30 assessed how pleasant and eventful 102 unique soundscape excerpts (30 s) from Stockholm were. Based on the Bag of Frames approach, a Support Vector Regression learning algorithm was used to identify relationships between various acoustic features of the acoustics signals and perceived affective quality. We found that the Mel-Frequency Cepstral Coefficients provided strong predictions for both Pleasantness (R2 = 0.74) and Eventfulness (R2 = 0.83). This model performed better than the average individual in the experiment in terms of internal consistency of individual assessments. Taken together, the results show that a computer can predict the outcome of soundscape assessments, which is promising for future soundscape mapping. © 2016, German Acoustical Society (DEGA). All rights reserved.",Machine learning; Soundscape mapping; Urban planning,"Lundén P., Axelsson O., Hurtig M.",
534,,2016,Conference Paper,Procedural urban environments for FPS games,"This paper presents a novel approach to procedural generation of urban maps for First Person Shooter (FPS) games. A multi-agent evolutionary system is employed to place streets, buildings and other items inside the Unity3D game engine, resulting in playable video game levels. A computational agent is trained using machine learning techniques to capture the intent of the game designer as part of the multi-agent system, and to enable a semi-automated aesthetic selection for the underlying genetic algorithm. Copyright 2016 ACM.","Agents; Artificial intelligence; Computer games; First person shooter, urban environment; Genetic algorithm; Procedural environment; Unity","Kruse J., Sosa R., Connor A.M.",10.1145/2843043.2843479
595,18.0,2005,Article,Capturing impressions of pedestrian landscapes used for healing purposes with decision tree learning,"In 2002, Medicare health insurance recognized the relationship between pedestrian environments and public health by providing co-pay for health care delivered in residential land use. In this multi-disciplinary experiment, artificial intelligence (AI) and landscape architecture (LA) bridge their respective domains to measure and model the pedestrian reaction to walking environments in small town residential community in Central Texas. In the process, we gained a deeper understanding of the health motivation of walkers and their empirical relationship to various street environments that they used for health purposes. The analytical model we ultimately developed is a flexible tool that facilitates exploration of people's perceptions of the landscape, how the pedestrian landscapes are functioning in the opinion of its users, and how changes to the design of the walking domain may predictably affect physical activity levels with the associated health benefits. A pilot study involving fifty-four participants and six walking environments were used in the development of an analytical model that is significantly site-specific and grass roots oriented. Participant perceptions were measured querying each participant's rating of fifty discrete environmental variables taken. This data was then analyzed using the decision tree algorithm. Our primary objective was to capture the decision-making pattern walkers engage in when deciding to walk in a particular environment specifically for health purposes and to make this available to the designers of pedestrian environments in transportation corridors. The approach gave the designers new insight into the critical variables and the not so critical variables that affected people's decision to walk for health purposes. The results from the analysis defined measurable environmental variables that form the design for pedestrian activity in the six walking environments in the study area. A customized version of decision tree machine learning algorithm rules for designing good pedestrian landscapes for health purposes were extracted from the grass roots surveys. The data indicated that variables influencing the decision to walk for health purposes in the study area included weather, sound, water, light and edge of space. The analytical model derived from the discipline of artificial intelligence facilitated examining a subset of variables and manipulating of individual or group of these variables to better understand how the built environment affected decisions to walk for different purposes. This collaboration was our first phase in developing intelligent tools for designers that provided site-specific user-specific data to the planner or designer of pedestrian space.","Artificial intelligence; Multi-disciplinary design analysis, Walking for health; Pedestrian landscapes; User evaluation","Naderi J.R., Raman B.",10.1016/j.landurbplan.2004.11.012
