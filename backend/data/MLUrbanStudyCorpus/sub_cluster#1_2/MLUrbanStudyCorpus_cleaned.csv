DocId,Cited by,Year,Document Type,Title,Abstract,Author Keywords,Authors,DOI
1,315.0,2018,Article,Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework,"In this paper, we designed an end-to-end spectral-spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia. © 1980-2012 IEEE.",3-D deep learning; hyperspectral image classification; spectral-spatial feature extraction; spectral-spatial residual network (SSRN),"Zhong Z., Li J., Luo Z., Chapman M.",10.1109/TGRS.2017.2755542
3,181.0,2015,Conference Paper,Building detection in very high resolution multispectral data with deep learning features,"The automated man-made object detection and building extraction from single satellite images is, still, one of the most challenging tasks for various urban planning and monitoring engineering applications. To this end, in this paper we propose an automated building detection framework from very high resolution remote sensing data based on deep convolutional neural networks. The core of the developed method is based on a supervised classification procedure employing a very large training dataset. An MRF model is then responsible for obtaining the optimal labels regarding the detection of scene buildings. The experimental results and the performed quantitative validation indicate the quite promising potentials of the developed approach. © 2015 IEEE.",deep convolutional networks; extraction; ImageNet; Machine learning; man made objects,"Vakalopoulou M., Karantzalos K., Komodakis N., Paragios N.",10.1109/IGARSS.2015.7326158
17,77.0,2008,Article,Land-cover change and environmental impact analysis in the Greater Mankato area of Minnesota using remote sensing and GIS modelling,"Land use and land-cover (LULC) data provide essential information for environmental management and planning. This research evaluates the land-cover change dynamics and their effects for the Greater Mankato Area of Minnesota using image classification and Geographic Information Systems (GIS) modelling in high-resolution aerial photography and QuickBird imagery. Results show that from 1971 to 2003, urban impervious surfaces increased from 18.3% to 32.6%, while cropland and grassland decreased from 54.2% to 39.1%. The dramatic urbanization caused evident environmental impacts in terms of runoff and water quality, whereas the annual air pollution removal rate and carbon storage/sequestration remained consistent since urban forests were steady over the 32-year span. The results also indicate that highly accurate land-cover features can be extracted effectively from high-resolution imagery by incorporating both spectral and spatial information, applying an image-fusion technique, and utilizing the hierarchical machine-learning Feature Analyst classifier. This research fills the high-resolution LULC data gap for the Greater Mankato Area. The findings of the study also provide valuable inputs for local decision-makers and urban planners.",,Yuan F.,10.1080/01431160701294703
20,61.0,2014,Article,Building type classification using spatial and landscape attributes derived from LiDAR remote sensing data,"Building information is one of the key elements for a range of urban planning and management practices. In this study, an investigation was performed to classify buildings delineated from light detection and ranging (LiDAR) remote sensing data into three types: single-family houses, multiple-family houses, and non-residential buildings. Four kinds of spatial attributes describing the shape, location, and surrounding environment of buildings were calculated and subsequently employed in the classification. Experiments were performed in suburban and downtown sites in Denver, CO, USA, considering different building components and neighborhood environments. Building type classification results yielded overall accuracy > 70% and Kappa > 0.5 for both sites, demonstrating the feasibility of obtaining building type information from LiDAR data. The shape attributes, such as width, footprint area, and perimeter, were most useful for identifying building types. Environmental landscape attributes surrounding buildings, such as the number of road and parking lot pixels, also contributed to obtaining building type information. Combining shape and environmental landscape attributes was necessary to obtain accurate and consistent classification results. © 2014 Elsevier B.V.",Building classification; Decision trees; LiDAR; Machine learning; Random forest; Support vector machines,"Lu Z., Im J., Rhee J., Hodgson M.",10.1016/j.landurbplan.2014.07.005
21,59.0,2015,Article,Urban land use and land cover classification using remotely sensed sar data through deep belief networks,"Land use and land cover (LULC) mapping in urban areas is one of the core applications in remote sensing, and it plays an important role in modern urban planning and management. Deep learning is springing up in the field of machine learning recently. By mimicking the hierarchical structure of the human brain, deep learning can gradually extract features from lower level to higher level. The Deep Belief Networks (DBN) model is a widely investigated and deployed deep learning architecture. It combines the advantages of unsupervised and supervised learning and can archive good classification performance. This study proposes a classification approach based on the DBN model for detailed urban mapping using polarimetric synthetic aperture radar (PolSAR) data. Through the DBN model, effective contextual mapping features can be automatically extracted from the PolSAR data to improve the classification performance. Two-date high-resolution RADARSAT-2 PolSAR data over the Great Toronto Area were used for evaluation. Comparisons with the support vector machine (SVM), conventional neural networks (NN), and stochastic Expectation-Maximization (SEM) were conducted to assess the potential of the DBN-based classification approach. Experimental results show that the DBN-based method outperforms three other approaches and produces homogenous mapping results with preserved shape details. © 2015 Qi Lv et al.",,"Lv Q., Dou Y., Niu X., Xu J., Xu J., Xia F.",10.1155/2015/538063
25,51.0,2018,Article,Exploring the optimal integration levels between SAR and optical data for better urban land cover mapping in the Pearl River Delta,"Integrating synthetic aperture radar (SAR) and optical data to improve urban land cover classification has been identified as a promising approach. However, which integration level is the most suitable remains unclear but important to many researchers and engineers. This study aimed to compare different integration levels for providing a scientific reference for a wide range of studies using optical and SAR data. SAR data from TerraSAR-X and ENVISAT ASAR in both WSM and IMP modes were used to be combined with optical data at pixel level, feature level and decision levels using four typical machine learning methods. The experimental results indicated that: 1) feature level that used both the original images and extracted features achieved a significant improvement of up to 10% compared to that using optical data alone; 2) different levels of fusion required different suitable methods depending on the data distribution and data resolution. For instance, support vector machine was the most stable at both the feature and decision levels, while random forest was suitable at the pixel level but not suitable at the decision level. 3) By examining the distribution of SAR features, some features (e.g., homogeneity) exhibited a close-to-normal distribution, explaining the improvement from the maximum likelihood method at the feature and decision levels. This indicated the benefits of using texture features from SAR data when being combined with optical data for land cover classification. Additionally, the research also shown that combining optical and SAR data does not guarantee improvement compared with using single data source for urban land cover classification, depending on the selection of appropriate fusion levels and fusion methods. © 2017 Elsevier B.V.",Fusion level; Fusion strategies; Optical and SAR fusion; Urban land cover,"Zhang H., Xu R.",10.1016/j.jag.2017.08.013
30,45.0,2014,Article,From land cover-graphs to urban structure types,"Urban structure types (UST) are an initial interest and basic instrument for monitoring, controlling and modeling tasks of urban planners and decision makers during ongoing urbanization processes. This study focuses on a method to classify UST from land cover (LC) objects, which were derived from high resolution satellite images. The topology of urban LC objects is analyzed by implementing neighborhood LC-graphs. Various graph measures are examined by their potential to distinguish between different UST, using the machine learning classifier random forest. Additionally the influence of different parameter settings of the random forest model, the reduction of training samples, and the graph measure importance is analyzed. An independent test set is classified and validated, achieving an overall accuracy of 87%. It was found that the height of the building with the highest node degree has a strong impact on the classification result. © 2014 © Taylor & Francis.",adjacency-graphs; land cover; land use; urban; urban structure types,"Walde I., Hese S., Berger C., Schmullius C.",10.1080/13658816.2013.865189
41,36.0,2017,Article,Building block level urban land-use information retrieval based on Google Street View images,"Land-use maps are important references for urban planning and urban studies. Given the heterogeneity of urban land-use types, it is difficult to differentiate different land-use types based on overhead remotely sensed data. Google Street View (GSV) images, which capture the façades of building blocks along streets, could be better used to judge the land-use types of different building blocks based on their façade appearances. Recently developed scene classification algorithms in computer vision community make it possible to categorize different photos semantically based on various image feature descriptors and machine-learning algorithms. Therefore, in this study, we proposed a method to derive detailed land-use information at building block level based on scene classification algorithms and GSV images. Three image feature descriptors (i.e., scale-invariant feature transform-Fisher, histogram of oriented gradients, GIST) were used to represent GSV images of different buildings. Existing land-use maps were used to create training datasets to train support vector machine (SVM) classifiers for categorizing GSV images. The trained SVM classifiers were then applied to case study areas in New York City, Boston, and Houston, to predict the land-use information at building block level. Accuracy assessment results show that the proposed method is suitable for differentiating residential buildings and nonresidential buildings with an accuracy of 85% or so. Since the GSV images are publicly accessible, this proposed method would provide a new way for building block level land-use mapping in future. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",GSV (Google Street View); image features; machine learning; urban land-use mapping,"Li X., Zhang C., Li W.",10.1080/15481603.2017.1338389
56,29.0,2016,Article,A supervoxel-based spectro-spatial approach for 3D urban point cloud labelling,"ABSTRACT: Three-dimensional (3D) point cloud labelling of airborne lidar (light detection and ranging) data has promising applications in urban city modelling. Automatic and efficient methods for semantic labelling of airborne urban point cloud data with multiple classes still remains a challenge. We propose a novel 3D object-based classification framework for labelling urban lidar point cloud using a computer vision technique, supervoxels. The supervoxel approach is promising for representing dense lidar point cloud in a compact manner for 3D segmentation and for improving the computational efficiency. Initially, supervoxels are generated by over-segmenting the coloured point cloud using the voxel-based cloud connectivity algorithm in the geometric space. The local connectivity established between supervoxels has been used to produce meaningful and realistic objects (segments). The segments are classified by different machine learning techniques based on several spectral and geometric features extracted from the segments. All the points within a labelled segment are assigned the same segment label. Furthermore, the effect of different feature vectors and varying point density on the classification accuracy has been studied. Results indicate an accurate labelling of points in realistic 3D space conforming to the boundaries of objects. An overall classification accuracy of 90% is achieved by the proposed method. The labelled 3D points can be used directly for the reconstruction of buildings and other man-made objects. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",,"Ramiya A.M., Nidamanuri R.R., Ramakrishnan K.",10.1080/01431161.2016.1211348
61,27.0,2007,Conference Paper,Conditional random field for 3D point clouds with adaptive data reduction,"We proposed using Conditional Random Fields with adaptive data reduction for the classification of 3D point clouds acquired from a Riegl Terrestrial laser scanner. The training and inference of the acquired large outdoor urban data can be time consuming. We approach the problem by computing an adaptive support region for each data point using 3D scale theory. For training and inference of the discriminative Conditional Random Fields, smaller set of data samples that contains relevant information within the support region is selected instead of using all point cloud data. We tested the algorithm on synthetically generated data and urban point clouds data acquired from the laser scanner. The computed support region is also used in feature extraction for urban point clouds data. The results showed improvement in the training and inference rate while maintaining comparable classification accuracy. © 2007 IEEE.",Classifications; Conditional random fields; LIDAR data; Machine learning; Scale theory,"Lim E.H., Suter D.",10.1109/CW.2007.24
71,23.0,2020,Review,Change detection based on artificial intelligence: State-of-the-art and challenges,"Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field. © 2020 by the authors.",Artificial intelligence; Change detection; Deep learning; Hyperspectral; Multispectral; Neural network; Remote sensing; SAR; Street view; Unsupervised learning,"Shi W., Zhang M., Zhang R., Chen S., Zhan Z.",10.3390/rs12101688
90,19.0,2019,Article,"Spatiotemporal detection of land use/land cover change in the large basin using integrated approaches of remote sensing and GIS in the Upper Awash basin, Ethiopia","Assessment of the changing environmental conditions is essential for planning the wise use of natural resources. The main objective of this paper is to analyze the historical and future modeled LULC changes using multi-temporal Landsat images in the Upper Awash basin, Ethiopia. The supervised image classification method was used to determine the historical LULC changes based on Landsat 1 MSS 1972, Landsat 5 TM 1984, Landsat 7 ETM + 2000, and Landsat 8 OLI TIRS 2014. The future LULC change was predicted using the machine-learning approaches of Land Change Modeler (LCM). The LULC change detection analysis exhibited significant increment in the areal extent of the cropland and urban areas, and decreasing trends in the pasture, forests and shrubland coverage. Mainly, the LULC change matrices indicated that larger conversion rate was observed from shrubland to cropland area. The urban area found to increase by 606.2% from the year 1972 to 2014 and cropland has also increased by 47.3%. Whereas, a decreasing trend was obtained in the forest by − 25.1%, pasture − 87.4%, shrubland − 28.8% and water − 21.0% in the same period. The modeled future LULC change scenarios of the year 2025 and 2035 have exhibited significant expansion of cropland and urban areas at the expense of forest, pasture and shrubland areas. The study has revealed the extent and the rate of LULC change at larger basin and subbasin level which can be useful for knowledge-based future land management practice in the Upper Awash basin. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Agricultural expansion; Classification accuracy; Land change modeler; Land cover change; Upper Awash basin; Urban sprawl,"Shawul A.A., Chakma S.",10.1007/s12665-019-8154-y
110,14.0,2019,Article,Deprivation pockets through the lens of convolutional neural networks,"Machine learning techniques have been frequently applied to map urban deprivation (commonly referred to as slums) in very high-resolution satellite images. Among these, Deep Convolutional Neural Networks have shown exceptional efficiency in automated deprivation mapping at the local scale. Yet these networks have never been used to map very small heterogeneous deprivation areas (pockets) at large scale. This study proposes and evaluates a U-Net-Compound model to map deprivation pockets in Bangalore, India. The model only relies on RGB satellite images with a resolution of 2 m as these are more commonly accessible to local urban planning departments. The experiment assumes a practical situation where only limited reference data is available for the model to learn the spatial morphology of deprivation pockets. It tests whether an updated map of deprivation pockets can be obtained with limited information. The model performance to map a large number of deprivation pockets is examined by incrementally changing the model architecture and the amount of training data. Results show that the proposed model is sensitive to the amount of spatial information contained in the training data. Once sufficient spatial information is learnt through a few samples, the city scale mapping accuracy outperforms existing models in mapping small deprivation pockets, achieving a Jaccard Index of 54%. This study demonstrated that a well-designed convolutional neural network can map the existence, extent, as well as distribution patterns of deprivation pockets at the city scale with limited training data, which is essential for upscaling research outputs to provide important information for the formulation of pro-poor policies. © 2019",Bangalore; Convolutional neural networks; Deep learning; Deprivation pockets; Slums,"Wang J., Kuffer M., Roy D., Pfeffer K.",10.1016/j.rse.2019.111448
137,11.0,2014,Article,Ensemble methods for binary classifications of airborne LIDAR data,"This paper presents a framework that is aimed at improving the performance of two existing ensemble methods (namely, AdaBoost and Bagging) for airborne light detection and ranging (LIDAR) classification. LIDAR is one of the fastest growing technologies to support a multitude of civil engineering applications, such as transportation, urban planning, flood control, and city 3D reconstruction. For the above applications, LIDAR data need to be classified into binary classes (i.e., terrain and nonterrain) or multiple classes (e.g., ground, vegetation, and buildings). The proposed framework is designed to enhance the generalization performance of binary classification approach by minimizing type II errors. The authors developed and tested the framework on different LIDAR data sets representing geographic sites in Germany and the United States. The results showed that the proposed ensemble framework performed better compared to the existing methods. In addition, the AdaBoost method outperformed the Bagging method on all the terrain types. However, the framework has some limitations in terms of dealing with rough terrain and discontinuous surfaces. © 2014 American Society of Civil Engineers.",Computing; Ensemble method; LIDAR; Machine learning; Remote sensing,"Nourzad S.H.H., Pradhan A.",10.1061/(ASCE)CP.1943-5487.0000276
156,8.0,2020,Article,A locally-constrained YOLO framework for detecting small and densely-distributed building footprints,"Building footprints are among the most predominant features in urban areas, and provide valuable information for urban planning, solar energy suitability analysis, etc. We aim to automatically and rapidly identify building footprints by leveraging deep learning techniques and the increased availability of remote sensing datasets at high spatial resolution. The task is computationally challenging due to the use of large training datasets and large number of parameters. In related work, You-Only-Look-Once (YOLO) is a state-of-the-art deep learning framework for object detection. However, YOLO is limited in its capacity to identify small objects that appear in groups, which is the case for building footprints. We propose a LOcally-COnstrained (LOCO) You-Only-Look-Once framework to detect small and densely-distributed building footprints. LOCO is a variant of YOLO. Its layer architecture is determined by the spatial characteristics of building footprints and it uses a constrained regression modeling to improve the robustness of building size predictions. We also present an invariant augmentation based voting scheme to further improve the precision in the prediction phase. Experiments show that LOCO can greatly improve the solution quality of building detection compared to related work. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.",Building detection; deep learning; locally constrained; remote sensing; YOLO,"Xie Y., Cai J., Bhojwani R., Shekhar S., Knight J.",10.1080/13658816.2019.1624761
171,7.0,2020,Article,A robust segmentation framework for closely packed buildings from airborne LiDAR point clouds,"Urban villages (UVs) are commonly found in many Asian cities. These villages contain many closely packed buildings constructed decades ago without proper urban planning. There is a need for those buildings to be identified and put into statistics. In this paper, we present a segmentation framework that invokes multiple machine learning techniques and point cloud/image processing algorithms to segment individual closely packed buildings from large urban scenes. The presented framework consists of two major segmentation processes. The framework first filters out the non-ground objects from the point cloud, then it classified them by using the Random Forest classifier to isolate buildings from the entire scene. After that, the building point clouds will be segmented based on several building attribute analysis methods. This is followed by using the Random Sample Consensus (RANSAC) plane filtering method to expand the space between two closely packed buildings, so that the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering technique can be used to more accurately segment each individual building from the closely packed building areas. Two airborne Light Detection and Ranging (LiDAR) datasets collected in two different cities with some typical closely packed buildings were used to verify the proposed framework. The results show that the framework can effectively identify the closely packed buildings with unified structures from large airborne LiDAR datasets. The overall segmentation accuracy reaches 84% for the two datasets. The proposed framework can serve as a basis for analysis and segmentation of closely packed buildings with a more complicated structure. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",,"Wang X., Chan T.O., Liu K., Pan J., Luo M., Li W., Wei C.",10.1080/01431161.2020.1727053
176,7.0,2019,Review,"Landscape Transformations in Rapidly Developing Peri-urban Areas of Accra, Ghana: Results of 30 years","Beyond the loss of peri-urban agricultural and forested land as a result of built-up expansion, not much information exists on the changes in the structure of the peri-urban landscape in Ghana. The aim of this paper is to examine the extent to which urban expansion is driving changes in landscape structure of the peri-urban fringes of Accra.We submit that rapid peri-urbanisation will fragment the existing agricultural and forested landscape with consequent ecological, socio-economic and urban governance implications. Using Landsat satellite images for the years 1985, 1991, 2002 and 2015 the study area was classified into four land cover classes. The study adopted the use of Urban Intensity Index (UII) and the Annual Rate of Urbanization (R) as measures of urbanization. Edge density (ED), largest patch index (LPI) and Aggregation index (AI) were used as proxies to measure landscape structural transformations. The study reveals substantial reductions and fragmentation in agricultural lands, riverine and open forests, while there has been over 200 percent increase in built-up areas. Beyond these revelations in spatiotemporal changes in landscape structure, the paper points to the ecological implications of the changes, and three key socio-economic and urban governance implications. © 2019 G. Ashiagbor et al.",,"Ashiagbor G., Amoako C., Asabere S.B., Quaye-Ballard J.A.",10.1515/geo-2019-0014
204,5.0,2019,Article,Understanding the spatial distribution of urban forests in China using Sentinel-2 images with Google Earth Engine,"Urban forests are vitally important for sustainable urban development and the well-being of urban residents. However, there is, as yet, no country-level urban forest spatial dataset of sufficient quality for the scientific management of, and correlative studies on, urban forests in China. At present, China attaches great importance to the construction of urban forests, and it is necessary to map a high-resolution and high-accuracy dataset of urban forests in China. The open-access Sentinel images and the Google Earth Engine platform provide a significant opportunity for the realization of this work. This study used eight bands (B2-B8, B11) and three indices of Sentinel-2 in 2016 to map the urban forests of China using the Random Forest machine learning algorithms at the pixel scale with the support of Google Earth Engine (GEE). The 7317 sample points for training and testing were collected from field visits and very high resolution images from Google Earth. The overall accuracy, producer's accuracy of urban forest, and user's accuracy of urban forest assessed by independent validation samples in this study were 92.30%, 92.27%, and 92.18%, respectively. In 2016, the percentage of urban forest cover was 19.2%. Nearly half of the cities had an urban forest cover between 10% and 20%, and the average percentage of large cities whose urban populations were over 5 million was 24.8%. Cities with less than half of the average were mainly distributed in northern and western parts of China, which should be focused on in urban greening planning. © 2019 by the authors.",China; Google Earth Engine; Sentinel-2; Urban area; Urban greening,"Duan Q., Tan M., Guo Y., Wang X., Xin L.",10.3390/f10090729
211,5.0,2017,Conference Paper,3D shape descriptor for objects recognition,"3D point cloud classification is an important task in applications for many areas such as robotics, urban planning and augmented reality. 3D sensors measure a high amount of points in the 3D scene objects' surface at a high collect rate, so robust techniques are needed to process all input data and also deal with some imprecision. A common solution for these tasks is the use of robust features extraction techniques to gather representative scene information at the lowest computational cost possible. This paper presents a new approach for object recognition in 3D scenes, using a novel 3D shape descriptor which is used as input for a supervised machine learning method. Proposed robust 3D feature is invariant to translation and scale and provides a very simplified object representation for pattern recognition input. Experiments were performed using an Artificial Neural Network to recognize six different object shapes, and obtained results showed that the proposed method is a promising approach for object recognition in 3D scenes. © 2017 IEEE.",3D Feature Extraction; Object Classification; Pattern Recognition,"Sales D.O., Amaro J., Osório F.S.",10.1109/SBR-LARS-R.2017.8215285
223,4.0,2020,Article,Using GIS and machine learning to classify residential status of urban buildings in low and middle income settings,"Utilising satellite images for planning and development is becoming a common practice as computational power and machine learning capabilities expand. In this paper, we explore the use of satellite image derived building footprint data to classify the residential status of urban buildings in low and middle income countries. A recently developed ensemble machine learning building classification model is applied for the first time to the Democratic Republic of the Congo, and to Nigeria. The model is informed by building footprint and label data of greater completeness and attribute consistency than have previously been available for these countries. A GIS workflow is described that semiautomates the preparation of data for input to the model. The workflow is designed to be particularly useful to those who apply the model to additional countries and use input data from diverse sources. Results show that the ensemble model correctly classifies between 85% and 93% of structures as residential and nonresidential across both countries. The classification outputs are likely to be valuable in the modelling of human population distributions, as well as in a range of related applications such as urban planning, resource allocation, and service delivery. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Building classification; Building footprint; Machine learning; Residential; Superlearner,"Lloyd C.T., Sturrock H.J.W., Leasure D.R., Jochem W.C., Lázár A.N., Tatem A.J.",10.3390/rs12233847
237,4.0,2018,Conference Paper,Satellite image spoofing: Creating remote sensing dataset with generative adversarial networks,"The rise of Artificial Intelligence (AI) has brought up both opportunities and challenges for today's evolving GIScience. Its ability in image classification, object detection and feature extraction has been frequently praised. However, it may also apply for falsifying geospatial data. To demonstrate the thrilling power of AI, this research explored the potentials of deep learning algorithms in capturing geographic features and creating fake satellite images according to the learned 'sense'. Specifically, Generative Adversarial Networks (GANs) is used to capture geographic features of a certain place from a group of web maps and satellite images, and transfer the features to another place. Corvallis is selected as the study area, and fake datasets with 'learned' style from three big cities (i.e. New York City, Seattle and Beijing) are generated through CycleGAN. The empirical results show that GANs can 'remember' a certain 'sense of place' and further apply that 'sense' to another place. With this paper, we would like to raise both public and GIScientists' awareness in the potential occurrence of fake satellite images, and its impacts on various geospatial applications, such as environmental monitoring, urban planning, and land use development. © Chun X. Xu and Bo Zhao.",Deep learning and AI; Fake satellite image; GANs; Geographic feature,"Xu C., Zhao B.",10.4230/LIPIcs.GIScience.2018.67
430,,2021,Article,Building Roof Superstructures Classification from Imbalanced and Low Density Airborne LiDAR Point Cloud,"Light Detection and Ranging (LiDAR), an active remote sensing technology, is becoming an essential tool for geoinformation extraction and urban planning. Airborne Laser Scanning (ALS) point clouds segmentation and accurate classification are challenging and crucial to produce different geo-information products like three-dimensional (3D) city designs. This paper introduces an effective data-driven approach to build roof superstructures classification for airborne LiDAR point clouds with very low density and imbalanced classes, covering an urban area. Notably, it focuses on building roof superstructures (especially dormers and chimneys) and mitigating nonplanar objects' problems. Also, the imbalanced class problem of LiDAR data, to the best of our knowledge, is not yet addressed in the literature; it is considered in this study. The major advantage of the proposed approach is using only raw data without assumptions on the distribution underlying data. The main methodological novelties of this work are summarized in the following key elements. (i) At first, an adapted connected component analysis for 3D points cloud is proposed. (ii) Twelve geometry-based features are extracted for each component. (iii) A Support Vector Machine (SVM)-driven procedure is applied to classify the 3D components. (iv) Furthermore, a new component size-based sampling (CSBS) method is proposed to treat the imbalanced data problem and has been compared with several existing resampling strategies. In this study, components are classified into five classes: shed and gable dormers, chimneys, ground, and others. The results of this investigation show the satisfying classification performance of the proposed approach. Results also showed that the proposed approach outperformed machine learning methods, including SVM, Random Forest, Decision Tree, and Adaboost. © 2001-2012 IEEE.",3D classification; imbalanced data; light detection and ranging (LiDAR); Low-density point cloud; roof superstructures,"Aissou B.E., Aissa A.B., Dairi A., Harrou F., Wichmann A., Kada M.",10.1109/JSEN.2021.3073535
